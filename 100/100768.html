<html><title>Teste de Turing</title><body>&#10;<p><a href="http://en.wikipedia.org/wiki/Ficheiro:Turing_Test_version_3.png%7Cthumb" id="w">Interpreta&ccedil;&atilde;o mais comum do Teste de Turing, segundo a qual o jogador C, o interrogador, fica incumbido de tentar determinar qual jogador &shy; A ou B &shy; &eacute; um computador e qual &eacute; um humano. O interrogador limita&shy;se a usar as respostas &agrave;s perguntas escritas, a fim de tomar a decis&atilde;o. </a></p>&#10;<p>O <b>Teste de Turing</b> testa a capacidade de uma <a href="http://en.wikipedia.org/wiki/M%C3%A1quina" id="w">m&aacute;quina</a> exibir comportamento inteligente equivalente a um ser humano, ou indistingu&iacute;vel deste. No exemplo ilustrativo original, um julgador humano entra em uma conversa, em linguagem natural, com outro humano e uma m&aacute;quina projetada para produzir respostas indistingu&iacute;veis de outro ser humano. Todos os participantes est&atilde;o separados um dos outros. Se o ju&iacute;z n&atilde;o for capaz de distinguir com seguran&ccedil;a a m&aacute;quina do humano, diz&shy;se que a m&aacute;quina passou no teste. O teste n&atilde;o verifica a capacidade de dar respostas corretas para as perguntas&semi; mas sim o qu&atilde;o pr&oacute;ximas as respostas s&atilde;o das respostas dados por um ser humano t&iacute;pico. A conversa &eacute; restrita a um canal de texto, como um <a href="http://en.wikipedia.org/wiki/Teclado(inform%C3%A1tica)" id="w"> teclado</a> e uma <a href="http://en.wikipedia.org/wiki/Monitor_de_v%C3%ADdeo" id="w">tela</a> para que o resultado n&atilde;o dependa da capacidade da m&aacute;quina de renderizar &aacute;udio. <sup id="_ref&shy;1" class="reference"><a href="#_note&shy;1" title="">[1]</a></sup> </p>&#10;<p>O teste foi introduzido por <a href="http://en.wikipedia.org/wiki/Alan_Turing" id="w">Alan Turing</a> em seu artigo de 1950 &#34&semi;<a href="http://en.wikipedia.org/wiki/Computing_Machinery_and_Intelligence" id="w">Computing Machinery and Intelligence</a>&#34&semi;, que come&ccedil;a com as palavras: &#34&semi;Eu proponho considerar a quest&atilde;o &#34&semi;As m&aacute;quinas podem pensar?&#34&semi;. J&aacute; que &#34&semi;pensar&#34&semi; &eacute; dif&iacute;cil de definir, Turing preferiu &#34&semi;trocar a pergunta por outra, a qual est&aacute; relacionada &agrave; anterior, e &eacute; expressa em palavras menos amb&iacute;guas&#34&semi; . A nova pergunta de Turing &eacute;: &#34&semi;H&aacute; como imaginar um computador digital que faria bem o &#39&semi;jogo da imita&ccedil;&atilde;o?&#34&semi;&#39&semi;.<sup id="_ref&shy;2" class="reference"><a href="#_note&shy;2" title="">[2]</a></sup> Turing cria que esta quest&atilde;o poderia ser respondida. No restante do artigo, ele argumenta contra as principais obje&ccedil;&otilde;es a proposta que &#34&semi;m&aacute;quinas podem pensar&#34&semi; <sup id="_ref&shy;As nove obje&ccedil;&otilde;es de Turing_a" class="reference"><a href="#_note&shy;As nove obje&ccedil;&otilde;es de Turing" title="">[3]</a></sup> o cientista afirmou ainda que, se um computador fosse capaz de enganar um ter&ccedil;o de seus interlocutores, fazendo&shy;os acreditar que ele seria um ser humano, ent&atilde;o estaria pensando por si pr&oacute;prio.<sup id="_ref&shy;History_a" class="reference"><a href="#_note&shy;History" title="">[4]</a></sup></p>&#10;<p>No dia 8 de junho de 2014 (exatamente um dia ap&oacute;s o 60&ordm; anivers&aacute;rio da morte de <a href="http://en.wikipedia.org/wiki/Alan_Turing" id="w">Alan Turing</a>) pela primeira vez um supercomputador conseguiu superar este teste, atrav&eacute;s de um software chamado &#34&semi;<i>Eugene Goostman</i>&#34&semi;.<sup id="_ref&shy;History_b" class="reference"><a href="#_note&shy;History" title="">[4]</a></sup></p>&#10;<p>Desde 1950, o teste provou ser, ao mesmo tempo, altamente influenciante e criticado, e &eacute; um conceito fundamental da <a href="http://en.wikipedia.org/wiki/Filosofia_da_intelig%C3%AAncia_artificial" id="w">filosofia da intelig&ecirc;ncia artificial</a>.   </p>&#10;<a id="Hist%C3%B3ria" name="Hist%C3%B3ria"></a><h2>Hist&oacute;ria</h2>&#10;&#10;<a id="Contexto_filos%C3%B3fico" name="Contexto_filos%C3%B3fico"></a><h3>Contexto filos&oacute;fico</h3>&#10;&#10;<p>A quest&atilde;o da intelig&ecirc;ncia das m&aacute;quinas possui uma longa hist&oacute;ria, que est&aacute; firmemente enraizada na distin&ccedil;&atilde;o entre as vis&otilde;es <a href="http://en.wikipedia.org/wiki/Dualismo" id="w">dualista</a> e <a href="http://en.wikipedia.org/wiki/Materialismo" id="w">materialista</a> da mente. <a href="http://en.wikipedia.org/wiki/Ren%C3%A9_Descartes" id="w">Ren&eacute; Descartes</a> antecipa aspectos do Teste de Turing no seu escrito, de 1637, entitulado <a href="http://en.wikipedia.org/wiki/Discurso_sobre_o_M%C3%A9todo" id="w">Discurso sobre o M&eacute;todo</a>, onde ele escreve:   &#10;Aqui Descartes observa que <a href="http://en.wikipedia.org/wiki/Aut%C3%B4mato" id="w">aut&ocirc;matos</a> s&atilde;o capazes de responder a intera&ccedil;&otilde;es com humanas, mas argumenta que aut&ocirc;matos n&atilde;o podem responder apropriadamente coisas ditas em sua presen&ccedil;a do modo que qualquer humano pode. Descartes, assim, prefigura o Teste de Turing quando identifica a insufici&ecirc;ncia de respostas lingu&iacute;sticas apropriadas como as que separam humanos de aut&ocirc;matos. Descartes falha em considerar a possibilidade que a insufici&ecirc;ncia de respostas lingu&iacute;sticas apropriadas possa ser superada por futuros aut&ocirc;matos e assim n&atilde;o prop&otilde;e o Teste de Turing, mesmo que ele prefigure seu quadro conceitual e crit&eacute;rio.</p>&#10;<p><a href="http://en.wikipedia.org/wiki/Denis_Diderot" id="w">Denis Diderot</a> formula em seu Pensees Philosophiques um crit&eacute;rio de Teste de Turing:</p>&#10;<p>&#34&semi;Se encontrarem um pagagaio que possa responder a tudo, eu iria, sem hesita&ccedil;&atilde;o, afirmar que este &eacute; um ser inteligente.&#34&semi;<sup id="_ref&shy;5" class="reference"><a href="#_note&shy;5" title="">[5]</a></sup> </p>&#10;<p>Isto n&atilde;o significa que ele concorda com isso, mas este j&aacute; era um argumento comum entre os materialistas da &eacute;poca.</p>&#10;<p>De acordo com o dualismo, a <a href="http://en.wikipedia.org/wiki/Mente" id="w">mente</a> &eacute; <a href="http://en.wikipedia.org/wiki/Entidade_n%C3%A3o&shy;f%C3%ADsica" id="w">n&atilde;o&shy;f&iacute;sica</a> (ou, no m&iacute;nimo, tem <a href="http://en.wikipedia.org/wiki/Dualismo_de_propriedades" id="w"> propriedades n&atilde;o&shy;f&iacute;sicas</a><sup id="_ref&shy;6" class="reference"><a href="#_note&shy;6" title="">[6]</a></sup> e, portanto, n&atilde;o pode ser explicada puramente em termos f&iacute;sicos. De acordo com o materialismo, a mente pode ser explicada fisicamente, o que deixa aberta a possibilidade de mentes criadas artificialmente.</p>&#10;<p>Em 1936, o fil&oacute;sofo <a href="http://en.wikipedia.org/wiki/Alfred_Ayer" id="w">Alfred Ayer</a> considerou a quest&atilde;o filos&oacute;fica <a href="http://en.wikipedia.org/wiki/Problema_das_outras_mentes" id="w">das outras mentes</a>: Como sabemos que outras pessoas tem as mesmas experi&ecirc;ncias de consci&ecirc;ncia que n&oacute;s? Em seu livro, &#34&semi;<a href="http://en.wikipedia.org/wiki/Linguagem%2C_Verdade_e_L%C3%B3gica" id="w">Linguagem, Verdade e L&oacute;gica</a>&#34&semi;, Ayer sugere um protocolo para distinguir um homem consciente de uma m&aacute;quina inconsciente: &#34&semi;O &uacute;nico motivo que possa ter para afirmar que um objeto que parece consciente n&atilde;o passa de um manequim ou uma m&aacute;quina &eacute; que ele falha em satisfazer um dos testes emp&iacute;ricos pelos quais a presen&ccedil;a ou abstin&ecirc;ncia de consci&ecirc;ncia &eacute; determinada. <sup id="_ref&shy;7" class="reference"><a href="#_note&shy;7" title="">[7]</a></sup> (Esta sugest&atilde;o &eacute; semelhante ao Teste de Turing, mas n&atilde;o certo se Ayer era familiar com Turing.) Em outras palavras, uma coisa n&atilde;o &eacute; consciente se falhar no teste de consci&ecirc;ncia.&#39&semi;</p>&#10;<a id="Alan_Turing" name="Alan_Turing"></a><h3>Alan Turing</h3>&#10;<p>Pesquisadores no <a href="http://en.wikipedia.org/wiki/Reino_Unido" id="w">Reino Unido</a> exploraram a &#34&semi;intelig&ecirc;ncia artificial&#34&semi; por dez anos antes da funda&ccedil;&atilde;o da <a href="http://en.wikipedia.org/wiki/Intelig%C3%AAncia_Artificial" id="w"> IA</a> como campo de pesquisa, em 1956. <sup id="_ref&shy;8" class="reference"><a href="#_note&shy;8" title="">[8]</a></sup> Este era um tema comum entre os membros do <a href="http://en.wikipedia.org/wiki/Ratio_Club" id="w">Ratio Club</a>, um grupo informal de pesquisadores brit&acirc;nicos de <a href="http://en.wikipedia.org/wiki/Cibern%C3%A9tica" id="w">cibern&eacute;tica</a> e <a href="http://en.wikipedia.org/wiki/Eletr%C3%B4nica" id="w">eletr&ocirc;nica</a>, entre os quais <a href="http://en.wikipedia.org/wiki/Alan_Turing" id="w">Alan Turing</a>, a quem o teste foi nomeado. </p>&#10;<p>Turing, particularmente, abordou a no&ccedil;&atilde;o de intelig&ecirc;ncia de m&aacute;quinas desde, pelo menos, 1941  e uma das mais antigas men&ccedil;&otilde;es de &#34&semi;intelig&ecirc;ncia computacional&#34&semi; foi feita por ele, em 1947.  No relat&oacute;rio de Turing, &#34&semi;Intelligent Machinery&#34&semi;, ele investigou &#34&semi;a quest&atilde;o se &eacute; poss&iacute;vel ou n&atilde;o m&aacute;quina apresentarem comportamento inteligente&#34&semi;  e, como parte da investiga&ccedil;&atilde;o, propor o que pode ser considerado o precursor do que seria o Teste de Turing:</p><blockquote> N&atilde;o &eacute; dif&iacute;cil de conceber uma m&aacute;quina de papel que vai jogar um jogo n&atilde;o muito ruim de xadrez.<sup id="_ref&shy;9" class="reference"><a href="#_note&shy;9" title="">[9]</a></sup> Agora, pegue tr&ecirc;s homens para um experimento. A,B e C. A e C devem ser p&eacute;ssimos xadrezistas, B &eacute; o operador da m&aacute;quina de papel. ...Duas salas s&atilde;o usadas com algum mecanismo para comunica&ccedil;&atilde;o de movimentos, e uma partida &eacute; disputada por C e A ou, exclusivamente, a m&aacute;quina de papel. C pode chara dif&iacute;cil afirmar com quem ele est&aacute; jogando. </blockquote>&#10;&#10;<p>Em um artigo posterior, Turing sugere um formula&ccedil;&atilde;o alternativa &#34&semi;equivalente&#34&semi; envolvendo um julgador conversando somente com um computador e um homem.   Apesar de nenhuma dessas formula&ccedil;&otilde;es correspondem a vers&atilde;o do Teste de Turing como &eacute; conhecido hoje, ele prop&ocirc;s uma terceira vers&atilde;o em 1952. Nesta vers&atilde;o, discutida por Turing na r&aacute;dio <a href="http://en.wikipedia.org/wiki/BBC" id="w">BBC</a>, um juri indaga um computador que tem o papel de fazer uma parte consider&aacute;vel do j&uacute;ri acreditar que est&atilde;o se comunicando com um homem.<sup id="_ref&shy;10" class="reference"><a href="#_note&shy;10" title="">[10]</a></sup></p>&#10;<p>O artigo de Turing considerava nove d&uacute;vidas putativas, as quais incluiam todos os principais argumentos com a <a href="http://en.wikipedia.org/wiki/Intelig%C3%AAncia_artificial" id="w">intelig&ecirc;ncia artificial</a> que foram levantados desde a publica&ccedil;&atilde;o do artigo &#34&semi;<a href="http://en.wikipedia.org/wiki/Computing_Machinery_and_Intelligence" id="w">Computing Machinery and Intelligence</a>&#34&semi;.</p>&#10;<a id="ELIZA_e_PARRY" name="ELIZA_e_PARRY"></a><h3>ELIZA e PARRY</h3>&#10;<p>Em 1966, <a href="http://en.wikipedia.org/wiki/Joseph_Weizenbaum" id="w">Joseph Weizenbaum</a> criou um programa que aparentava passar no Teste de Turing. O programa, denominado <a href="http://en.wikipedia.org/wiki/ELIZA" id="w">ELIZA</a>, trabalhava examinando coment&aacute;rios digitados por um usu&aacute;rio procurando por palavras&shy;chave. Se uma palavra&shy;chave era encontrada, a regra que transforma o coment&aacute;rio do usu&aacute;rio era aplicada e a senten&ccedil;a resultante retornada. Se nenhuma palavra&shy;chave era encontrada, ELIZA retornava uma resposta gen&eacute;rica ou repetida o retorno do coment&aacute;rio anterior.  Al&eacute;m disso, Weizenbaum desenvolveu ELIZA de modo a replicar o comportamento de um <a href="http://en.wikipedia.org/wiki/Abordagem_centrada_na_pessoa" id="w">psicoterapeuta Rogeriano</a>, permitindo ELIZA, assim, ser &#34&semi;quase que livre para assumir uma postura de desconhecimento total do mundo real.&#34&semi; Com essas t&eacute;cnicas, o programa de Weizenbaum foi capaz de fazer com que pessoas acreditassem que estavam falando com um ser humano, ao ponto de, para algumas pessoas ser &#34&semi;muito dif&iacute;cil de convenc&ecirc;&shy;las que ELIZA [...] <i>n&atilde;o</i> &eacute; um humano.&#34&semi;  Assim, ELIZA foi considerada por alguns como um programa (talvez o primeiro) a passar no Teste de Turing,   , apesar destas vis&otilde;es serem altamente controv&eacute;rsias.(veja <a href="http://en.wikipedia.org/wiki/#Ingenuidade dos interrogadores e a fal&aacute;cia antropom&oacute;rfica" id="w">abaixo</a>).</p>&#10;<a id="A_sala_chinesa" name="A_sala_chinesa"></a><h3>A sala chinesa</h3>&#10;<p> &#10;Em 1980, <a href="http://en.wikipedia.org/wiki/John_Searle" id="w">John Searle</a> divulgou o artigo denominado <i><a href="http://en.wikipedia.org/wiki/Minds%2C_Brains%2C_and_Programs" id="w">Minds, Brains, and Programs</a></i>, onde propunha o experimento mental &#34&semi;<a href="http://en.wikipedia.org/wiki/Sala_chinesa" id="w">Sala chinesa</a>&#34&semi; e argumentava que o Teste de Turing n&atilde;o poderia determinar se uma m&aacute;quina pensava. Searle notou que software (como ELIZA) poderia passar no Teste de Turing simplesmente manipulando s&iacute;mbolos que ele n&atilde;o entendia. Sem entendimento, eles n&atilde;o poderiam ser descritos como &#34&semi;pensantes&#34&semi; no mesmo sentido que as pessoas s&atilde;o. Assim, Searle conclui, que o Teste de Turing n&atilde;o pode provar se uma m&aacute;quina pode pensar. O argumento de Searle foi altamente criticado,<sup id="_ref&shy;11" class="reference"><a href="#_note&shy;11" title="">[11]</a></sup> mas o argumento tamb&eacute;m foi endossado.<sup id="_ref&shy;12" class="reference"><a href="#_note&shy;12" title="">[12]</a></sup></p>&#10;<p>Argumentos como o de Searle e que outros trabalham sobre a <a href="http://en.wikipedia.org/wiki/Filosofia_da_mente" id="w">filosofia da mente</a> desencadearam nas d&eacute;cadas de 1980 e 1990 um debate mais intenso sobre a natureza da intelig&ecirc;ncia, a possibilidade de m&aacute;quina inteligentes e o valor do Teste de Turing. </p>&#10;<a id="Pr%C3%AAmio_de_Loebner" name="Pr%C3%AAmio_de_Loebner"></a><h3>Pr&ecirc;mio de Loebner</h3>&#10;<p> </p>&#10;<p>O Pr&ecirc;mio de Loebner promove, desde novembro de 1991, uma plataforma anual para demonstra&ccedil;&otilde;es pr&aacute;ticas do Teste Turing. Ele &eacute; assinado por <a href="http://en.wikipedia.org/wiki/Hugh_Loebner" id="w">Hugh Loebner</a>.O Cambridge Center for Behavioral Studies em <a href="http://en.wikipedia.org/wiki/Massachusetts" id="w">Massachusetts</a>,<a href="http://en.wikipedia.org/wiki/Estados_Unidos" id="w">Estados Unidos</a> organizou os pr&ecirc;mios at&eacute; 2003. Como Loebner disse, uma das raz&otilde;es para a cria&ccedil;&atilde;o da competi&ccedil;&atilde;o &eacute; o avan&ccedil;o da pesquisa em IA e tamb&eacute;m porque ningu&eacute;m conseguiu trilhar um caminho para implementa&ccedil;&atilde;o do Teste de Turing, apesar dos 40 anos de discuss&atilde;o do tema. </p>&#10;<p>A primeira disputa do Pr&ecirc;mio de Loebner ocorreu em 1991 e levou a renova&ccedil;&atilde;o da discuss&atilde;o sobre viabilidade do Teste de Turing e o valor em busc&aacute;&shy;lo, na m&iacute;dia popular   e na academia .<sup id="_ref&shy;SHAPIRO_SHIEBER_a" class="reference"><a href="#_note&shy;SHAPIRO_SHIEBER" title="">[13]</a></sup> O primeiro concurso foi vencido por um programa sem nenhum tipo de IA que foi capaz de enganar interrogadores. Isto destacou v&aacute;rias fraquezas do Teste de Turing (discutido em  <a href="http://en.wikipedia.org/wiki/#Fraquezas do Teste de Turing" id="w">abaixo</a>): O vencedor venceu, pelo menos em parte,  porque foi capaz de &#34&semi;imitar os erros de digita&ccedil;&atilde;o recorrentes em humanos&#34&semi;&semi;  os interrogadores foram facilmente enganados&semi; <sup id="_ref&shy;SHAPIRO_SHIEBER_b" class="reference"><a href="#_note&shy;SHAPIRO_SHIEBER" title="">[13]</a></sup> e outro pesquisadores de IA cr&ecirc;em que o teste &eacute; somente uma distra&ccedil;&atilde;o de pesquisas mais promissoras. </p>&#10;<p>Os pr&ecirc;mios de prata (somente texto) e de ouro (&aacute;udio e v&iacute;deo) nunca foram vencidos. Entretanto, a competi&ccedil;&atilde;o vem premiando todos os anos com medalhas de bronze programas que, a opini&atilde;o dos julgadores, demonstram um comportamento em conversar &#34&semi;mais humano&#34&semi;. <a href="http://en.wikipedia.org/wiki/Artificial_Linguistic_Internet_Computer_Entity" id="w">Artificial Linguistic Internet Computer Entity</a> (A.L.I.C.E.) venceu a medalha de bronze por tr&ecirc;s anos recentemente (2000,2001,2004). O programa de aprendizado artificial <a href="http://en.wikipedia.org/wiki/Jabberwacky" id="w">Jabberwacky</a> venceu em 2005 e 2006.<sup id="_ref&shy;14" class="reference"><a href="#_note&shy;14" title="">[14]</a></sup></p>&#10;<p>O vencedores dos testes de conversa&ccedil;&atilde;o normalmente s&atilde;o programas de <a href="http://en.wikipedia.org/wiki/Chatterbot" id="w">chatterbot</a> ou <a href="http://en.wikipedia.org/wiki/Entidade_de_Conversa%C3%A7%C3%A3o_Artificial" id="w">Entidades de conversa&ccedil;&atilde;o artificial (ACE)</a>. Nos primeiros anos, as regras de conversa&ccedil;&atilde;o era restritas: Cada m&aacute;quina e humano conversavam sobre um s&oacute; t&oacute;pico, assim os interrogadores eram restritos a uma linha de questionamento por intera&ccedil;&atilde;o com o programa. A regra de conversa restrita foi extinta em 1995. A dura&ccedil;&atilde;o das intera&ccedil;&otilde;es entre o interrogador e a m&aacute;quina varia entre as edi&ccedil;&otilde;es do pr&ecirc;mio. Em 2003, na Universidade de Surrey, cada interrogador era permitido interagir por 5 minutos com a m&aacute;quina, entidade ou humano&shy;escondido. Entre 2004 e 2007, o tempo de intera&ccedil;&atilde;o foi estendido para 20 minutos. Em 2008, voltou&shy;se a usar 5 minutos porque o organizador, <a href="http://en.wikipedia.org/wiki/Kevin_Warwick" id="w">Kevin Warwick</a>, e o coordenador, <a href="http://en.wikipedia.org/wiki/Huma_Shah" id="w">Huma Shah</a>, consideraram que esta deve ser a dura&ccedil;&atilde;o de qualquer teste, como Turing disse em  seu artigo de 1950: &#34&semi;... fazendo a correta identifica&ccedil;&atilde;o ap&oacute;s 5 minutos de questionamentos&#34&semi;.  Eles sentiram que o tempo usado em 2007 e 2008 era inapropriado para o estado da conversa&ccedil;&atilde;o artificial &Eacute; ir&ocirc;nico que o vencedor de 2008, <a href="http://en.wikipedia.org/wiki/Elbot" id="w">Elbot</a>, n&atilde;o imita um humano&semi; sua personalidade &eacute; a de um rob&ocirc;, apesar de Elbot ter enganado tr&ecirc;s ju&iacute;zes humanos. <sup id="_ref&shy;2008 Loebner Prize_a" class="reference"><a href="#_note&shy;2008 Loebner Prize" title="">[15]</a></sup></p>&#10;<p>Durante a competi&ccedil;&atilde;o de 2009, ocorrida em Brighton, Reino Unido, a restri&ccedil;&atilde;o de tempo foi de 10 minutos para cada rodada, 5 minutos de conversa com um humano e 5 minutos de conversa com um programa. Isto serviu para testar a leitura alternativa da predi&ccedil;&atilde;o de Turing, com interac&ccedil;&atilde;o de 5 minutos com o computador. Para a competi&ccedil;&atilde;o de 2010, o tempo de intera&ccedil;&atilde;o foi, novamente, aumentado para 25 minutos. <sup id="_ref&shy;16" class="reference"><a href="#_note&shy;16" title="">[16]</a></sup> </p>&#10;&#10;<a id="Vers%C3%B5es_do_Teste_de_Turing" name="Vers%C3%B5es_do_Teste_de_Turing"></a><h2>Vers&otilde;es do Teste de Turing</h2>&#10;<p><a href="http://en.wikipedia.org/wiki/File:The_Imitation_Game.png%7Cthumb" id="w">O Jogo da Imita&ccedil;&atilde;o, como descrito por Alan Turing em &#34&semi;Computing Machinery and Intelligence.&#34&semi; Jogador C, atrav&eacute;s de uma s&eacute;rie de quest&otilde;es escritas, tenta determinar qual dos outros dois jogadores &eacute; um homem e qual &eacute; uma mulher. Jogador A, o homem, tenta enganar o jogador C, enquanto o jogador B tenta ajudar o jogador C. Figura adaptada de Saygin, 2000. </a></p>&#10;<p>Saul Traiger argumento que h&aacute; ao menos tr&ecirc;s vers&otilde;es para o Teste de Turing, duas das quais s&atilde;o apresentadas em &#34&semi;Computing Machinery and Intelligence&#34&semi; e outra &eacute; descrita por ele como &#34&semi;Interpreta&ccedil;&atilde;o padr&atilde;o.&#34&semi;   H&aacute; um debate sobre o fato da &#34&semi;interpreta&ccedil;&atilde;o padr&atilde;o&#34&semi; ser descrita por Turing ou, em vez disso, baseado em uma interpreta&ccedil;&atilde;o errada do artigo, essas tr&ecirc;s vers&otilde;es n&atilde;o s&atilde;o equivalentes,  e suas for&ccedil;as e fraquezas s&atilde;o distintas. </p>&#10;<p>Huma Shah aponta que o pr&oacute;prio Turing estava interessado na quest&atilde;o do pensamento de m&aacute;quinas e estava propondo um m&eacute;todo simples testar se isto &eacute; poss&iacute;vel: atrav&eacute;s de sess&otilde;es de perguntas e respostas entre humanos e m&aacute;quinas.  Shah argumenta que o jogo de imita&ccedil;&atilde;o proposto por Turing poderia ser praticado de dois modos: a) testes de interrogamento um&shy;a&shy;um e b)compara&ccedil;&atilde;o simult&acirc;nea de uma m&aacute;quina com um homem, ambos sendo questionados em paralelo por um interrogador.  J&aacute; que o Teste de Turing &eacute; um teste de indistin&ccedil;&atilde;o em capacidade de perfomace, a vers&atilde;o verbal generaliza naturalmente toda a capacidade de perfomace humana, tanto verbal como n&atilde;o&shy;verbal (rob&oacute;tica). <sup id="_ref&shy;The Turing Test_a" class="reference"><a href="#_note&shy;The Turing Test" title="">[17]</a></sup> </p>&#10;<a id="O_Jogo_de_Imita%C3%A7%C3%A3o" name="O_Jogo_de_Imita%C3%A7%C3%A3o"></a><h3>O Jogo de Imita&ccedil;&atilde;o</h3>&#10;&#10;<p>O jogo original, proposto por Turing, descreve uma simples intera&ccedil;&atilde;o entre tr&ecirc;s jogadores. Jogador A &eacute; um homem, jogador B &eacute; uma mulher e o jogador C (que faz o papel de interrogador) pode ter qualquer sexo. Neste Jogo de Imita&ccedil;&atilde;o, o jogador C n&atilde;o &eacute; capaz de ver nenhum dos outros participante e s&oacute; pode comunicar&shy;se com eles atrav&eacute;s de mensagens escritas. Fazendo perguntas a A e B, o jogador C tenta determinar qual deles &eacute; homem e qual &eacute; mulher. O papel do jogador A &eacute; de levar o interrogador a fazer a decis&atilde;o errada, enquanto o jogador B tenta ajudar o interrogador. </p>&#10;<p>Sterret referencia este como o &#34&semi;Teste do Jogo de Imita&ccedil;&atilde;o Original&#34&semi;  Turing prop&ocirc;s que o papel do jogador A fosse feito por um computador, ou seja, fazer o papel do homem e levar o interrogador ao erro. O sucesso do computador seria determinado por uma compara&ccedil;&atilde;o com o resultado do jogo quando o jogador A &eacute; um homem. Turing disse que se &#34&semi;o interrogador decidir incorretamente t&atilde;o frequentemente em ambos os cen&aacute;rios, com um computador ou com um homem.&#34&semi;,  pode&shy;se dizer que o computador &eacute; inteligente.</p>&#10;<p><a href="http://en.wikipedia.org/wiki/File:Turing_Test_Version_1.png%7Cthumb" id="w">O Teste do Jogo de Imita&ccedil;&atilde;o Original no qual o jogador A &eacute; substitu&iacute;do por um computador. O computador fica encarregado do papel de uma mulher, enquanto o jogador B continua ajudando o interrogador. Figura adaptada de Saygin, 2000 </a></p>&#10;<p>A segunda vers&atilde;o apareceu em um artigo posterior de Turing, em 1950. Similarmente ao Teste do Jogo de Imita&ccedil;&atilde;o Original, o papel do jogador A &eacute; feito por um computador. Entretanto, o papel do jogador B &eacute; feito por um homem, ao inv&eacute;s de uma mulher.</p>&#10;<p /><blockquote>&#34&semi;Fixemos nossa aten&ccedil;&atilde;o em um computador em particular, digamos <i>C.</i> &Eacute; verdade que, modificando este computador para que tenha um capacidade de mem&oacute;ria suficiente, com um aumento substancial na sua velocidade de processamento, e provendo&shy;o com um programa&ccedil;&atilde;o adequada, <i>C</i> pode desempenhar satisfatoriamente o papel de A no jogo da imita&ccedil;&atilde;o, sendo a parte B desempenhada por um homem?&#34&semi; </blockquote>&#10;&#10;<p>Nesta vers&atilde;o, tanto o jogador A (o computador) tanto o B est&atilde;o tentando enganar o interrogador.</p>&#10;<a id="A_interpreta%C3%A7%C3%A3o_padr%C3%A3o" name="A_interpreta%C3%A7%C3%A3o_padr%C3%A3o"></a><h3>A interpreta&ccedil;&atilde;o padr&atilde;o</h3>&#10;&#10;<p>O entendimento comum diz que a proposta do Teste de Turing n&atilde;o &eacute; de que, especificamente, em computador &eacute; capaz de enganar um interrogador, levando&shy;o a acreditar que est&aacute; lidando com um humano, mas que um computador &eacute; capaz de <i>imitar</i> um humano.  Enquanto h&aacute; alguma disputa sobre a interpreta&ccedil;&atilde;o proposta por Turing = Sterrett acreditava que esta era a correta  e deste modo, funde as duas vers&otilde;es em uma, enquanto outros, como Traiger, n&atilde;o o fazem  &shy; isto, n&atilde;o obstante, levou ao que &eacute; visto como &#34&semi;interpreta&ccedil;&atilde;o padr&atilde;o.&#34&semi; Nesta vers&atilde;o, o jogador A &eacute; um computador e o jgoador B uma pessoa de qualquer sexo. O papel de interrogador n&atilde;o &eacute; determinar quem &eacute; homem ou mulher, mas quem &eacute; o computador e quem &eacute; o humano.  A quest&atilde;o fundamental com a interpreta&ccedil;&atilde;o padr&atilde;o &eacute; que o interrogador n&atilde;o pode diferenciar uma resposta dada por uma m&aacute;quina da dada por um humano. H&aacute; quest&otilde;es de dura&ccedil;&atilde;o do teste, mas a interpreta&ccedil;&atilde;o padr&atilde;o generaliza essa limita&ccedil;&atilde;o para algo que seja razo&aacute;vel.</p>&#10;<a id="Jogo_da_imita%C3%A7%C3%A3o_vs._Teste_padr%C3%A3o_de_Turing" name="Jogo_da_imita%C3%A7%C3%A3o_vs._Teste_padr%C3%A3o_de_Turing"></a><h3>Jogo da imita&ccedil;&atilde;o vs. Teste padr&atilde;o de Turing</h3>&#10;&#10;<p>Controv&eacute;rsia surgiu sobre as formula&ccedil;&otilde;es alternativas do Teste de Turing.  Sterrett argumenta que dois testes distintos podem ser extra&iacute;dos de seu artigo de 1950 e que, o coment&aacute;rio de &#34&semi;ritmo&#34&semi; de Turing, eles n&atilde;o s&atilde;o equivalentes. O teste que emprega o jogo e compara frequ&ecirc;ncias de sucesso &eacute; referenciado como o &#34&semi;Teste do Jogo de Imita&ccedil;&atilde;o Original&#34&semi;, enquanto o teste que consiste de um ju&iacute;z humano conversando com um humano e uma m&aacute;quina &eacute; referenciado como &#34&semi;Teste de Turing Padr&atilde;o&#34&semi;, notando que Sterrett equivale este com a &#34&semi;interpreta&ccedil;&atilde;o padr&atilde;o&#34&semi;, em vez da segunda vers&atilde;o do jogo de imita&ccedil;&atilde;o. Sterrett concorda que o Teste de Turing Padr&atilde;o (TTP) tem problemas que seus cr&iacute;ticos citam, mas sente que, em contraste, o Teste do Jogo de Imita&ccedil;&atilde;o Original (TJIO) &eacute; imune a muitas destas, devido a uma diferen&ccedil;a cr&iacute;tica: Diferentemente do TTP, o TIJO n&atilde;o usa como crit&eacute;rio a similaridade com a perfomace humana, apesar de empregar o desempenho humano em estabelecer um crit&eacute;rio para a intelig&ecirc;ncia da m&aacute;quina. Um homem pode falhar no TIJO, mas argumenta&shy;se que &eacute; uma virtude que uma falhas em um teste de intelig&ecirc;ncia indica um falta de desenvoltura: O TIJO requer uma desenvoltura associada com intelig&ecirc;ncia e n&atilde;o simplesmente &#34&semi;simula&ccedil;&atilde;o do comportamento humano de conversa&ccedil;&atilde;o.&#34&semi; A estrutura geral do TIJO pode at&eacute; ser usada com vers&otilde;es n&atilde;o&shy;verbais dos jogos de imita&ccedil;&atilde;o.  </p>&#10;<p>Ainda h&aacute; outro autores<sup id="_ref&shy;18" class="reference"><a href="#_note&shy;18" title="">[18]</a></sup> que interpretaram que Turing prop&ocirc;s o jogo da imita&ccedil;&atilde;o como um teste em si, sem especificar como levar em considera&ccedil;&atilde;o a declara&ccedil;&atilde;o de Tuirng que o teste que eles prop&ocirc;s usa a vers&atilde;o da festa do jogo de imita&ccedil;&atilde;o &eacute; baseada em um crit&eacute;rio  de compara&ccedil;&atilde;o de frequ&ecirc;ncia de sucesso naquele jogo de imita&ccedil;&atilde;o, ao inv&eacute;s de uma capacidade de sucesso em uma rodada do jogo.</p>&#10;<p>Saygin sugeriu que talvez o jogo original &eacute; um meio de propor um design experimental menos tendencioso, j&aacute; que ele esconde a participa&ccedil;&atilde;o do computador.<sup id="_ref&shy;19" class="reference"><a href="#_note&shy;19" title="">[19]</a></sup> O jogo da imita&ccedil;&atilde;o tamb&eacute;m inclui um &#34&semi;hack social&#34&semi; n&atilde;o encontrado na interpreta&ccedil;&atilde;o padr&atilde;o, visto que o jogo requere um humano masculino e um computador, jogando com a inten&ccedil;&atilde;o de demonstrar que s&atilde;o algu&eacute;m que n&atilde;o s&atilde;o.</p>&#10;<a id="O_interrogador_deve_saber_sobre_o_computador%3F" name="O_interrogador_deve_saber_sobre_o_computador%3F"></a><h3>O interrogador deve saber sobre o computador?</h3>&#10;&#10;<p>Uma pe&ccedil;a crucial de qualquer laborat&oacute;rio de testes deve ser a sala de controle. Turing nunca deixou claro, em seus testes, se o interrogador estava ciente que um dos participantes &eacute; um computador. Entretanto, se h&aacute; uma m&aacute;quina capaz de passar no Teste de Turing, pode&shy;se assumir que um teste duplo&shy;cego &eacute; necess&aacute;rio.</p>&#10;<p>Para retornar ao Jogo de Imita&ccedil;&atilde;o Original, em declara que somente o jogador A deve ser substitu&iacute;do por uma m&aacute;quina, sem que o jogador C esteja ciente disto.  QUando Colbu, FD Hilf, S Weber e AD Kramer testaram PARRY, eles assumiram que os interrogadores n&atilde;o sabiam que um ou mais dos entrevistados era um computador.  Enquanto Ayse Saygin, Peter Swirski , e outros destacaram, isto faz uma grande diferen&ccedil;a na implementa&ccedil;&atilde;o e resultado do teste.  Um estudo experimental observou &#34&semi;Gricean maxim violations&#34&semi; usando  transcri&ccedil;&otilde;es de Loebner um&shy;a&shy;um (interlocutor escondido do interrogador) Premiado em competi&ccedil;&otilde;es de IA entre 1994&shy;1999, Ayse Saygin encontrou uma diferen&ccedil;a substancial entre as respostas dos participantes que sabiam e que n&atilde;o sabiam sobre o envolvimento de computadores. </p>&#10;<p><a href="http://en.wikipedia.org/wiki/Huma_Shah" id="w">Huma Shah</a> e <a href="http://en.wikipedia.org/wiki/Kevin_Warwick" id="w">Kevin Warwick</a>, que organizaram o <a href="http://en.wikipedia.org/wiki/Pr%C3%AAmio_Loebner" id="w">2008 Loebner Prize</a> na <a href="http://en.wikipedia.org/wiki/Reading_University" id="w">Reading University</a>, mostraram que o conhecimento do envolvimento de computadores n&atilde;o fez uma diferen&ccedil;a significativa na decis&atilde;o dos ju&iacute;zes. Ju&iacute;zes n&atilde;o foram informados explicitamente da natureza de seus pares. Ju&iacute;zes capazes  de distinguir humanos de computadores, incluindo quando eles eram postos com dois humanos ou duas m&aacute;quinas. Erros de grafia revelaram os humanos&semi; m&aacute;quinas foram identificadas pela &#39&semi;velocidade de resposta&#39&semi; e  express&otilde;es mais longas.<sup id="_ref&shy;2008 Loebner Prize_b" class="reference"><a href="#_note&shy;2008 Loebner Prize" title="">[15]</a></sup></p>&#10;<a id="For%C3%A7a_do_teste" name="For%C3%A7a_do_teste"></a><h2>For&ccedil;a do teste</h2>&#10;&#10;<a id="Tratabilidade_e_simplicidade" name="Tratabilidade_e_simplicidade"></a><h3>Tratabilidade e simplicidade</h3>&#10;&#10;<p>O poder e apelo do teste de Turing vem de sua simplicidade. A <a href="http://en.wikipedia.org/wiki/Filosofia_da_mente" id="w">filosofia da mente</a>, <a href="http://en.wikipedia.org/wiki/Psicologia" id="w">psicologia</a> e a moderna <a href="http://en.wikipedia.org/wiki/Neuroci%C3%AAncia" id="w">neuroci&ecirc;ncia</a> n&atilde;o conseguiram prover defini&ccedil;&otilde;es de &#34&semi;intelig&ecirc;ncia&#34&semi; e &#34&semi;pensamento&#34&semi; que sejam suficientemente precisas e gerais para serem aplicadas &agrave; m&aacute;quinas. Sem estas defini&ccedil;&otilde;es, as quest&otilde;es centrais da <a href="http://en.wikipedia.org/wiki/Filosofia_da_intelig%C3%AAncia_artificial" id="w">filosofia da intelig&ecirc;ncia artificial</a> n&atilde;o podem ser respondidas. O teste de Turing, apesar de sua imperfei&ccedil;&atilde;o, ao menos prov&ecirc; algo que pode ser medido. Portanto, &eacute; uma solu&ccedil;&atilde;o pragm&aacute;tica para uma dif&iacute;cil quest&atilde;o filos&oacute;fica.</p>&#10;<a id="Extens%C3%A3o_do_assunto" name="Extens%C3%A3o_do_assunto"></a><h3>Extens&atilde;o do assunto</h3>&#10;&#10;<p>O formato do teste permite que o interrogador d&ecirc; &agrave; m&aacute;quina uma vasta variedade de tarefas intelectuais. Turing escreveu que &#34&semi;o m&eacute;todo de quest&atilde;o e resposta parece ser adequado para introduzir quase que qualquer um dos campos do pensamento humano que desejarmos.&#34&semi;  <a href="http://en.wikipedia.org/wiki/John_Haugeland" id="w">John Haugeland</a> ainda diz que &#34&semi;o entendimento das palavras n&atilde;o &eacute; suficiente&semi; voc&ecirc; tem que entender o &#34&semi;t&oacute;pico&#34&semi; tamb&eacute;m.&#34&semi; </p>&#10;<p>Para passar em um Teste de Turing bem planejado, a m&aacute;quina deve usar de <a href="http://en.wikipedia.org/wiki/Processamento_natural_de_linguagem" id="w">linguagem natural</a>,<a href="http://en.wikipedia.org/wiki/Racioc%C3%ADnio_de_senso&shy;comum" id="w">raz&atilde;o</a>, ter <a href="http://en.wikipedia.org/wiki/Representa%C3%A7%C3%A3o_de_conhecimento" id="w">conhecimento</a> e <a href="http://en.wikipedia.org/wiki/Capacidade_de_aprender" id="w">aprendizado</a>. O teste pode ser expandido para incluir input de v&iacute;deo, assim como uma escotilha pela qual objetos pode ser passados: Isto for&ccedil;aria a m&aacute;quina a possuir <a href="http://en.wikipedia.org/wiki/Vis%C3%A3o_computacional" id="w">vis&atilde;o</a> e <a href="http://en.wikipedia.org/wiki/Rob%C3%B3tica" id="w">rob&oacute;tica</a>. Juntos, estes representam quase que a totalidade dos principais problemas que a pesquisa de IA gostaria de resolver.<sup id="_ref&shy;20" class="reference"><a href="#_note&shy;20" title="">[20]</a></sup></p>&#10;&#10;<a id="Fraquezas_do_teste" name="Fraquezas_do_teste"></a><h2>Fraquezas do teste</h2>&#10;&#10;<p>Turing n&atilde;o declarou explicitamente que o Teste de Turing poderia ser usado como medida de intelig&ecirc;ncia. Ele queria prover uma clara e compreens&iacute;vel alternativa para a palavra &#34&semi;pensar&#34&semi;, pela qual ele poderia usar para responder ao criticismo da possibilidade de &#34&semi;m&aacute;quinas pensantes&#34&semi; e para sugerir meio que a pesquisa poderia desenvolver&shy;se.</p>&#10;<p>N&atilde;o obstante, o Teste de Turing foi proposto para uma medida da &#34&semi;capacidade de pensamento&#34&semi; e &#34&semi;intelig&ecirc;ncia&#34&semi; de uma m&aacute;quina. A proposta foi recebida com criticismo tanto por fil&oacute;sofos como por cientistas da computa&ccedil;&atilde;o. Assume&shy;se que um interrogador pode determinar se uma m&aacute;quina est&aacute; &#34&semi;pensando&#34&semi; comparando seu desempenho com o comportamento humano. Todo elemento dessa assump&ccedil;&atilde;o pode ser questionada: a confian&ccedil;a no julgamento do interrogador, o valor da compara&ccedil;&atilde;o simplesmente do comportamento e o valor de comparar uma m&aacute;quina com um homem. Por causa disso e de outras considera&ccedil;&otilde;es, alguns pesquisadores de IA  questionaram a relev&acirc;ncia do teste no seu campo.</p>&#10;<a id="Intelig%C3%AAncia_humana_vs_intelig%C3%AAncia_em_geral" name="Intelig%C3%AAncia_humana_vs_intelig%C3%AAncia_em_geral"></a><h3>Intelig&ecirc;ncia humana vs intelig&ecirc;ncia em geral</h3>&#10;&#10;<p><a href="http://en.wikipedia.org/wiki/File:Weakness_of_Turing_test_1.svg%7C250px" id="w">thumb</a> &#10;O Teste de Turing n&atilde;o testa diretamente se um computador se comporta de forma inteligente &shy; ele teste somente se um computador se comporta como um humano. J&aacute; que o comportamento humano e comportamento inteligente n&atilde;o s&atilde;o exatamente a mesma coisa, o teste de falhar como medida de intelig&ecirc;ncia de duas formas:</p>&#10;<dl><dt>Algum comportamento humano &eacute; ininteligente</dt><dd>O Teste de Turing requer que a m&aacute;quina possa ser capaz de executar &#34&semi;todo&#34&semi; comportamento humano, independentemente dele ser inteligente. O teste cobre at&eacute; comportamentos que n&atilde;o podem ser considerados inteligentes, como suscetibilidade para insultos,    tenta&ccedil;&atilde;o de <a href="http://en.wikipedia.org/wiki/Mentir" id="w">mentira</a> ou, simplesmente, uma alta frequ&ecirc;ncia de erros de escrita. Se a m&aacute;quina n&atilde;o pode imitar estes comportamentos ininteligentes em detalhes, ela falha no teste.</dd></dl>&#10;<dl><dd>Esta obje&ccedil;&atilde;o surgiu no &#34&semi;<a href="http://en.wikipedia.org/wiki/The_Economist" id="w">The Economist</a>&#34&semi;, num artigo intitulado &#34&semi;<a href="http://en.wikipedia.org/wiki/Estupidade_artificial" id="w">Estupidade Artificial</a>&#34&semi; publicado logo ap&oacute;s o primeiro pr&ecirc;mio de Loebner, em 1992. O artigo aponta que o primeiro vencedor do pr&ecirc;mio deveu&shy;se, ao menos em parte, a habilidade de &#34&semi;imitar os erros de digita&ccedil;&atilde;o do ser humano.&#34&semi;  Turing sugeriu que os programas adicionassem erros nos seus resultados, para tornarem&shy;se melhores &#34&semi;jogadores&#34&semi; do jogo. </dd></dl>&#10;<dl><dt>Algum comportamento inteligente &eacute; inumano</dt><dd>O Teste de Turing n&atilde;o testa altos n&iacute;veis de intelig&ecirc;ncia, como habilidade de resolver problemas dif&iacute;ceis ou criar insights originais. Na verdade, ele especificamente requer engano por parte da m&aacute;quina: Se a m&aacute;quina &eacute; &#34&semi;mais&#34&semi; inteligente que um humano, ela precisa deliberadamente parecer menos inteligente. Se damos um problema computacional que &eacute; imposs&iacute;vel para qualquer humano resolver, o interrogador saberia que trata&shy;se de uma m&aacute;quina e ela falharia no teste.</dd></dl>&#10;<dl><dd>Devido ao fato que n&atilde;o testa&shy;se n&iacute;veis de intelig&ecirc;ncia sobre&shy;humanas, o teste n&atilde;o pode ser usado para construir ou avaliar sistemas que s&atilde;o mais inteligentes que humanos. Por isso, v&aacute;rios testes alternativos para avaliar sistemas superinteligentes foram propostos.<sup id="_ref&shy;21" class="reference"><a href="#_note&shy;21" title="">[21]</a></sup></dd></dl>&#10;<ul>&#10;<li> </li>&#10;<li> </li>&#10;<li> </li>&#10;<li> </li></ul>&#10;<p />&#10;<a id="Intelig%C3%AAncia_real_vs_intelig%C3%AAncia_simulada" name="Intelig%C3%AAncia_real_vs_intelig%C3%AAncia_simulada"></a><h3>Intelig&ecirc;ncia real vs intelig&ecirc;ncia simulada</h3>&#10;<p>O Teste de Turing est&aacute; preocupado estritamente com como o objeto &#34&semi;age&#34&semi; &shy; o comportamento externo da m&aacute;quina. Neste aspecto, ele toma as abordagens do <a href="http://en.wikipedia.org/wiki/Behaviorismo" id="w">Behaviorismo</a> ou do <a href="http://en.wikipedia.org/wiki/Functionalism_(philosophy_of_mind)" id="w">funcionalismo</a> para estudar intelig&ecirc;ncia. O exemplo de <a href="http://en.wikipedia.org/wiki/ELIZA" id="w">ELIZA</a> sugere que uma m&aacute;quina que passa no teste pode ser capaz de simular o comportamento de conversa humana seguindo um simples (por&eacute;m grande) lista de regras mec&acirc;nicas, sem nenhum tipo de pensamento.</p>&#10;<p><a href="http://en.wikipedia.org/wiki/John_Searle" id="w">John Searle</a> argumentou que comportamento externo n&atilde;o pode ser usado para determinar se uma m&aacute;quina est&aacute; &#34&semi;realmente&#34&semi; pensando ou simplesmente &#34&semi;simulando pensamento&#34&semi;.  Seu argumento da <a href="http://en.wikipedia.org/wiki/Sala_chinesa" id="w">sala chinesa</a> tem a inten&ccedil;&atilde;o de mostrar que, mesmo o Teste de Turing sendo uma boa defini&ccedil;&atilde;o operacional de intelig&ecirc;ncia, isto pode n&atilde;o indicar que a m&aacute;quina tem uma <a href="http://en.wikipedia.org/wiki/Mente" id="w">mente</a>, <a href="http://en.wikipedia.org/wiki/Consci%C3%AAncia" id="w">consci&ecirc;ncia</a> ou <a href="http://en.wikipedia.org/wiki/Inten%C3%A7%C3%A3o" id="w">inten&ccedil;&atilde;o</a>. (Inten&ccedil;&atilde;o &eacute; um termo filos&oacute;fico para poder de pensamento ser &#34&semi;sobre&#34&semi; algo.)</p>&#10;<p>Turing antecipou esta linha de criticismo no seu artigo original, <sup id="_ref&shy;22" class="reference"><a href="#_note&shy;22" title="">[22]</a></sup> escrevendo:  </p>&#10;<a id="Inoc%C3%AAncia_dos_interrogadores_e_a_fal%C3%A1cia_antropom%C3%B3rfica" name="Inoc%C3%AAncia_dos_interrogadores_e_a_fal%C3%A1cia_antropom%C3%B3rfica"></a><h3>Inoc&ecirc;ncia dos interrogadores e a fal&aacute;cia antropom&oacute;rfica</h3>&#10;<p>Na pr&aacute;tica, os resultados do teste podem ser facilmente dominados n&atilde;o pela intelig&ecirc;ncia do computador, mas pelas atitudes, habilidades e inoc&ecirc;ncia do questionador.</p>&#10;<p>Turing n&atilde;o especifica habilidades ou conhecimento necess&aacute;rios para o interrogador na descri&ccedil;&atilde;o do teste, mas ele usa o termo &#34&semi;interrogador comum&#34&semi;: &#34&semi;[o] interrogador comum n&atilde;o deve ter mais de 70% de chances de fazer a identifica&ccedil;&atilde;o correta ap&oacute;s 5 minutos de conversa&ccedil;&atilde;o&#34&semi;. </p>&#10;<p>  mostra que experts podem ser enganados, e que a estrat&eacute;gia do interrogador, &#34&semi;poder&#34&semi; vs &#34&semi;solidariedade&#34&semi; afeta a correta identifica&ccedil;&atilde;o, o segundo sendo melhor para o sucesso.</p>&#10;<p>Programas chatterbot como ELIZA enganaram repetidamente pessoas desavisadas, fazendo&shy;as acreditarem estar falando com um humano. Nestes casos, o &#34&semi;interrogador&#34&semi; n&atilde;o est&aacute; ciente da possibilidade de estarem interagindo com um computador. Para parecer humano com sucesso, n&atilde;o h&aacute; necessidade da m&aacute;uqina ter qualquer intelig&ecirc;ncia, somente uma lembran&ccedil;a superficial do comportamento humano.</p>&#10;<p>Os competidores dos primeiros pr&ecirc;mios Loebner usavam interrogadores &#34&semi;n&atilde;o&shy;sofisticados&#34&semi; que era facilmente enganados pelas m&aacute;quinas.<sup id="_ref&shy;SHAPIRO_SHIEBER_c" class="reference"><a href="#_note&shy;SHAPIRO_SHIEBER" title="">[13]</a></sup>  Desde 2004, os organizadores do pr&ecirc;mio Leobner usaram fil&oacute;sofos, cientistas da computa&ccedil;&atilde;o, jornalistas como interrogadores. N&atilde;o obstante, alguns destes interrogadores foram enganados pelas m&aacute;quinas.  </p>&#10;<p><a href="http://en.wikipedia.org/wiki/Micheal_Shermer" id="w">Micheal Shermer</a> aponta que humanos constantemente escolhem considerar objetos n&atilde;o&shy;humanos como humanos sempre que tem a chance, um erro chamado <a href="http://en.wikipedia.org/wiki/Fal%C3%A1cia_antropom%C3%B3rfica" id="w">fal&aacute;cia antropom&oacute;rfica</a>: Eles falam com seus carros, atribuem desejo e inten&ccedil;&atilde;o a for&ccedil;as da natureza (e.g., &#34&semi;natureza abomina o v&aacute;cuo&#34&semi;), e adoram o Sol como um ser humanificado com intelig&ecirc;ncia. Se o Teste de Turing &eacute; aplicado a objetos religiosos, Shermer argumenta, ent&atilde;o, que est&aacute;tuas inanimadas, rochas e lugares passaram o teste por toda a hist&oacute;ria.  Esta tend&ecirc;ncia humana pelo antropomorfismo efetivamente diminui o limite para o Teste de Turing, ao menos que o interrogador esteja treinado para evit&aacute;&shy;la.</p>&#10;<a id="Impraticabilidade_e_irrelevancia:_O_Teste_de_Turing_e_pesquisa_de_IA" name="Impraticabilidade_e_irrelevancia:_O_Teste_de_Turing_e_pesquisa_de_IA"></a><h3>Impraticabilidade e irrelevancia: O Teste de Turing e pesquisa de IA</h3>&#10;<p>Os principais pesquisadores de IA argumenta que a tentativa de passar no Teste de Turing &eacute; simplesmente uma distra&ccedil;&atilde;o, n&atilde;o uma pesquisa frut&iacute;fera. De fato, o Teste de Turing n&atilde;o &eacute; o foco de muitas pesquisas acad&ecirc;micas ou comerciais &shy; como <a href="http://en.wikipedia.org/wiki/Stuart_J._Russell" id="w">Stuart Russell</a> e <a href="http://en.wikipedia.org/wiki/Peter_Norvig" id="w">Peter Norvig</a> escreveram: &#34&semi;Pesquisadores de IA dedicaram pouca aten&ccedil;&atilde;o a tentativas de passar no Teste de Turing.&#34&semi;  Por diversas raz&otilde;es.</p>&#10;<p>Primeiro, h&aacute; maneiras mais f&aacute;ceis de testar seus programas. Boa parte da pesquisa atual na &aacute;rea de IA est&aacute; focada em objetivos modestos e espec&iacute;ficos, como <a href="http://en.wikipedia.org/wiki/Planejamento_automatizado" id="w">planejamento automatizado</a>, <a href="http://en.wikipedia.org/wiki/Reconhecimento_de_objetos" id="w">reconhecimento de objetos</a> ou <a href="http://en.wikipedia.org/wiki/Log%C3%ADstica" id="w">log&iacute;stica</a>. Para testar a intelig&ecirc;ncia de programas nestes problemas, pesquisadores de IA simplesmente os d&atilde;o tarefas diretamente, ao inv&eacute;s de  ir atrav&eacute;s do m&eacute;todo indireto de postar uma pergunta em uma <a href="http://en.wikipedia.org/wiki/Sala_de_chat" id="w">sala de chat</a> populada com computadores e pessoas.</p>&#10;<p>Segundo, criar simula&ccedil;&otilde;es semelhantes a vida de humanos &eacute; um problema dif&iacute;cil por si s&oacute; que n&atilde;o precisa ser resolvido para alcan&ccedil;ar os objetivos b&aacute;sicos de pesquisa de IA. Personagens que atuem como humanos por ser interessantes em um trabalho de arte, um <a href="http://en.wikipedia.org/wiki/Video_game" id="w">video game</a> ou uma <a href="http://en.wikipedia.org/wiki/Interface_de_usu%C3%A1rio" id="w">interface de usu&aacute;rio</a> sofisticada, mas eles n&atilde;o s&atilde;o parte da ci&ecirc;ncia de criar m&aacute;quina inteligentes, ou seja, m&aacute;quinas que resolvam problemas usando intelig&ecirc;ncia. Russell e Norvig sugerem uma analogia com a <a href="http://en.wikipedia.org/wiki/Hist%C3%B3ria_do_voo" id="w">hist&oacute;ria do voo</a>: Avi&otilde;es s&atilde;o testados para qu&atilde;o bem podem voar, mas n&atilde;o s&atilde;o comparados como aves. &#34&semi;Textos de <a href="http://en.wikipedia.org/wiki/Engenharia_aeron%C3%A1utica" id="w">engenharia aeron&aacute;utica</a>&#34&semi;, eles escrevem, &#34&semi;n&atilde;o definem objetivos em seus campos como &#39&semi;fazer m&aacute;quina que voam assim como aves, para que possam enganar outras aves&#39&semi;&#34&semi; </p>&#10;<p>Turing nunca teve a inten&ccedil;&atilde;o que seu teste fosse usado como um meio pr&aacute;tico de medir a intelig&ecirc;ncia de programas de IA&semi; eles pretendia prover um claro e entend&iacute;vel exemplo para contribuir com a discuss&atilde;o da <a href="http://en.wikipedia.org/wiki/Filosofia_da_intelig%C3%AAncia_artificial" id="w">filosofia da intelig&ecirc;ncia artificial</a>.<sup id="_ref&shy;23" class="reference"><a href="#_note&shy;23" title="">[23]</a></sup> <a href="http://en.wikipedia.org/wiki/John_McCarthy" id="w">John McCarthy</a> observa que a filosofia da IA &eacute; &#34&semi;improv&aacute;vel que afete a pesquisa pr&aacute;tica de IA que a filosofia da ci&ecirc;ncia em geral tem sobre a pr&aacute;tica cient&iacute;fica.&#34&semi;<sup id="_ref&shy;24" class="reference"><a href="#_note&shy;24" title="">[24]</a></sup></p>&#10;&#10;<p> </p>&#10;<a id="Bibliografia" name="Bibliografia"></a><h2>Bibliografia</h2>&#10;&#10;<ul>&#10;<li> </li></ul>&#10;<a id="Ver_tamb%C3%A9m" name="Ver_tamb%C3%A9m"></a><h2> Ver tamb&eacute;m </h2>&#10;&#10;<ul>&#10;<li><a href="http://en.wikipedia.org/wiki/Intelig%C3%AAncia_artificial" id="w">Intelig&ecirc;ncia artificial</a></li>&#10;<li><a href="http://en.wikipedia.org/wiki/Rob%C3%B3tica" id="w">Rob&oacute;tica</a></li>&#10;<li><a href="http://en.wikipedia.org/wiki/SCIgen" id="w">SCIgen</a></li></ul>&#10;<p> </p>&#10;<p> &#10;<a href="http://en.wikipedia.org/wiki/Categoria:Alan_Turing" id="w">Categoria:Alan Turing</a>&#10;<a href="http://en.wikipedia.org/wiki/Categoria:Intelig%C3%AAncia_artificial" id="w">Categoria:Intelig&ecirc;ncia artificial</a>&#10;<a href="http://en.wikipedia.org/wiki/Categoria:Hist%C3%B3ria_da_intelig%C3%AAncia_artificial" id="w">Categoria:Hist&oacute;ria da intelig&ecirc;ncia artificial</a>&#10;<a href="http://en.wikipedia.org/wiki/Categoria:Intera%C3%A7%C3%A3o_humano&shy;computador" id="w">Categoria:Intera&ccedil;&atilde;o humano&shy;computador</a></p></body></html>