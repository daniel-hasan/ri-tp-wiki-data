<html><title>Arquitetura de von Neumann</title><body>&#10;<p> &#10; &#10;<a href="http://en.wikipedia.org/wiki/File:JohnvonNeumann&shy;LosAlamos.gif%7Cthumb%7C160px" id="w">[[John von Neumann]].</a>&#10;<a href="http://en.wikipedia.org/wiki/Ficheiro:Arquitetura_de_von_Neumann.svg%7Cthumb%7C200px" id="w">Ilustra&ccedil;&atilde;o representando a &#34&semi;Arquitetura de von Neumann&#34&semi;</a>&#10;<a href="http://en.wikipedia.org/wiki/Ficheiro:Arquitectura_von_Neumann.png%7Cthumb%7C200px" id="w">Ilustra&ccedil;&atilde;o detalhando a Arquitetura</a>&#10;<a href="http://en.wikipedia.org/wiki/Ficheiro:Von_Neumann_Cyclus.png%7Cthumb%7C200px" id="w">Ciclo de von Neumann: Buscar&shy;Decodificar&shy;Executar</a>&#10;<a href="http://en.wikipedia.org/wiki/Ficheiro:Arquitecturaneumann.jpg%7Cthumb%7C200px" id="w">Diagrama da Arquitetura</a></p>&#10;<p>A <b>Arquitetura de von Neumann</b> &shy; de <a href="http://en.wikipedia.org/wiki/John_von_Neumann" id="w">John von Neumann</a> (pronunciado N&oacute;imann) &shy; &eacute; uma arquitetura de computador que se caracteriza pela possibilidade de uma m&aacute;quina digital armazenar seus <a href="http://en.wikipedia.org/wiki/Programa_de_computador" id="w">programas</a> no mesmo espa&ccedil;o de <a href="http://en.wikipedia.org/wiki/Mem%C3%B3ria_(computador)" id="w">mem&oacute;ria</a> que os dados, podendo assim manipular tais programas. Esta arquitetura &eacute; um projeto modelo de um computador digital de programa armazenado que utiliza uma unidade de processamento (<a href="http://en.wikipedia.org/wiki/CPU" id="w">CPU</a>) e uma de armazenamento (&#34&semi;mem&oacute;ria&#34&semi;) para comportar, respectivamente, instru&ccedil;&otilde;es e dados.</p>&#10;<p>A m&aacute;quina proposta por Von Neumann re&uacute;ne os seguintes componentes: (i) uma <a href="http://en.wikipedia.org/wiki/Mem%C3%B3ria" id="w">mem&oacute;ria</a>, (ii) uma <a href="http://en.wikipedia.org/wiki/Unidade_aritm%C3%A9tica_e_l%C3%B3gica" id="w">unidade aritm&eacute;tica e l&oacute;gica</a> (ALU), (iii) uma <a href="http://en.wikipedia.org/wiki/Unidade_central_de_processamento" id="w">unidade central de processamento</a> (CPU), composta por diversos <a href="http://en.wikipedia.org/wiki/Registrador" id="w">registradores</a>, e (iv) uma Unidade de Controle (CU), cuja fun&ccedil;&atilde;o &eacute; a mesma da tabela de controle da <a href="http://en.wikipedia.org/wiki/M%C3%A1quina_de_Turing_universal" id="w">M&aacute;quina de Turing universal</a>: buscar um programa na mem&oacute;ria, instru&ccedil;&atilde;o por instru&ccedil;&atilde;o, e execut&aacute;&shy;lo sobre os <a href="http://en.wikipedia.org/wiki/Dados" id="w">dados</a> de <a href="http://en.wikipedia.org/wiki/Entrada/sa%C3%ADda" id="w">entrada</a>.</p>&#10;<p>Todos os elementos dessa arquitetura s&atilde;o alinhados da estrutura hardware do CPU, assim o sistema pode realizar todas as suas atividades sem apresentar erros no desempenho. Von Neumann &eacute; continuamente influenciado pela evolu&ccedil;&atilde;o tecnol&oacute;gica, tendo pe&ccedil;as mais modernas inseridas. Cada um dos elementos apresentados &eacute; realizado &agrave; custa de componentes f&iacute;sicos independentes, cuja implementa&ccedil;&atilde;o tem variado ao longo do tempo, consoante a evolu&ccedil;&atilde;o das tecnologias de fabrica&ccedil;&atilde;o, desde os rel&eacute;s electromagn&eacute;ticos, os tubos de v&aacute;cuo (ou <a href="http://en.wikipedia.org/wiki/V%C3%A1lvula_termoi%C3%B4nica" id="w">v&aacute;lvulas</a>), at&eacute; aos semicondutores, abrangendo os <a href="http://en.wikipedia.org/wiki/Transistor" id="w">transistores</a> e os circuitos eletr&ocirc;nicos integrados, com m&eacute;dia, alta ou muito alta densidade de integra&ccedil;&atilde;o (MSI &shy; <i>medium scale</i>, <a href="http://en.wikipedia.org/wiki/LSI" id="w">LSI</a> &shy; <i>large scale</i>, ou VLSI &shy; <i>very large scale integration</i>), medida em termos de milh&otilde;es transistores por <a href="http://en.wikipedia.org/wiki/Chip" id="w">pastilha</a> de sil&iacute;cio.</p>&#10;<p>As novas intera&ccedil;&otilde;es entre os elementos exibem tempos t&iacute;picos que tamb&eacute;m t&ecirc;m variado ao longo do tempo, consoante as tecnologias de fabrica&ccedil;&atilde;o. Atualmente, as <a href="http://en.wikipedia.org/wiki/CPU" id="w">CPUs</a> processam instru&ccedil;&otilde;es sob controlo de rel&oacute;gios cujos per&iacute;odos t&iacute;picos s&atilde;o da ordem de 1 nanosegundo, ou seja, <span class="math">10^{&shy;9}</span> segundos. As mem&oacute;rias centrais t&ecirc;m tempos t&iacute;picos de acesso da ordem da dezena de nanosegundos. As unidades de entrada e sa&iacute;da exibem tempos t&iacute;picos extremamente vari&aacute;veis, mas que s&atilde;o tipicamente muito superiores &agrave; escala do nanosegundo. Por exemplo, os <a href="http://en.wikipedia.org/wiki/Disco_r%C3%ADgido" id="w">discos r&iacute;gidos</a> exibem tempos da ordem dos milissegundos (mil&eacute;simo de segundo, <span class="math">10^{&shy;3}</span>). Outros dispositivos perif&eacute;ricos s&atilde;o inertes, a n&atilde;o ser que sejam ativados por utilizadores humanos. Por exemplo, ao se fazer &#34&semi;copy and paste&#34&semi; nao se&shy;percebe nada do que foi descrito acima, pois um <a href="http://en.wikipedia.org/wiki/Teclado_(computador)" id="w">teclado</a> s&oacute; envia informa&ccedil;&atilde;o para o computador ap&oacute;s serem pressionada as devidas teclas. Assim, este dispositivo se comunica com a <a href="http://en.wikipedia.org/wiki/CPU" id="w">CPU</a> eventualmente e, portanto, exibe tempos indeterminados.</p>&#10;<p>O modelo (ou arquitetura) de Von Neumann foi concebido a partir de 1946, quando John von Neumann e  sua equipe desenvolveram um novo projeto de &ldquo;computador de programa armazenado&rdquo;. Projetado pela IAS (Princeton Institute for Advanced Studies), este computador foi largamente difundido, influenciando muitos projetos subsequentes de outras m&aacute;quinas.</p>&#10;<a id="Descri%C3%A7%C3%A3o" name="Descri%C3%A7%C3%A3o"></a><h2>Descri&ccedil;&atilde;o</h2>&#10;&#10;<p>As primeiras m&aacute;quinas de computa&ccedil;&atilde;o tinham programas fixos. Alguns computadores muito simples ainda usam este projeto, quer para fins de simplicidade ou de forma&ccedil;&atilde;o. Por exemplo, uma calculadora de mesa (em princ&iacute;pio) &eacute; um programa de computador fixo. Ele pode fazer a matem&aacute;tica b&aacute;sica, mas n&atilde;o pode ser usado como um processador de texto ou um emulador de console de videogame. Alterar o programa de uma m&aacute;quina de programa fixo exige re&shy;liga&ccedil;&atilde;o, re&shy;estrutura&ccedil;&atilde;o ou re&shy;projetar a m&aacute;quina. Os primeiros computadores n&atilde;o eram t&atilde;o &#34&semi;programados&#34&semi;, como eles foram &#34&semi;desenhados&#34&semi;. Era um processo trabalhoso, come&ccedil;ando com fluxogramas e c&eacute;dulas de papel, seguido de desenhos detalhados de engenharia e, em seguida o processo muitas vezes penoso fisicamente de re&shy;liga&ccedil;&atilde;o e re&shy;constru&ccedil;&atilde;o da m&aacute;quina. Podendo levar tr&ecirc;s semanas para criar um programa no ENIAC e come&ccedil;ar a trabalhar.</p>&#10;<p>A ideia do computador de programa armazenado, mudou tudo isso: um computador que pelo projeto inclui um conjunto de instru&ccedil;&otilde;es e pode armazenar na mem&oacute;ria um conjunto de instru&ccedil;&otilde;es (programa) que detalha o c&aacute;lculo. Um projeto de programa armazenado tamb&eacute;m permite que os programas possam se  modificar durante a execu&ccedil;&atilde;o. Uma motiva&ccedil;&atilde;o precoce para uma instala&ccedil;&atilde;o desse tipo foi a necessidade de um programa para incrementar ou modificar a por&ccedil;&atilde;o do endere&ccedil;o das instru&ccedil;&otilde;es, o que tinha que ser feito manualmente em projetos adiantados. Isto tornou&shy;se menos importante quando registradores de &iacute;ndice e endere&ccedil;amento indireto foram as caracter&iacute;sticas usuais da arquitetura da m&aacute;quina. C&oacute;digo de Auto&shy;modifica&ccedil;&atilde;o foi amplamente ca&iacute;do em desuso, j&aacute; que normalmente &eacute; dif&iacute;cil de entender e depurar, bem como sendo ineficiente em pipelining processador moderno, e esquemas de cache.</p>&#10;<p>Em grande escala, a capacidade de tratar as instru&ccedil;&otilde;es como os dados &eacute; o que faz montadores, compiladores e outras ferramentas de programa&ccedil;&atilde;o automatizada poss&iacute;veis. Pode&shy;se &#34&semi;escrever programas que escrevem programas.&#34&semi; Em uma escala menor, instru&ccedil;&otilde;es de I / O da m&aacute;quina intensiva, como o BitBlt primitivos usados para modificar imagens em um display bitmap. Foi mostrado posteriormente que estas instru&ccedil;&otilde;es podem ser implementadas de forma eficiente por &#34&semi;na compila&ccedil;&atilde;o fly&#34&semi; (&#34&semi;just&shy;in&shy;time de compila&ccedil;&atilde;o) de tecnologia, por exemplo, gera&ccedil;&atilde;o de c&oacute;digo de programas, uma forma de c&oacute;digo de auto&shy;modifica&ccedil;&atilde;o que se manteve popular.</p>&#10;<p>H&aacute; desvantagens para a concep&ccedil;&atilde;o de von Neumann. Al&eacute;m do gargalo de von Neumann descrito abaixo, alterar o programa pode ser bastante prejudicial, quer por acidente ou design. Em alguns projetos simples computador de programa armazenado, um programa com defeito pode danificar outros programas, ou o sistema operacional, possivelmente levando a uma pane no computador. Prote&ccedil;&atilde;o de mem&oacute;ria e outras formas de controle de acesso. </p>&#10;<p>O matem&aacute;tico Alan Turing, que tinha sido alertado para um problema de l&oacute;gica matem&aacute;tica pelas palestras de Max Newman na Universidade de Cambridge, escreveu um artigo em 1936 intitulado On Computable Numbers, com um aplicativo para o Entscheidungsproblem, que foi publicado nos Anais da Sociedade Matem&aacute;tica de Londres. Nela, ele descreveu uma m&aacute;quina hipot&eacute;tica que ele chamou de &#34&semi;m&aacute;quina de computa&ccedil;&atilde;o universal&#34&semi;, e que agora &eacute; conhecida como a &#34&semi;m&aacute;quina de Turing universal&#34&semi;. A m&aacute;quina hipot&eacute;tica tinha um armazenamento infinito (mem&oacute;ria, na terminologia de hoje instru&ccedil;&otilde;es e dados). O engenheiro alem&atilde;o Konrad Zuse, independentemente escreveu sobre este conceito em 1936. John von Neumann tornou&shy;se familiarizado com Turing, quando ele era professor visitante na Universidade de Cambridge em 1935 e tamb&eacute;m durante o ano que Turing passou na Universidade de Princeton, em 1936&shy;1937.</p>&#10;<p>Von Neumann estava envolvido no Projeto Manhattan no Los Alamos National Laboratory, que exigiu enormes quantidades de c&aacute;lculo. Isso o levou para o projeto ENIAC, no ver&atilde;o de 1944. L&aacute; ele se juntou ao debate em curso sobre a concep&ccedil;&atilde;o deste computador de programa armazenado, o EDVAC. Como parte desse grupo, ele se ofereceu para escrever uma descri&ccedil;&atilde;o do mesmo. O termo &#34&semi;arquitetura de von Neumann&#34&semi; surgiu a partir de uma publica&ccedil;&atilde;o de von Neumann, o primeiro esbo&ccedil;o de um relat&oacute;rio sobre o EDVAC datado de 30 de junho de 1945, que inclu&iacute;a ideias de Eckert e Mauchly. O esbo&ccedil;o estava inacabado quando seu colega Herman Goldstine que circulou somente com o nome de von Neumann sobre ele, para a consterna&ccedil;&atilde;o de Eckert e Mauchly. O documento foi lido por dezenas de colegas de von Neumann nos Estados Unidos e Europa, influenciando a pr&oacute;xima rodada de modelos de computador.</p>&#10;<p>Ambas publica&ccedil;&otilde;es de von Neumann e Turing descreveram um programa armazenado para computadores, mas a publica&ccedil;&atilde;o de von Neumann alcan&ccedil;ou maior circula&ccedil;&atilde;o e a arquitetura do computador que ele exp&ocirc;s ficou conhecida como a &#34&semi;arquitetura de von Neumann&#34&semi;. Von Neumann foi, ent&atilde;o, o criador da arquitetura de programa armazenado, mas Jack Copeland considera que &eacute; &#34&semi;historicamente inadequado&#34&semi; referir&shy;se a eletr&ocirc;nica de programa armazenado e computadores digitais como &#34&semi;m&aacute;quinas de von Neumann&#34&semi;</p>&#10;<a id="Gargalo_de_von_Neumann" name="Gargalo_de_von_Neumann"></a><h2>Gargalo de von Neumann</h2>&#10;&#10;<p>O canal de transmiss&atilde;o de dados entre a CPU e a mem&oacute;ria leva ao gargalo de von Neumann, a troca de dados limitada (taxa de transfer&ecirc;ncia) entre a CPU e a mem&oacute;ria em rela&ccedil;&atilde;o &agrave; quantidade de mem&oacute;ria. Na maioria dos computadores modernos, a troca de dados entre o processador e a mem&oacute;ria &eacute; muito menor do que a taxa com que o processador pode trabalhar. Isso limita seriamente a velocidade eficaz de processamento, principalmente quando o processador &eacute; exigido para realizar o processamento de grandes quantidades de dados. A CPU &eacute; constantemente for&ccedil;ada a esperar por dados  que precisam ser transferidos para, ou a partir da, mem&oacute;ria. Como a velocidade da CPU e o tamanho da mem&oacute;ria t&ecirc;m aumentado muito mais rapidamente que a taxa de transfer&ecirc;ncia entre eles, o gargalo se tornou mais um problema, um problema cuja gravidade aumenta com cada gera&ccedil;&atilde;o de CPU.</p>&#10;<p>O termo &#34&semi;gargalo de von Neumann&#34&semi; foi cunhado por <a href="http://en.wikipedia.org/wiki/John_Backus" id="w">John Backus</a> em sua palestra Award 1977 ACM Turing. Segundo Backus:</p>&#10;<p /><blockquote>Certamente deve haver uma maneira menos primitiva de se fazer grandes altera&ccedil;&otilde;es na mem&oacute;ria, do que empurrando um grande n&uacute;mero de palavras, de um lado a outro, do gargalo de von Neumann. N&atilde;o &eacute; somente um gargalo literal para o tr&aacute;fego de dados, mas, o mais importante, &eacute; um gargalo intelectual que nos tem mantido atados a um pensamento de &#34&semi;uma palavra por vez&#34&semi; em vez de encorajar&shy;nos a pensar em termos unidades conceituais maiores. Assim, a programa&ccedil;&atilde;o &eacute; basicamente o planejamento e detalhamento do enorme tr&aacute;fego de palavras atrav&eacute;s do gargalo de von Neumann e grande parte desse tr&aacute;fego n&atilde;o diz respeito aos dados propriamente ditos, e sim a onde esses dados s&atilde;o encontrados.<sup id="_ref&shy;backus_a" class="reference"><a href="#_note&shy;backus" title="">[1]</a></sup></blockquote>&#10;&#10;<p>O problema de desempenho pode ser aliviado (at&eacute; certo ponto) por diversos mecanismos. Colocando uma mem&oacute;ria  cache entre o processador e a mem&oacute;ria principal, proporcionando caches separados com os caminhos de acesso separado para dados e instru&ccedil;&otilde;es (a chamada arquitetura <a href="http://en.wikipedia.org/wiki/Harvard_Modificada" id="w">Harvard Modificada</a>), utilizando um algor&iacute;tmo preditor de salto e l&oacute;gica. O problema tamb&eacute;m pode ser contornado usando um pouco de <a href="http://en.wikipedia.org/wiki/Computa%C3%A7%C3%A3o_paralela" id="w">computa&ccedil;&atilde;o paralela</a>, por exemplo a arquitetura NUMA, esta abordagem &eacute; geralmente utilizada em supercomputadores.</p>&#10;<a id="Primeiros_computadores_de_arquitetura_von_Neumann" name="Primeiros_computadores_de_arquitetura_von_Neumann"></a><h2> Primeiros computadores de arquitetura von Neumann </h2>&#10;<p>A Primeira Ideia (primeiro rascunho &shy; <i>First Draft</i>) descrevia um design de computador que foi usado por muitas universidades e corpora&ccedil;&otilde;es para construir seus computadores. <sup id="_ref&shy;2" class="reference"><a href="#_note&shy;2" title="">[2]</a></sup>  Dentre esses computadores, somente o ILLIAC e o ORDVAC possu&iacute;am instru&ccedil;&otilde;es compat&iacute;veis.</p>&#10;&#10;<ul>&#10;<li><a href="http://en.wikipedia.org/wiki/ORDVAC" id="w">ORDVAC</a> (U&shy;Illinois) @ Aberdeen Proving Ground, Maryland (completado em novembro de 1951<sup id="_ref&shy;3" class="reference"><a href="#_note&shy;3" title="">[3]</a></sup>)</li>&#10;<li><a href="http://en.wikipedia.org/wiki/IAS_machine" id="w">IAS machine</a> @ Princeton University (jan. de 1952)</li>&#10;<li><a href="http://en.wikipedia.org/wiki/MANIAC_I" id="w">MANIAC I</a> @ Los Alamos Scientific Laboratory (mar. 1952)</li>&#10;<li><a href="http://en.wikipedia.org/wiki/ILLIAC" id="w">ILLIAC</a> @ the University of Illinois, (set. 1952)</li>&#10;<li><a href="http://en.wikipedia.org/wiki/AVIDAC" id="w">AVIDAC</a> @ Argonne National Laboratory (1953)</li>&#10;<li><a href="http://en.wikipedia.org/wiki/ORACLE_(computer)" id="w">ORACLE</a> @ Oak Ridge National Laboratory (jun. 1953)</li>&#10;<li><a href="http://en.wikipedia.org/wiki/JOHNNIAC" id="w">JOHNNIAC</a> @ RAND Corporation (jan. 1954)</li>&#10;<li><a href="http://en.wikipedia.org/wiki/BESK" id="w">BESK</a> em Stockholm (1953)</li>&#10;<li><a href="http://en.wikipedia.org/wiki/BESM" id="w">BESM&shy;1</a> em Moscow (1952)</li>&#10;<li><a href="http://en.wikipedia.org/wiki/DASK" id="w">DASK</a> em Denmark (1955)</li>&#10;<li><a href="http://en.wikipedia.org/wiki/PERM_(computer)" id="w">PERM</a> em Munich (1956?)</li>&#10;<li><a href="http://en.wikipedia.org/wiki/SILLIAC" id="w">SILLIAC</a> em Sydney (1956)</li>&#10;<li><a href="http://en.wikipedia.org/wiki/WEIZAC" id="w">WEIZAC</a> em Rehovoth (1955)</li></ul>&#10;<p> </p>&#10;&#10;<p> </p>&#10;<p> </p>&#10;<p><a href="http://en.wikipedia.org/wiki/Categoria:Arquitetura_de_computadores" id="w">Categoria:Arquitetura de computadores</a>&#10;<a href="http://en.wikipedia.org/wiki/Categoria:Taxonomia_de_Flynn" id="w">Categoria:Taxonomia de Flynn</a>&#10;<a href="http://en.wikipedia.org/wiki/Categoria:Tipos_de_computadores" id="w">Categoria:Tipos de computadores</a></p>&#10;<p> </p></body></html>