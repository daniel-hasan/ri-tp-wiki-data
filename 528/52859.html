<html><title>RISC</title><body>&#10;<p> &#10; &#10; &#10; &#10;<b>Reduced Instruction Set Computer</b> ou <b>Computador com um Conjunto Reduzido de Instru&ccedil;&otilde;es</b> <b>(RISC)</b>, &eacute; uma linha de <a href="http://en.wikipedia.org/wiki/Arquitetura_de_processador" id="w">arquitetura de processadores</a> que favorece um conjunto simples e pequeno de <a href="http://en.wikipedia.org/wiki/Conjunto_de_instru%C3%A7%C3%B5es" id="w">instru&ccedil;&otilde;es</a> que levam aproximadamente a mesma quantidade de tempo para serem executadas. Muitos dos <a href="http://en.wikipedia.org/wiki/Microprocessadores" id="w">microprocessadores</a> modernos s&atilde;o RISCs, por exemplo <a href="http://en.wikipedia.org/wiki/DEC_Alpha" id="w">DEC Alpha</a>, <a href="http://en.wikipedia.org/wiki/SPARC" id="w">SPARC</a>, <a href="http://en.wikipedia.org/wiki/Arquitetura_MIPS" id="w">MIPS</a>, e <a href="http://en.wikipedia.org/wiki/PowerPC" id="w">PowerPC</a>. Os computadores atuais mixam as duas arquiteturas, criando o conceito de <a href="http://en.wikipedia.org/wiki/Arquitetura_h%C3%ADbrida" id="w">arquitetura h&iacute;brida</a>, incorporando os conceitos das duas arquiteturas e a inclus&atilde;o de um n&uacute;cleo RISC aos seus processadores. O tipo de microprocessador mais comum em desktops, o <a href="http://en.wikipedia.org/wiki/X86" id="w">x86</a>, &eacute; mais semelhante ao <a href="http://en.wikipedia.org/wiki/CISC" id="w">CISC</a> do que ao RISC, embora <a href="http://en.wikipedia.org/wiki/Circuito_integrado" id="w">chips</a> mais novos traduzam <a href="http://en.wikipedia.org/wiki/Instru%C3%A7%C3%B5es_x86" id="w">instru&ccedil;&otilde;es x86</a> baseadas em arquitetura <a href="http://en.wikipedia.org/wiki/CISC" id="w">CISC</a> em formas baseadas em arquitetura RISC mais simples, utilizando prioridade de execu&ccedil;&atilde;o.</p>&#10;<p>Os processadores baseados na computa&ccedil;&atilde;o de conjunto de instru&ccedil;&otilde;es reduzidas n&atilde;o t&ecirc;m <a href="http://en.wikipedia.org/wiki/Micro&shy;programa%C3%A7%C3%A3o" id="w">micro&shy;programa&ccedil;&atilde;o</a>, as instru&ccedil;&otilde;es s&atilde;o executadas diretamente pelo <a href="http://en.wikipedia.org/wiki/Hardware" id="w">hardware</a>. Como caracter&iacute;stica, esta arquitetura, al&eacute;m de n&atilde;o ter <a href="http://en.wikipedia.org/wiki/Microc%C3%B3digo" id="w">microc&oacute;digo</a>, tem o conjunto de instru&ccedil;&otilde;es reduzidas, bem como baixo n&iacute;vel de complexidade.</p>&#10;<p>A ideia foi inspirada pela descoberta de que muitas das caracter&iacute;sticas inclu&iacute;das na arquitetura tradicional de processadores para ganho de desempenho foram ignoradas pelos programas que foram executados neles. Mas o desempenho do processador em rela&ccedil;&atilde;o &agrave; <a href="http://en.wikipedia.org/wiki/Mem%C3%B3ria" id="w">mem&oacute;ria</a> que ele acessava era crescente. Isto resultou num n&uacute;mero de t&eacute;cnicas para otimiza&ccedil;&atilde;o do processo dentro do processador, enquanto ao mesmo tempo tentando reduzir o n&uacute;mero total de acessos &agrave; mem&oacute;ria.<sup id="_ref&shy;Flynn54_a" class="reference"><a href="#_note&shy;Flynn54" title="">[1]</a></sup></p>&#10;<p>RISC &eacute; tamb&eacute;m a arquitetura adotada para os processadores dos videogames modernos, que proporcionam um hardware extremamente dedicado somente &agrave; execu&ccedil;&atilde;o do jogo, tornando&shy;o muito mais r&aacute;pido em rela&ccedil;&atilde;o a micro computadores com mais recursos, embora com <a href="http://en.wikipedia.org/wiki/Processador_x86" id="w">processador x86</a>.</p>&#10;<a id="Hist%C3%B3ria" name="Hist%C3%B3ria"></a><h2> Hist&oacute;ria </h2>&#10;<p>Desde os primeiros momentos da ind&uacute;stria de computadores os cientistas dos principais fabricantes t&ecirc;m estudado m&eacute;todos e t&eacute;cnicas que possam aperfei&ccedil;oar o desempenho e a capacidade dos sistemas de computa&ccedil;&atilde;o.</p>&#10;<p>Alguns aspectos atribu&iacute;dos ao primeiro&shy;RISC: projetos marcados por volta de 1975 incluem as observa&ccedil;&otilde;es que os compiladores de mem&oacute;ria restritos da &eacute;poca eram freq&uuml;entemente incapazes de tirar proveito dos recursos destinados a facilitar a montagem manual de codifica&ccedil;&atilde;o, e que os modos de endere&ccedil;amento complexos levavam  muitos ciclos para executar devido aos exigidos acessos &agrave; mem&oacute;ria adicional. Foi alegado que tais fun&ccedil;&otilde;es seriam melhor executadas por sequ&ecirc;ncias de instru&ccedil;&otilde;es mais simples se isso poderia render implementa&ccedil;&otilde;es pequenas o suficiente para deixar espa&ccedil;o para muitos registros, reduzindo o n&uacute;mero de acessos &agrave; mem&oacute;ria lenta. Nestes projetos simples, a maioria das instru&ccedil;&otilde;es s&atilde;o de tamanho uniforme e estrutura semelhante, as opera&ccedil;&otilde;es aritm&eacute;ticas s&atilde;o restritas a registros de CPU e instru&ccedil;&otilde;es a carregar apenas separam e armazenam a mem&oacute;ria de acesso. Essas propriedades permitem um melhor balanceamento de est&aacute;gios no pipeline do que antes, fazendo pipelines RISC significativamente mais eficientes e permitindo que as freq&uuml;&ecirc;ncias de clock fossem mais altas.</p>&#10;<p>No in&iacute;cio da <a href="http://en.wikipedia.org/wiki/D%C3%A9cada_de_1980" id="w">d&eacute;cada de 1980</a>, surgiram v&aacute;rias pesquisas cujo desejo era de aumentar o desempenho do sistema de computa&ccedil;&atilde;o. Se o desejo era esse, deve&shy;se procurar aperfei&ccedil;oar o emprego das instru&ccedil;&otilde;es que consomem mais tempo de execu&ccedil;&atilde;o, e n&atilde;o se preocupar tanto com instru&ccedil;&otilde;es mais complexas que raramente s&atilde;o usadas.</p>&#10;<p>Ao longo das d&eacute;cadas em que &eacute; usado o computador, observa&shy;se que o hardware em geral, os processadores e a mem&oacute;ria, tem evolu&iacute;do mais rapidamente que o <a href="http://en.wikipedia.org/wiki/Software" id="w">software</a>.</p>&#10;<p>Por outro lado, a manuten&ccedil;&atilde;o e desenvolvimento de programas n&atilde;o evolu&iacute;ram em custo/benef&iacute;cio. Apesar de a todo o momento surgirem novas cria&ccedil;&otilde;es e lan&ccedil;amentos, isso acarreta um custo muito elevado. A manuten&ccedil;&atilde;o tamb&eacute;m pode ser um problema, pois os programas oferecidos pelos fabricantes est&atilde;o longe da aus&ecirc;ncia de falhas(<a href="http://en.wikipedia.org/wiki/Defeito_de_software" id="w">bugs</a>).</p>&#10;<p>Entre as pesquisas realizadas nessa &eacute;poca, podemos citar a de David Patterson. Juntamente com Carlos S&eacute;quin, ele publicou em 1982 [PATT82] um estudo mostrando o desempenho, os par&acirc;metros e elementos de linguagens de alto n&iacute;vel quando compiladas e executadas. Esse artigo descrevia uma nova arquitetura para um processador, propondo solucionar os problemas de desempenho e custo existentes nas arquiteturas complexas vigentes (CISC). Esta arquitetura foi chamada de RISC, porque criava um processador com pequeno conjunto de instru&ccedil;&otilde;es.</p>&#10;<p>Esse trabalho &eacute; usado como refer&ecirc;ncia para a avalia&ccedil;&atilde;o do comportamento dos programas de alto n&iacute;vel e seu desempenho din&acirc;mico, no qual os autores apresentaram resultados da compila&ccedil;&atilde;o e da execu&ccedil;&atilde;o de oito programas diferentes, quatro em linguagem Pascal e quatro em <a href="http://en.wikipedia.org/wiki/Linguagem_C" id="w">linguagem C</a>.</p>&#10;<p>As an&aacute;lises efetuadas de programas compilados por m&aacute;quinas de arquitetura CISC, mostraram que os compiladores n&atilde;o eram mais t&atilde;o espertos quanto os programadores <a href="http://en.wikipedia.org/wiki/Assembly" id="w">assembly</a> na busca de instru&ccedil;&otilde;es de m&aacute;quina complexas. O programa compilador utiliza pouco da grande quantidade de instru&ccedil;&otilde;es e dos modos de endere&ccedil;amento que est&atilde;o dispon&iacute;veis, pois parece ser dif&iacute;cil analisar o programa de alto n&iacute;vel.&#10;Por exemplo, para efetuar a soma entre dois operandos em uma m&aacute;quina com arquitetura CISC, sendo que um dos valores est&aacute; em um registrador e o outro na mem&oacute;ria, levar&aacute; um certo tempo gasto para calcular o endere&ccedil;o de acesso a mem&oacute;ria.&#10;J&aacute; em uma m&aacute;quina com arquitetura RISC, s&atilde;o usadas duas instru&ccedil;&otilde;es(diferente da arquitetura CISC que utiliza uma instru&ccedil;&atilde;o), mas como s&atilde;o instru&ccedil;&otilde;es mais simples, sua execu&ccedil;&atilde;o &eacute; bem mais r&aacute;pida fazendo com que seu tempo total seja menor.</p>&#10;<p>&Eacute; uma estrat&eacute;gia de desenvolvimento de CPU com base na percep&ccedil;&atilde;o de que simplificado (em oposi&ccedil;&atilde;o ao complexo) as instru&ccedil;&otilde;es podem proporcionar maior desempenho, se essa simplicidade permite a execu&ccedil;&atilde;o muito mais r&aacute;pida de cada instru&ccedil;&atilde;o. Um computador com base nesta estrat&eacute;gia &eacute; um computador com um reduzido conjunto de instru&ccedil;&otilde;es (tamb&eacute;m RISC). Existem muitas propostas de defini&ccedil;&otilde;es precisas, mas o termo est&aacute; sendo lentamente substitu&iacute;do pela arquitetura mais descritiva load&shy;store. Fam&iacute;lias bem conhecidas incluem RISC DEC Alpha, a AMD 29k, ARC, ARM, Atmel AVR, MIPS, PA&shy;RISC, Power (incluindo PowerPC), SuperH e SPARC.<sup id="_ref&shy;Fisher55_a" class="reference"><a href="#_note&shy;Fisher55" title="">[2]</a></sup></p>&#10;<a id="Caracter%C3%ADsticas_das_Arquiteturas_CISC" name="Caracter%C3%ADsticas_das_Arquiteturas_CISC"></a><h2> Caracter&iacute;sticas das Arquiteturas CISC </h2>&#10;<p>O nome CISC (Complex Instruction Set Computer) adv&eacute;m do fato de se considerar complexo um conjunto constitu&iacute;do de grande quantidade de instru&ccedil;&otilde;es, com m&uacute;ltiplos modos de endere&ccedil;amento, entre outras cr&iacute;ticas.&#10;Em uma &eacute;poca inicial da computa&ccedil;&atilde;o em que a mem&oacute;ria era cara e pequena e, por isso, os c&oacute;digos gerados pelos compiladores deveriam ser compactos e eficientes na execu&ccedil;&atilde;o.&#10;Dessa forma, os projetistas precisavam obter boa densidade do c&oacute;digo de m&aacute;quina, ou seja, cada instru&ccedil;&atilde;o deveria fazer muito, de modo que o programa completo tivesse poucas instru&ccedil;&otilde;es.</p>&#10;<p>O surgimento, em 1951, do conceito de microprograma&ccedil;&atilde;o facilitou o trabalho de projetar instru&ccedil;&otilde;es complexas, implementando&shy;as em microc&oacute;digo. O microc&oacute;digo reside em mem&oacute;ria de controle, podendo&shy;se acelerar a sua execu&ccedil;&atilde;o devido a essas mem&oacute;rias serem r&aacute;pidas. A cria&ccedil;&atilde;o de novas instru&ccedil;&otilde;es &eacute;, na maioria das vezes, quase sem custo e sem aumento de espa&ccedil;o, facilitando a implementa&ccedil;&atilde;o do conceito de fam&iacute;lias de processadores. Um bom exemplo disso &eacute; a arquitetura <a href="http://en.wikipedia.org/wiki/X86" id="w">x86</a>.&#10;Outra vantagem do emprego de microc&oacute;digo reside na rapidez da execu&ccedil;&atilde;o de instru&ccedil;&otilde;es que est&atilde;o armazenadas em mem&oacute;ria (mem&oacute;ria ROM de controle) bem mais r&aacute;pido que a mem&oacute;ria convencional.</p>&#10;<p>O primeiro sistema de computa&ccedil;&atilde;o lan&ccedil;ado com microc&oacute;digo e que originou, tamb&eacute;m, o conceito de fam&iacute;lia de computadores foi introduzido pela IBM em 1964, o Sistema IBM/360. Posteriormente, a DEC (Digital Equipament Corporation) introduziu sua fam&iacute;lia de PDP, mais tarde substitu&iacute;da pelo sistema VAX, um dos melhores exemplos de m&aacute;quina CISC.</p>&#10;<p>Pode&shy;se concluir que os projetistas de arquiteturas CISC consideram tr&ecirc;s aspectos b&aacute;sicos:&#10;</p>&#10;<ol>&#10;<li>&shy; uso de microc&oacute;digo&semi;</li>&#10;<li>constru&ccedil;&atilde;o de conjuntos com instru&ccedil;&otilde;es completas e eficientes (completeza no conjunto)&semi;</li>&#10;<li>cria&ccedil;&atilde;o de instru&ccedil;&otilde;es de m&aacute;quina de &ldquo;alto n&iacute;vel&rdquo;, ou seja, com complexidade semelhante &agrave; dos comandos de alto n&iacute;vel.</li></ol>&#10;<p>Colocados juntos, esses elementos do projeto nortearam a filosofia de constru&ccedil;&atilde;o de processadores CISC por longo tempo, como a fam&iacute;lia Intel x86, os processadores AMD K e, anteriormente, os sistemas IBM e VAX.&#10;Assim &eacute; que existem naqueles conjuntos instru&ccedil;&otilde;es poderosas, do tipo:&#10;</p>&#10;<ul>&#10;<li>CAS &shy; compare and swap operands (comparar valores e trocas operandos)</li>&#10;<li>RTR &shy; return and restore codes (retornar e restaurar c&oacute;digo)</li>&#10;<li>SWAP &shy; swap register words (trocar palavras dos registradores)</li></ul>&#10;<p>Em geral o desenvolvimento das arquiteturas CISC tende a seguir algumas regras b&aacute;sicas:&#10;</p>&#10;<ol>&#10;<li>Formato de dois operandos mais comum &ndash; instru&ccedil;&otilde;es com campos de origem e destino, como a instru&ccedil;&atilde;o: ADD CX, mem (subtrair o valor na mem&oacute;ria do valor no registrador CX e colocar resultado no registrador CX).</li>&#10;<li>Uso de modos registrador para registrador&semi; registrador para mem&oacute;ria e mem&oacute;ria para registrador.</li>&#10;<li>Uso de m&uacute;ltiplos modos de endere&ccedil;amento para a mem&oacute;ria, incluindo indexa&ccedil;&atilde;o para o caso de vetores.</li>&#10;<li>Instru&ccedil;&otilde;es com largura vari&aacute;vel, com a quantidade de bytes variando de acordo com o modo de endere&ccedil;amento utilizado.</li>&#10;<li>As instru&ccedil;&otilde;es requerem m&uacute;ltiplos ciclos de rel&oacute;gio para sua complexa execu&ccedil;&atilde;o, al&eacute;m do que a quantidade desses ciclos varia de acordo com a largura das instru&ccedil;&otilde;es. Por exemplo, se uma instru&ccedil;&atilde;o realiza mais de um acesso &agrave; mem&oacute;ria para buscar dois operandos, ent&atilde;o gasta mais ciclos do que outra que s&oacute; realiza um acesso.</li>&#10;<li>As instru&ccedil;&otilde;es requerem m&uacute;ltiplos ciclos de rel&oacute;gio para sua complexa execu&ccedil;&atilde;o, al&eacute;m do que a quantidade desses ciclos varia de acordo com a largura das instru&ccedil;&otilde;es. Por exemplo, se uma instru&ccedil;&atilde;o realiza mais de um acesso &agrave; mem&oacute;ria para buscar dois operandos, ent&atilde;o gasta mais ciclos do que outra que s&oacute; realiza um acesso.</li>&#10;<li>O <a href="http://en.wikipedia.org/wiki/Hardware" id="w">hardware</a> possui poucos registradores devido ao fato de possuir muitas instru&ccedil;&otilde;es com acesso &agrave; mem&oacute;ria e por causa da limita&ccedil;&atilde;o do espa&ccedil;o no chip usado para a mem&oacute;ria de controle.</li>&#10;<li>H&aacute; tamb&eacute;m registradores especializados, como o <a href="http://en.wikipedia.org/wiki/Registrador" id="w">registrador</a> de controle (flags...)&semi; de segmento para o ponteiro da pilha, para tratamento de interpreta&ccedil;&atilde;o e outros.</li></ol>&#10;<p>Como &eacute; usual acontecer em qualquer &aacute;rea da atividade humana, &eacute; raro que algum conceito ou tecnologia importante obtenha unanimidade entre pesquisadores, t&eacute;cnicos, projetistas e administradores. Este &eacute; o caso da arquitetura CISC, a qual sempre foi alvo de cr&iacute;ticas e coment&aacute;rios sobre desvantagens e problemas. Neste texto n&atilde;o cabe posicionamento por este ou aquele fato ou tecnologia, mas sim apresentar todos os elementos poss&iacute;veis das diversas tend&ecirc;ncias, no caso entre CISC e RISC. No entanto, para se compreender o surgimento de processadores com arquitetura RISC deve&shy;se analisar os eventuais problemas indicados para a arquitetura CISC, que levaram pesquisadores e projetistas de sistemas a criar uma alternativa, considerada por eles mais vantajosa.</p>&#10;<p>Para entender melhor as ra&iacute;zes do surgimento da filosofia RISC, pode&shy;se mencionar alguns pontos das arquiteturas CISC citados como problem&aacute;ticos por um dos criadores de m&aacute;quinas RISC, David Patterson, em um de seus artigos, induzindo ao projeto de processadores que pudessem, com sua especifica&ccedil;&atilde;o mais simples, reduzir ou eliminar os citados problemas. Na realidade, parece ter sido Patterson quem primeiro definiu as arquiteturas com muitas e poderosas instru&ccedil;&otilde;es de CISC e sua m&aacute;quina prot&oacute;tipo de RISC (o nome escolhido foi RISC&shy;1): &#10;</p>&#10;<ul>&#10;<li><b>Diferen&ccedil;as de velocidade entre mem&oacute;ria e processador</b> &ndash; no final da <a href="http://en.wikipedia.org/wiki/D%C3%A9cada_de_1970" id="w">d&eacute;cada de 1970</a>, a IBM verificou que essa diferen&ccedil;a era um problema em seus sistemas, algumas opera&ccedil;&otilde;es eram realizadas por programas, acarretando muitos acessos a uma mem&oacute;ria lenta. A solu&ccedil;&atilde;o encontrada foi criar novas instru&ccedil;&otilde;es de m&aacute;quina para executar tais opera&ccedil;&otilde;es, podendo&shy;se acreditar que esse foi o in&iacute;cio do aumento da quantidade de instru&ccedil;&otilde;es no CISC.</li></ul>&#10;&#10;<ul>&#10;<li><b>Emprego de microc&oacute;digo</b> &ndash; o surgimento e a real vantagem de custo/beneficio do emprego de microc&oacute;digo sobre programa&ccedil;&atilde;o diretamente no hardware induziram os projetistas a criar mais e mais instru&ccedil;&otilde;es, devido a facilidade e a flexibilidade decorrentes. Desenvolvimento acelerado de linguagens de alto n&iacute;vel &ndash; na <a href="http://en.wikipedia.org/wiki/D%C3%A9cada_de_1980" id="w">d&eacute;cada de 1980</a>, havia um crescimento acelerado do emprego de linguagens de alto n&iacute;vel, o que conduzia os projetistas de processadores a incluir cada vez mais instru&ccedil;&otilde;es de m&aacute;quinas em seus produtos, como o prop&oacute;sito de manter um suporte adequado na compila&ccedil;&atilde;o.</li></ul>&#10;&#10;<ul>&#10;<li><b>Densidade de c&oacute;digo a ser executado</b> &ndash; as arquiteturas CISC procuram obter um c&oacute;digo compacto ap&oacute;s a compila&ccedil;&atilde;o, de modo a n&atilde;o consumir mem&oacute;ria em excesso. Isso era necess&aacute;rio em uma &eacute;poca em que as mem&oacute;rias eram caras e de reduzindo tamanho. Construindo conjuntos de instru&ccedil;&otilde;es, cada uma delas mais pr&oacute;xima do significado do comando de alto n&iacute;vel, poder&shy;se&shy;ia obter c&oacute;digos execut&aacute;veis mais densos, mais compactos. Alega Patterson que isto acarretaria tamb&eacute;m mais bits nas instru&ccedil;&otilde;es (c&oacute;digos de opera&ccedil;&otilde;es com mais bits devido &agrave; quantidade delas, bem como mais modos de endere&ccedil;amento), o que contrabalan&ccedil;aria aquela pretensa vantagem.</li></ul>&#10;&#10;<ul>&#10;<li><b>Necessidade de compatibilidade com processadores anteriores</b> &ndash; uma das metas sempre seguida pela Intel e outros fabricantes foi a de conservar a compatibilidade entre as vers&otilde;es de seus processadores. Assim o processador <a href="http://en.wikipedia.org/wiki/486" id="w">486</a> veio com apenas algumas instru&ccedil;&otilde;es novas e todo o c&oacute;digo do <a href="http://en.wikipedia.org/wiki/386" id="w">386</a> junto, c&oacute;digos execut&aacute;veis para o 386 rodavam tamb&eacute;m no 486, e os usu&aacute;rios poderiam trocar de computador sem nenhum custo adicional de compila&ccedil;&atilde;o, etc. O mesmo aconteceu com o <a href="http://en.wikipedia.org/wiki/Pentium_II" id="w">Pentium I</a>, II, III e 4. Mesmo isso, embora seja um not&oacute;rio requisito importante de marketing, acarreta uma limita&ccedil;&atilde;o especifica&ccedil;&atilde;o de novas arquiteturas. Dessa forma, as arquiteturas novas s&oacute; crescem em quantidade de instru&ccedil;&otilde;es, visto que o fabricante nunca retira as instru&ccedil;&otilde;es antigas devido ao problema de compatibilidade.</li></ul>&#10;<a id="Filosofia_de_desenvolvimento_n%C3%A3o&shy;RISC" name="Filosofia_de_desenvolvimento_n%C3%A3o&shy;RISC"></a><h2> Filosofia de desenvolvimento n&atilde;o&shy;RISC </h2>&#10;<p>Nos primeiros dias da ind&uacute;stria de computadores, a programa&ccedil;&atilde;o era feita em linguagem assembly ou c&oacute;digo de m&aacute;quina, o que incentivou instru&ccedil;&otilde;es poderosas e f&aacute;ceis de usar. projetistas da CPU, portanto tentaram fazer as instru&ccedil;&otilde;es que iria fazer tanto trabalho quanto poss&iacute;vel. Com o advento das linguagens de alto n&iacute;vel, os arquitetos do computador tamb&eacute;m come&ccedil;aram a criar instru&ccedil;&otilde;es dedicadas a implementar diretamente alguns mecanismos centrais dessas linguagens. Outro objetivo geral foi o de fornecer todos os modos poss&iacute;veis de endere&ccedil;amento para cada instru&ccedil;&atilde;o, conhecido como ortogonalidade, para facilitar a implementa&ccedil;&atilde;o do compilador. As opera&ccedil;&otilde;es aritm&eacute;ticas podiam, portanto, ter muitas vezes resultados, bem como operandos diretamente na mem&oacute;ria (em adi&ccedil;&atilde;o ao registrador ou imediata).</p>&#10;<p>A atitude na &eacute;poca era que o desenvolvimento de hardware fosse mais maduro do que o projeto do compilador e que esta foi, em si tamb&eacute;m uma raz&atilde;o para implementar partes da funcionalidade do hardware ou microc&oacute;digo em vez de um compilador de mem&oacute;ria limitada (ou seu c&oacute;digo gerado) sozinho. Esta filosofia de design foi denominada de computa&ccedil;&atilde;o de conjunto complexo de instru&ccedil;&otilde;es (CISC ou <i>Complex Instruction Set Computing</i>), ap&oacute;s a filosofia RISC estar em cena. CPUs tamb&eacute;m tiveram registradores relativamente baixos, por v&aacute;rias raz&otilde;es:</p>&#10;&#10;<ul>&#10;<li>Mais registradores tamb&eacute;m implica uma maior economia de tempo e restaura&ccedil;&atilde;o de conte&uacute;do registrar na m&aacute;quina de pilha.</li>&#10;<li>Um grande n&uacute;mero de registradores requer um grande n&uacute;mero de bits de instru&ccedil;&atilde;o como especificadores de registo, ou seja, um c&oacute;digo menos denso. Registradores da CPU  s&atilde;o mais caros do que posi&ccedil;&otilde;es de mem&oacute;ria externa&semi; jogos de registo de grande porte foram pesados com placas de circuito limitado ou integra&ccedil;&atilde;o de chips.</li></ul>&#10;<p>Uma for&ccedil;a importante incentivar a complexidade era o fato das mem&oacute;rias principais serem muito limitadas (da ordem de kilobytes). Foi, portanto, vantajosa para a densidade de informa&ccedil;&otilde;es contidas em programas de computador a ser elevado, levando a caracter&iacute;sticas tais como alta codifica&ccedil;&atilde;o, instru&ccedil;&otilde;es de comprimento vari&aacute;vel, fazendo o carregamento de dados, bem como o c&aacute;lculo (como mencionado acima). Estas quest&otilde;es foram de maior prioridade que a facilidade de decodifica&ccedil;&atilde;o de instru&ccedil;&otilde;es.</p>&#10;<p>Uma raz&atilde;o igualmente importante foi que as mem&oacute;rias principais foram bastante lentas (um tipo comum foi a mem&oacute;ria de n&uacute;cleo de ferrite), usando a embalagem de informa&ccedil;&atilde;o densa, pode&shy;se reduzir a freq&uuml;&ecirc;ncia com que a CPU tinha de aceder a este recurso lento. Os computadores modernos mostram fatores de limita&ccedil;&atilde;o semelhantes: mem&oacute;rias principais s&atilde;o lentas em compara&ccedil;&atilde;o com o CPU e as mem&oacute;rias cache r&aacute;pidas empregadas para superar este s&atilde;o limitadas em tamanho. Isso pode explicar o fato de que conjuntos de instru&ccedil;&otilde;es altamente codificados tem provado ser t&atilde;o &uacute;til como projetos RISC em computadores modernos.</p>&#10;<a id="Filosofia_de_Desenvolvimento_RISC" name="Filosofia_de_Desenvolvimento_RISC"></a><h2> Filosofia de Desenvolvimento RISC </h2>&#10;<p>Em meados de 1970 investigadores (em especial John Cocke) da IBM (e projetos semelhantes em outros lugares) demonstraram que a maioria das combina&ccedil;&otilde;es desses modos ortogonais de endere&ccedil;amento e as instru&ccedil;&otilde;es n&atilde;o foram utilizados pela maioria dos programas gerados por compiladores dispon&iacute;veis no momento. Ele revelou&shy;se dif&iacute;cil em muitos casos, para escrever um compilador com mais que a capacidade limitada de tirar proveito dos recursos oferecidos pelos processadores convencionais.</p>&#10;<p>Tamb&eacute;m foi descoberto que, em implementa&ccedil;&otilde;es de arquiteturas microcodificadas, certas opera&ccedil;&otilde;es complexas tendem a ser mais lentas do que uma sequ&ecirc;ncia de opera&ccedil;&otilde;es mais simples fazendo a mesma coisa. Isso foi em parte um efeito do fato de que muitos projetos foram levados &agrave;s pressas, com pouco tempo para otimizar ou sintonizar todas as instru&ccedil;&otilde;es, mas sim apenas aquelas usadas com mais freq&uuml;&ecirc;ncia. Um exemplo famoso foi a instru&ccedil;&atilde;o do VAX de &iacute;ndice.</p>&#10;<p>Como mencionado anteriormente, a mem&oacute;ria de n&uacute;cleo h&aacute; muito havia sido mais lenta do que muitos projetos de CPU. O advento de mem&oacute;rias de semicondutores reduziu essa diferen&ccedil;a, mas ainda era aparente que mais registradores (e mais tarde caches) permitiria maior freq&uuml;&ecirc;ncia de opera&ccedil;&atilde;o da CPU. registros adicionais exigiriam chips importantes ou &aacute;reas bordo que, na &eacute;poca (1975), poderiam ser disponibilizados se a complexidade da l&oacute;gica de CPU havia sido reduzida.</p>&#10;<p>Contudo um outro impulso de ambos os RISC e outros projetos veio a partir de medi&ccedil;&otilde;es pr&aacute;ticas em programas no mundo real. <a href="http://en.wikipedia.org/wiki/Andrew_Tanenbaum" id="w">Andrew Tanenbaum</a> resumiu muitos destes, demonstrando que os processadores tiveram muitas vezes tamanhos desproporcionais imediatos. Por exemplo, ele mostrou que 98% de todas as constantes em um programa iriam caber em 13 bits, mas muitos projetos CPU dedicam de 16 ou 32 bits para armazen&aacute;&shy;los.</p>&#10;<p>Isto sugere que, para reduzir o n&uacute;mero de acessos &agrave; mem&oacute;ria, uma m&aacute;quina de comprimento fixo pode armazenar constantes em bits n&atilde;o utilizados da palavra de instru&ccedil;&atilde;o em si, de modo que eles seriam imediatamente prontos quando a CPU precisa deles (muito parecido com endere&ccedil;amento imediato em um desenho convencional). Estes necess&aacute;rios e pequenos <a href="http://en.wikipedia.org/wiki/Opcodes" id="w">opcodes</a>, ocorreram a fim de deixar espa&ccedil;o para uma constante com um tamanho razo&aacute;vel em uma palavra de instru&ccedil;&atilde;o de 32 bits.</p>&#10;<p>Uma vez que muitos programas do mundo real passam a maior parte do seu tempo executando opera&ccedil;&otilde;es simples, alguns pesquisadores decidiram concentrar em fazer as opera&ccedil;&otilde;es o mais r&aacute;pido poss&iacute;vel. A velocidade do <a href="http://en.wikipedia.org/wiki/Clock" id="w">clock</a> de uma CPU &eacute; limitado pelo tempo que leva para executar a mais lenta sub&shy;opera&ccedil;&atilde;o de qualquer instru&ccedil;&atilde;o, diminuindo o tempo de ciclo que, muitas vezes acelera a execu&ccedil;&atilde;o de outras instru&ccedil;&otilde;es. O foco na &#34&semi;instru&ccedil;&otilde;es reduzida&#34&semi; levou ao. resultando m&aacute;quina que est&aacute; sendo chamado de &#34&semi;computador conjunto reduzido de instru&ccedil;&otilde;es&#34&semi; (RISC). O objetivo era fazer instru&ccedil;&otilde;es t&atilde;o simples que poderiam ser facilmente e rapidamente processadas, a fim de aumentar o clock e atingir altas frequ&ecirc;ncias.</p>&#10;<p>Mais tarde verificou&shy;se que uma das caracter&iacute;sticas mais importantes dos processadores RISC &eacute; que a mem&oacute;ria externa s&oacute; era acess&iacute;vel por uma instru&ccedil;&atilde;o de armazenar carga. Todas as outras instru&ccedil;&otilde;es foram limitadas aos registos internos. Isso simplificou muitos aspectos do design do processador: permitir que as instru&ccedil;&otilde;es para ser de comprimento fixo, simplifica&ccedil;&atilde;o de condutas, e isolar a l&oacute;gica para lidar com o atraso na conclus&atilde;o de um acesso &agrave; mem&oacute;ria (cache miss, etc.) para apenas duas instru&ccedil;&otilde;es. Isso levou a RISC projetos que est&atilde;o sendo referidos como arquiteturas <i>load/store</i>.</p>&#10;<a id="Instru%C3%A7%C3%A3o_de_defini%C3%A7%C3%A3o_do_tamanho_e_terminologia_alternativa" name="Instru%C3%A7%C3%A3o_de_defini%C3%A7%C3%A3o_do_tamanho_e_terminologia_alternativa"></a><h2> Instru&ccedil;&atilde;o de defini&ccedil;&atilde;o do tamanho e terminologia alternativa </h2>&#10;<p>Um equ&iacute;voco comum da express&atilde;o &#34&semi;computador conjunto reduzido de instru&ccedil;&otilde;es&#34&semi; &eacute; a ideia de que as instru&ccedil;&otilde;es s&atilde;o simplesmente eliminadas, resultando em um menor conjunto de instru&ccedil;&otilde;es. De fato, ao longo dos anos, conjuntos de instru&ccedil;&otilde;es RISC cresceram em tamanho, e hoje muitos deles t&ecirc;m um conjunto maior de instru&ccedil;&otilde;es do que muitos processadores CISC. Alguns processadores RISC, como o Transputer INMOS t&ecirc;m conjuntos de instru&ccedil;&otilde;es t&atilde;o grandes como, por exemplo, o CISC IBM System/370 e, inversamente, o DEC PDP&shy;8 &shy; claramente uma CPU CISC porque muitas de suas instru&ccedil;&otilde;es envolvem m&uacute;ltiplos acessos &agrave; mem&oacute;ria &shy; tem apenas 8 instru&ccedil;&otilde;es b&aacute;sicas, al&eacute;m de algumas instru&ccedil;&otilde;es prorrogadas.</p>&#10;<p>O termo &#34&semi;redu&ccedil;&atilde;o&#34&semi; em que a frase foi concebido para descrever o fato que a quantidade de qualquer trabalho &uacute;nico a instru&ccedil;&atilde;o realizada &eacute; reduzida &shy; no m&aacute;ximo um ciclo de mem&oacute;ria de dados &uacute;nico &shy; em compara&ccedil;&atilde;o com as &#34&semi;instru&ccedil;&otilde;es complexas&#34&semi; do CISC CPUs que podem exigir dezenas de ciclos de mem&oacute;ria para executar uma &uacute;nica instru&ccedil;&atilde;o. Em particular, os processadores RISC geralmente t&ecirc;m instru&ccedil;&otilde;es separadas por I/O (input/output &shy; entrada/sa&iacute;da) e de processamento de dados&semi; consequentemente, os observadores da ind&uacute;stria come&ccedil;aram a utilizar os termos &#34&semi;registro&shy;registro&#34&semi; ou &#34&semi;carga armazenada &#34&semi;para descrever os processadores RISC.</p>&#10;<p>Alguns CPUs foram retroativamente apelidados RISC &shy; um artigo da revista Byte certa vez se referiu a <a href="http://en.wikipedia.org/wiki/6502" id="w">6502</a> como &#34&semi;o processador RISC original&#34&semi;, devido &agrave; sua instru&ccedil;&atilde;o simplistas e quase ortogonais (mais instru&ccedil;&otilde;es de trabalho, com a maioria dos modos de endere&ccedil;amento), bem como a sua 256 p&aacute;gina&shy;zero &#34&semi;registos&#34&semi;. O 6502 est&aacute; sem carga design do armazenamento no entanto: opera&ccedil;&otilde;es aritm&eacute;ticas pode ler a mem&oacute;ria e as instru&ccedil;&otilde;es de como INC ROL e at&eacute; mesmo modificar a mem&oacute;ria. Al&eacute;m disso, ortogonalidade &eacute; igualmente associada frequentemente com &#34&semi;CISC&#34&semi;. No entanto, o 6502 pode ser considerado semelhante ao RISC (m&aacute;quinas e precoce) no fato de que ele n&atilde;o usa sequ&ecirc;ncia de microc&oacute;digo. No entanto, o fato bem conhecido que a empresa empregava mais longos, por&eacute;m menos ciclos de clock em rela&ccedil;&atilde;o a muitos microprocessadores contempor&acirc;neos foi devido a um design mais ass&iacute;ncrono com menor subdivis&atilde;o de ciclos de m&aacute;quina interna. Isso &eacute; semelhante &agrave;s m&aacute;quinas de in&iacute;cio, mas n&atilde;o para RISC.</p>&#10;<p>Alguns processadores foram projetados especificamente para ter um conjunto muito pequeno de instru&ccedil;&otilde;es &shy; mas esses projetos s&atilde;o muito diferentes dos desenhos cl&aacute;ssicos RISC, para que eles tenham recebido outras denomina&ccedil;&otilde;es, tais como computador instru&ccedil;&atilde;o m&iacute;nima set (MISC), a Instru&ccedil;&atilde;o Zero Set Computer (ZISC), um conjunto de instru&ccedil;&otilde;es de computador (OISC), transporte acionado arquitetura (ATT), etc</p>&#10;<a id="Alternativas" name="Alternativas"></a><h2> Alternativas </h2>&#10;<p>RISC foi desenvolvida como uma alternativa ao que &eacute; hoje conhecido como CISC. Ao longo dos anos, outras estrat&eacute;gias foram implementadas como alternativa para o RISC e CISC. Alguns exemplos s&atilde;o a arquitetura <a href="http://en.wikipedia.org/wiki/VLIW" id="w">VLIW</a>, <a href="http://en.wikipedia.org/wiki/MISC" id="w">MISC</a>, <a href="http://en.wikipedia.org/wiki/OISC" id="w">OISC</a>, processamento paralelo maci&ccedil;o, matriz sist&oacute;lica, computa&ccedil;&atilde;o reconfigur&aacute;vel, e o fluxo de dados.</p>&#10;<a id="Caracter%C3%ADsticas_das_arquiteturas_RISC" name="Caracter%C3%ADsticas_das_arquiteturas_RISC"></a><h2> Caracter&iacute;sticas das arquiteturas RISC </h2>&#10;<p>Em meados de 1970 investigadores (em especial John Cocke) da IBM (e projetos semelhantes em outros lugares) demonstraram que a maioria das combina&ccedil;&otilde;es desses modos ortogonais de endere&ccedil;amento e as instru&ccedil;&otilde;es n&atilde;o foram utilizados pela maioria dos programas gerados por compiladores dispon&iacute;veis no momento. Ele revelou&shy;se dif&iacute;cil em muitos casos, para escrever um compilador com mais que a capacidade limitada de tirar proveito dos recursos oferecidos pelos processadores convencionais.</p>&#10;<p>Tamb&eacute;m foi descoberto que, em implementa&ccedil;&otilde;es de arquiteturas microcodificadas certas opera&ccedil;&otilde;es complexas tendem a ser mais lentas do que uma sequ&ecirc;ncia de opera&ccedil;&otilde;es mais simples fazendo a mesma coisa. Isso foi em parte um efeito do fato de que muitos projetos foram levados &agrave;s pressas, com pouco tempo para otimizar ou sintonizar todas as instru&ccedil;&otilde;es, mas sim apenas aquelas usadas com mais freq&uuml;&ecirc;ncia. Um exemplo famoso foi a instru&ccedil;&atilde;o do VAX de &iacute;ndice.</p>&#10;<p>Como mencionado anteriormente, a mem&oacute;ria de n&uacute;cleo h&aacute; muito havia sido mais lenta do que muitos projetos de CPU. O advento de mem&oacute;rias de semicondutores reduziu essa diferen&ccedil;a, mas ainda era aparente que mais registradores (e mais tarde caches) permitiria maior freq&uuml;&ecirc;ncia de opera&ccedil;&atilde;o da CPU. registros adicionais exigiriam chips importantes ou &aacute;reas bordo que, na &eacute;poca (1975), poderiam ser disponibilizados se a complexidade da l&oacute;gica de CPU havia sido reduzida.</p>&#10;<p>Contudo um outro impulso de ambos os RISC e outros projetos veio a partir de medi&ccedil;&otilde;es pr&aacute;ticas em programas no mundo real. <a href="http://en.wikipedia.org/wiki/Andrew_Tanenbaum" id="w">Andrew Tanenbaum</a> resumiu muitos destes, demonstrando que os processadores tiveram muitas vezes tamanhos desproporcionais imediatos. Por exemplo, ele mostrou que 98% de todas as constantes em um programa iriam caber em 13 bits, mas muitos projetos CPU dedicam de 16 ou 32 bits para armazen&aacute;&shy;los. Isto sugere que, para reduzir o n&uacute;mero de acessos &agrave; mem&oacute;ria, uma m&aacute;quina de comprimento fixo pode armazenar constantes em bits n&atilde;o utilizados da palavra de instru&ccedil;&atilde;o em si, de modo que eles seriam imediatamente prontos quando a CPU precisa deles (muito parecido com endere&ccedil;amento imediato em um desenho convencional). Estes necess&aacute;rios e pequenos opcodes, ocorreram a fim de deixar espa&ccedil;o para uma constante com um tamanho razo&aacute;vel em uma palavra de instru&ccedil;&atilde;o de 32 bits.</p>&#10;<p>Uma vez que muitos programas do mundo real passam a maior parte do seu tempo executando opera&ccedil;&otilde;es simples, alguns pesquisadores decidiram concentrar em fazer as opera&ccedil;&otilde;es o mais r&aacute;pido poss&iacute;vel. A velocidade do clock de uma CPU &eacute; limitado pelo tempo que leva para executar a mais lenta sub&shy;opera&ccedil;&atilde;o de qualquer instru&ccedil;&atilde;o, diminuindo o tempo de ciclo que, muitas vezes acelera a execu&ccedil;&atilde;o de outras instru&ccedil;&otilde;es. O foco na &#34&semi;instru&ccedil;&otilde;es reduzida&#34&semi; levou ao. resultando m&aacute;quina que est&aacute; sendo chamado de &#34&semi;computador conjunto reduzido de instru&ccedil;&otilde;es&#34&semi; (RISC). O objetivo era fazer com que as instru&ccedil;&otilde;es t&atilde;o simples que poderiam ser facil conduta, a fim de atingir uma capacidade de clock &uacute;nica em altas freq&uuml;&ecirc;ncias.</p>&#10;<p>Mais tarde verificou&shy;se que uma das caracter&iacute;sticas mais importantes dos processadores RISC &eacute; que a mem&oacute;ria externa s&oacute; era acess&iacute;vel por uma instru&ccedil;&atilde;o de armazenar carga. Todas as outras instru&ccedil;&otilde;es foram limitadas aos registos internos. Isso simplificou muitos aspectos do design do processador: permitir que as instru&ccedil;&otilde;es para ser de comprimento fixo, simplifica&ccedil;&atilde;o de condutas, e isolar a l&oacute;gica para lidar com o atraso na conclus&atilde;o de um acesso &agrave; mem&oacute;ria (cache miss, etc.) para apenas duas instru&ccedil;&otilde;es. Isso levou a RISC projetos que est&atilde;o sendo referidos como arquiteturas load / store.</p>&#10;<p>O resultado do trabalho de v&aacute;rios pesquisadores de diferentes locais, fez com que surgissem processadores com caracter&iacute;sticas bem diferentes dos j&aacute; conhecidos por CISC. Eles trabalhavam visando encontrar novas possibilidades para aperfei&ccedil;oar o desempenho dos processadores, usando caminhos diferentes dos adotados pela arquitetura CISC.&#10;Para o desenvolvimento de arquiteturas RISC, teve in&iacute;cio por tr&ecirc;s caminhos pr&oacute;ximos:</p>&#10;&#10;<ol>&#10;<li>O primeiro deles, foi em meados da <a href="http://en.wikipedia.org/wiki/D%C3%A9cada_de_1970" id="w">d&eacute;cada de 1970</a> com um projeto da IBM, desenvolvido pelo pesquisador daquela empresa: John Cocke. Esse projeto foi denominado IBM 801, o qual nem se tornou comercial, mas serviu de base para os desenvolvimentos seguintes da IBM nessa &aacute;rea.</li>&#10;<li>Anos depois em medos da <a href="http://en.wikipedia.org/wiki/D%C3%A9cada_de_1980" id="w">d&eacute;cada de 1980</a>, na Universidade de Stanford, na Calif&oacute;rnia, EUA, foi desenvolvida outra pesquisa pela equipe de John Hennessey [HENN84]. Esse projeto se tornou redundante nos processadores MIPS e na cria&ccedil;&atilde;o da empresa MIPS Technology Inc.</li>&#10;<li>Na mesma &eacute;poca (1980), na Universidade da Calif&oacute;rnia, EUA, foram desenvolvidas pesquisas muito semelhantes. Lideradas por David Patterson, foram criados os primeiros prot&oacute;tipos, RISC&shy;1 e RISC&shy;2, que acabaram se tornando base para o surgimento dos processadores SPARC.</li></ol>&#10;<p>Est&atilde;o descritos a seguir os elementos base que constituem a arquitetura RISC(Reduced Instruction Set Computer):&#10;&shy; pequeno conjunto de instru&ccedil;&otilde;es, todas com largura fixa&semi;&#10;&shy; execu&ccedil;&atilde;o otimizada de chamada de fun&ccedil;&atilde;o&semi;&#10;&shy; menor quantidade de modos de endere&ccedil;amento&semi;&#10;&shy; uso de pipelining&semi;&#10;&shy; execu&ccedil;&atilde;o r&aacute;pida de cada instru&ccedil;&atilde;o (uma a cada ciclo de clock).</p>&#10;<p><b>Menor quantidade de instru&ccedil;&otilde;es: </b> talvez a caracter&iacute;stica mais marcante das arquiteturas RISC, seja a de possuir um conjunto de instru&ccedil;&otilde;es menor(todas tamb&eacute;m com largura fixa), que as m&aacute;quinas que possu&iacute;am a arquitetura CISC, por&eacute;m com a mesma capacidade. Vem da&iacute; o nome dado a arquitetura RISC (computadores com um conjunto reduzido de instru&ccedil;&otilde;es). A SPARC, da Sun, possu&iacute;a um conjunto de cerca de 50 instru&ccedil;&otilde;es, a VAX&shy;11/780 tinha at&eacute; 300 instru&ccedil;&otilde;es, o Intel 80486 foi apresentado com 200 instru&ccedil;&otilde;es e os Pentium possuem mais de 200 instru&ccedil;&otilde;es.</p>&#10;<p>Com o conjunto de instru&ccedil;&otilde;es reduzido e cada uma delas tendo suas fun&ccedil;&otilde;es otimizadas, os sistemas possu&iacute;am um resultado melhor em quest&atilde;o de desempenho. Em virtude do conjunto reduzido das instru&ccedil;&otilde;es, acarretavam em programas um pouco mais longos.</p>&#10;<p>Mesmo assim, o conjunto de instru&ccedil;&otilde;es de m&aacute;quina reduzido, possibilitava outras vantagens, que entre elas podemos citar:&#10;&shy; Com uma menor quantidade de chips e transistores, conseq&uuml;entemente, o especo f&iacute;sico era maior com um custo reduzido&semi;</p>&#10;&shy; A redu&ccedil;&atilde;o da complexidade do decodificador de instru&ccedil;&otilde;es, reduz tamb&eacute;m o tempo de decodifica&ccedil;&atilde;o.&#10;&#10;<p>A busca pelas instru&ccedil;&otilde;es foi facilitada porque todas as instru&ccedil;&otilde;es possuem o mesmo tamanho em bits e alinhadas a largura da palavra. Por isso n&atilde;o &eacute; mais necess&aacute;rio verificar o tamanho do contador de instru&ccedil;&otilde;es, pois ele &eacute; incrementado sempre com o mesmo valor. Com isso, n&atilde;o tem risco da instru&ccedil;&atilde;o ocupar duas p&aacute;ginas de dados diferentes, porque traria problemas para o sistema operacional na hora do acesso.</p>&#10;<p><b>Execu&ccedil;&atilde;o otimizada de chamadas de fun&ccedil;&atilde;o: </b> outra evolu&ccedil;&atilde;o da arquitetura RISC para a arquitetura CISC tem rela&ccedil;&atilde;o com a chamada de retinas e passagem de par&acirc;metros. Estudos indicam que as chamadas de fun&ccedil;&otilde;es consomem um tempo significativo de processador. Elas requerem poucos dados, mas  demoram muito tempo nos acessos a mem&oacute;ria.</p>&#10;<p>Em virtude disso, na arquitetura RISC foram utilizados mais registradores. As chamadas de fun&ccedil;&atilde;o que na arquitetura CISC ocorriam com acessos a mem&oacute;ria, mas na RISC isso era feito dentro do processador mesmo, utilizando os registradores que foram colocados a mais.</p>&#10;<p><b>Modo de execu&ccedil;&atilde;o com Pipelining: </b> uma das caracter&iacute;sticas mais relevantes da arquitetura RISC &eacute; o uso de <a href="http://en.wikipedia.org/wiki/Pipeline_(hardware)" id="w">pipelining</a>, mesmo sabendo que ela tem um funcionamento mais efetivo quando as instru&ccedil;&otilde;es s&atilde;o todas bastante parecidas.</p>&#10;<p>Imaginando est&aacute;gios de uma linha de montagem, n&atilde;o &eacute; interessantes que um est&aacute;gio termine antes do outro, pois nesse caso perde&shy;se a vantagem da linha de montagem. O objetivo de cada instru&ccedil;&atilde;o, &eacute; completar um est&aacute;gio de pipeline em um ciclo de clock, mas esse objetivo nem sempre &eacute; alcan&ccedil;ado.</p>&#10;<p>O processamento de uma instru&ccedil;&atilde;o &eacute; composto pelo menos por cinco fases:&#10;</p>&#10;<ul>&#10;<li>Instruction fetch&semi;</li></ul>&#10;&#10;<ul>&#10;<li>Instruction decode&semi;</li>&#10;<li>Operand fetch&semi;</li>&#10;<li>Execution&semi;</li>&#10;<li>Write back.</li></ul>&#10;<p>Hoje em dia o pipeline n&atilde;o se limita a apenas 5 est&aacute;gios, mas pode chegar a 20 ou 30 est&aacute;gios (Intel Pentium 4).&#10;No entanto, para que todo o processo funcione &eacute; necess&aacute;rio que determinadas restri&ccedil;&otilde;es se verifiquem. A prioridade &eacute; que todas as instru&ccedil;&otilde;es permane&ccedil;am em cada est&aacute;gio o mesmo tempo, para que:</p>&#10;&#10;<ul>&#10;<li>O sinal de rel&oacute;gio seja usado como cad&ecirc;ncia de processamento&semi;</li>&#10;<li>N&atilde;o sejam necess&aacute;rios &ldquo;buffers&rdquo;&semi;</li></ul>&#10;<p>Execu&ccedil;&atilde;o de cada instru&ccedil;&atilde;o em um ciclo de clock: se o uso do pipelining se considera uma caracter&iacute;stica importante da arquitetura RISC, a execu&ccedil;&atilde;o de uma instru&ccedil;&atilde;o por ciclo de clock &eacute; mais importante, segundo os que estabeleceram suas bases.&#10;Um dos pontos mais negativos das arquiteturas RISC &eacute; o longo tempo de execu&ccedil;&atilde;o de cada instru&ccedil;&atilde;o. Com o surgimento dessa nova arquitetura, cada instru&ccedil;&atilde;o passou a ser executada a cada ciclo de clock.</p>&#10;&#10;<div style="page&shy;break&shy;inside:&#9;avoid&semi;">&#10;<table class="wikitable">&#10;<tr>&#10;<th>Caracter&iacute;sticas </th>&#10;<th>Considera&ccedil;&otilde;es</th></tr>&#10;<tr>&#10;<td>Menor quantidade de instru&ccedil;&otilde;es que as m&aacute;quinas CISC </td>&#10;<td>&bull; Simplifica o processo de cada instru&ccedil;&atilde;o e torna este item mais eficaz&semi;&#10;&#10;&#10;<ul>&#10;<li>Embora o processador RS/600 possua 184 instru&ccedil;&otilde;es, ainda assim &eacute; bem menos que as 303 instru&ccedil;&otilde;es dos sistemas VAX&shy;11. Al&eacute;m disso, a maioria das instru&ccedil;&otilde;es &eacute; realizada em 1 ciclo de clock, o que &eacute; considerado o objetivo maior dessa arquitetura.</li></ul></td></tr>&#10;<tr>&#10;<td>Execu&ccedil;&atilde;o otimizada de chamadas de fun&ccedil;&atilde;o </td>&#10;<td>&bull; As m&aacute;quinas RISC utilizam os registradores da UCP (em maior quantidade que os processadores CISC) para armazenar par&acirc;metros e vari&aacute;veis em chamadas de rotinas e fun&ccedil;&otilde;es. Os processadores CISC usam mais a mem&oacute;ria para a tarefa.</td></tr>&#10;<tr>&#10;<td>Menor quantidade de modos de endere&ccedil;amento</td>&#10;<td>&bull; As instru&ccedil;&otilde;es de processadores RISC s&atilde;o basicamente do tipo Load/Store, desvio e de opera&ccedil;&otilde;es aritm&eacute;ticas e l&oacute;gicas, reduzindo com isso seu tamanho.&#10;&#10;&#10;<ul>&#10;<li>A grande quantidade de modos de endere&ccedil;amento das instru&ccedil;&otilde;es de processadores CISC aumenta o tempo de execu&ccedil;&atilde;o das mesmas.</li></ul></td></tr>&#10;<tr>&#10;<td>Utiliza&ccedil;&atilde;o em larga escala de pipelining </td>&#10;<td>&bull; Um dos fatores principais que permite aos processadores RISC atingirem seu objetivo de completar a execu&ccedil;&atilde;o de uma instru&ccedil;&atilde;o pelo menos a cada ciclo de clock &eacute; o emprego de pipelining em larga escala.</td></tr></table></div>Tabela 1 &shy; <sup id="_ref&shy;3" class="reference"><a href="#_note&shy;3" title="">[3]</a></sup>&#10;&#10;<a id="RISC_Inicial" name="RISC_Inicial"></a><h2> RISC Inicial </h2>&#10;<p>O primeiro sistema que hoje seria conhecido como RISC era o supercomputador CDC 6600, projetado em 1964, uma d&eacute;cada antes que o termo foi inventado. O CDC 6600 tinha uma arquitetura load&shy;store, com apenas dois modos de endere&ccedil;amento (Registrar e registrar constante imediato) e 74 opcodes (enquanto um Intel 8086 tem 400). O 6600 tinha onze unidades funcionais pipeline para aritm&eacute;tica e l&oacute;gica, al&eacute;m de cinco unidades de carga e duas unidades de armazenamento, a mem&oacute;ria tinha bancos m&uacute;ltiplos assim todas as unidades de armazenamento de carga poderiam operar ao mesmo tempo. O ciclo de clock base / taxa de emiss&atilde;o de instru&ccedil;&atilde;o foi de 10 vezes mais r&aacute;pido que o tempo de acesso &agrave; mem&oacute;ria. Jim Thornton e Seymour Cray projetou como um processador central de processamento de n&uacute;meros, apoiados por 10 computadores simples, chamados de &#34&semi;processadores perif&eacute;ricos&#34&semi; para lidar com I / O e outras fun&ccedil;&otilde;es do sistema operacional. Assim, o coment&aacute;rio de brincadeira depois que a sigla RISC realmente significava &#34&semi; Realmente Inventado por Seymour Cray.</p>&#10;<p>Outra m&aacute;quina de armazenar carga inicial foi o minicomputador Data General Nova, projetada em 1968 por Edson de Castro. Tinha um conjunto de instru&ccedil;&otilde;es RISC quase puro, muito semelhante ao dos processadores ARM de hoje, por&eacute;m, n&atilde;o foi citado como tendo influenciado os designers ARM, embora Novas estavam em uso na Universidade de Cambridge, Laborat&oacute;rio de Inform&aacute;tica no in&iacute;cio de 1980.</p>&#10;<p>A primeira tentativa de fazer um chip baseado em RISC CPU era um projeto da IBM, que come&ccedil;ou em 1975. Nomeando ap&oacute;s o edif&iacute;cio onde funcionou o projeto, o trabalho levou &agrave; fam&iacute;lia de processadores IBM 801, que foi amplamente utilizado no interior de hardware da IBM. O 801 acabou por ser produzida em uma &uacute;nica forma de chip como o ROMP, em 1981, que era para &#39&semi;Pesquisa OPD [Office Products Division] micro processador. Como o nome indica, este processador foi projetado para &#34&semi;mini&#34&semi; tarefas, e quando a IBM lan&ccedil;ou o IBM RT&shy;PC baseado no projeto em 1986, o desempenho n&atilde;o era aceit&aacute;vel. No entanto, o 801 inspirado v&aacute;rios projectos de investiga&ccedil;&atilde;o, incluindo novos na IBM que acabaria por levar &agrave; sua rede el&eacute;ctrica.</p>&#10;<p>A maioria dos projetos p&uacute;blicos RISC, no entanto, foram os resultados dos programas de universidade de pesquisa executado com financiamento do Programa de VLSI DARPA. O Programa de VLSI, hoje praticamente desconhecido, levou a um grande n&uacute;mero de avan&ccedil;os no design de chips, fabrica&ccedil;&atilde;o, gr&aacute;ficos e at&eacute; mesmo um computador.</p>&#10;<p>Projeto UC Berkeley RISC come&ccedil;ou em 1980 sob a dire&ccedil;&atilde;o de David Patterson e Carlo H. Lantejoula, com base no ganho de desempenho atrav&eacute;s da utiliza&ccedil;&atilde;o de pipelining e um uso agressivo de uma t&eacute;cnica conhecida como registro de janelas. Em uma CPU normal tem um pequeno n&uacute;mero de registros, e um programa pode usar qualquer registro a qualquer momento. Em uma CPU com o registro de Janelas, h&aacute; um grande n&uacute;mero de registros, por exemplo, 128, mas os programas podem usar apenas um pequeno n&uacute;mero deles, por exemplo, 8, a qualquer momento. Um programa que limita&shy;se a 8 registros por procedimento pode fazer chamadas de procedimento muito r&aacute;pido: A chamada simplesmente move a janela &#34&semi;para baixo&#34&semi; por 8, para o conjunto de 8 registros utilizados por esse procedimento, e o retorno move a janela traseira. (Em um CPU normal, a maioria das chamadas deve poupar pelo menos os valores poucos registros &#39&semi;para a pilha, a fim de utilizar esses registos como espa&ccedil;o de trabalho, e restaurar os valores de retorno).</p>&#10;<p>O projeto RISC entregou o processador RISC&shy;I em 1982. Composta de apenas 44.420 transistores (em compara&ccedil;&atilde;o com as m&eacute;dias de cerca de 100 mil em projetos novos CISC da &eacute;poca) RISC eu tinha apenas 32 instru&ccedil;&otilde;es, e ainda completamente superado qualquer outro projeto de chip &uacute;nico. Eles seguiram para o transistor 40.760, de 39 anos instru&ccedil;&otilde;es RISC&shy;II, em 1983, que decorreu ao longo de tr&ecirc;s vezes mais r&aacute;pido que RISC&shy;I.</p>&#10;<p>Na mesma &eacute;poca, John L. Hennessy come&ccedil;ou um projeto semelhante chamado MIPS na Universidade de Stanford em 1981. MIPS centrou&shy;se quase inteiramente sobre o gasoduto, certificando&shy;se que poderia ser executado como &#34&semi;completa&#34&semi; poss&iacute;vel. Embora pipelining j&aacute; estava em uso em outros projetos, v&aacute;rias caracter&iacute;sticas do chip MIPS fez seu pipeline muito mais r&aacute;pido. O mais importante, e talvez chato, desses recursos foi a exig&ecirc;ncia de que todas as instru&ccedil;&otilde;es de ser capaz de concluir em um ciclo. Essa exig&ecirc;ncia permitiu que o pipeline para ser executado em taxas de dados muito maior (n&atilde;o houve necessidade de atrasos induzidos) e &eacute; respons&aacute;vel por muito do desempenho do processador. No entanto, tamb&eacute;m teve o efeito colateral negativo de elimina&ccedil;&atilde;o de muitas instru&ccedil;&otilde;es potencialmente &uacute;teis, como uma multiplica&ccedil;&atilde;o ou uma divis&atilde;o.</p>&#10;<p>Nos primeiros anos, os esfor&ccedil;os RISC eram bem conhecidos, mas confinado aos laborat&oacute;rios universit&aacute;rios, que havia criado. O esfor&ccedil;o de Berkeley tornou&shy;se t&atilde;o conhecido que acabou se tornando o nome de todo o conceito. Muitos na ind&uacute;stria de inform&aacute;tica criticou que os benef&iacute;cios de desempenho foram pouco prov&aacute;vel que se traduzem em ajustes do mundo real, devido &agrave; diminui&ccedil;&atilde;o da efici&ecirc;ncia da mem&oacute;ria de v&aacute;rias instru&ccedil;&otilde;es, e que essa foi a raz&atilde;o que ningu&eacute;m estava usando. Mas a partir de 1986, todos os projetos de pesquisa RISC come&ccedil;aram a entregar os produtos.</p>&#10;<a id="RISC_posterior" name="RISC_posterior"></a><h2> RISC posterior </h2>&#10;<p>A pesquisa de Berkeley n&atilde;o estava diretamente comercializada, mas o projeto RISC&shy;II foi usado pela Sun Microsystems para desenvolver o SPARC, pela Pyramid tecnologia para desenvolver sua linha de m&aacute;quinas de gama m&eacute;dia, multi&shy;processador, e em quase todas as outras empresas, alguns anos depois. Foi o uso da Sun de um chip RISC em suas novas m&aacute;quinas, que demonstrou que os benef&iacute;cios do RISC eram reais, e as suas m&aacute;quinas rapidamente ultrapassou a concorr&ecirc;ncia e, essencialmente, assumiu o mercado de workstations inteiro.</p>&#10;<p>John Hennessy deixou Stanford (temporariamente) para comercializar o projeto MIPS, come&ccedil;ando a companhia conhecida como MIPS Computer Systems. Seu primeiro projeto foi uma segunda gera&ccedil;&atilde;o de chips MIPS conhecido como o R2000. projetos MIPS passou a se tornar um dos chips RISC mais utilizada quando foram inclu&iacute;dos na PlayStation e Nintendo 64 consoles de jogos. Hoje eles s&atilde;o um dos processadores mais comuns embutidos em uso para aplica&ccedil;&otilde;es high&shy;end.</p>&#10;<p>IBM aprendeu com o fracasso RT&shy;PC e passou a projetar o RS/6000 com base na sua nova arquitetura POWER. Ela, ent&atilde;o, mudou seu sistema AS/400 existentes para chips POWER, e encontrou para sua surpresa que, mesmo o conjunto de instru&ccedil;&otilde;es muito complexas correu consideravelmente mais r&aacute;pido. Power tamb&eacute;m iria encontrar&shy;se em movimento &#34&semi;para baixo&#34&semi; na escala para produzir o desenho PowerPC, o que elimina muitos dos &#34&semi;IBM apenas&#34&semi; instru&ccedil;&otilde;es e criou uma aplica&ccedil;&atilde;o de um &uacute;nico chip. Hoje, o PowerPC &eacute; um dos CPUs mais comumente usados para aplica&ccedil;&otilde;es automotivas (alguns carros t&ecirc;m mais de 10 deles no interior). Foi tamb&eacute;m o CPU utilizado em m&aacute;quinas Apple Macintosh 1994&shy;2006. (A partir de fevereiro de 2006, a Apple mudou sua linha de produ&ccedil;&atilde;o principal para processadores Intel x86).</p>&#10;<p>Quase todos os outros fabricantes rapidamente se juntou. Do Reino Unido esfor&ccedil;os de pesquisa, resultou na transputer INMOS, a Acorn Archimedes e do Advanced RISC Machine line, que &eacute; um enorme sucesso hoje. Empresas com projetos existentes CISC tamb&eacute;m rapidamente se juntaram &agrave; revolu&ccedil;&atilde;o. Intel lan&ccedil;ou o i860 e i960 pelo final dos anos 1980, embora n&atilde;o tenham sido muito bem sucedida. Motorola construiu um novo projeto chamado de 88.000 em homenagem ao seu famoso CISC 68000, mas viu quase nenhum recurso, e, eventualmente, abandonou e se juntou a IBM para produzir o PowerPC. A AMD lan&ccedil;ou o seu 29000, que viria a se tornar o mais popular de projeto RISC do in&iacute;cio de 1990.</p>&#10;<p>Hoje a grande maioria de todas as CPUs de 32 bits em uso s&atilde;o CPUs RISC e microcontroladores. t&eacute;cnicas de projeto RISC oferece pot&ecirc;ncia mesmo em tamanhos pequenos, e assim tornou&shy;se dominante para a baixa pot&ecirc;ncia processadores de 32 bits. Sistemas embarcados s&atilde;o, de longe o maior mercado de processadores: enquanto que uma fam&iacute;lia pode possuir um ou dois PCs, telefones de seu carro (s), celulares e outros dispositivos que podem conter um total de dezenas de processadores embarcados. RISC tamb&eacute;m tinha tomado conta do mercado de esta&ccedil;&otilde;es de trabalho maior para muito dos <a href="http://en.wikipedia.org/wiki/D%C3%A9cada_de_1990" id="w">anos 90</a> (at&eacute; a retomada pelo baixo custo de solu&ccedil;&otilde;es baseadas em PC). Ap&oacute;s o lan&ccedil;amento do Sun SPARCstation os outros vendedores se apressaram para concorrer com solu&ccedil;&otilde;es RISC pr&oacute;pria. O mercado hoje servidor high&shy;end &eacute; quase totalmente RISC [carece de fontes?], E o 1 &ordm; lugar entre os supercomputadores a partir de 2008 [atualiza&ccedil;&atilde;o] &eacute; realizada pelo sistema da IBM Roadrunner, que usa processadores Power Architecture baseado Cell para oferecer parte de seu poder de computa&ccedil;&atilde;o, embora muitos outros supercomputadores usam processadores x86 CISC vez.</p>&#10;<a id="RISC_e_%5B%5Bx86%5D%5D" name="RISC_e_%5B%5Bx86%5D%5D"></a><h2> RISC e [[x86]] </h2>&#10;<p>No entanto, apesar de muitos sucessos, RISC tem feito poucas incurs&otilde;es  no PC desktop e servidor mercados de commodities, onde a plataforma Intel x86 continua a ser a arquitetura do processador dominante. Existem tr&ecirc;s raz&otilde;es principais para isso:</p>&#10;<p><b>1</b>. A base muito grande de aplica&ccedil;&otilde;es do PC propriet&aacute;rios s&atilde;o escritos para 86, enquanto que nenhuma plataforma RISC tem uma base semelhante instalado, e isto significava usu&aacute;rios de PC foram fechados na 86.</p>&#10;<p><b>2</b>. Embora RISC era de fato capaz de ampliar em muito o desempenho r&aacute;pido e barato, a Intel se aproveitou de seu grande mercado gastando vastas quantias de dinheiro sobre o desenvolvimento do processador. Intel poderia gastar muitas vezes, tanto quanto qualquer fabricante RISC de melhorar o projeto e fabrica&ccedil;&atilde;o de baixo n&iacute;vel. O mesmo n&atilde;o pode ser dito sobre as empresas menores, como Cyrix e NexGen, mas eles perceberam que poderiam aplicar (bem) pr&aacute;ticas de design de conduta tamb&eacute;m para a arquitetura x86, como nos 486 e Pentium. A s&eacute;rie 6x86 MII e fez exatamente isso, mas era mais avan&ccedil;ada, implementou execu&ccedil;&atilde;o especulativa superescalar atrav&eacute;s do registo de renomea&ccedil;&atilde;o, diretamente no n&iacute;vel 86&shy;sem&acirc;ntico. Outros, como o AMD K5 Nx586 e fez o mesmo, mas indiretamente, via buffering microc&oacute;digo din&acirc;mica e semi&shy;independente de agendamento superescalares e instru&ccedil;&atilde;o expedi&ccedil;&atilde;o ao n&iacute;vel micro&shy;opera&ccedil;&atilde;o (mais velhos ou mais simples &#34&semi;CISC&#34&semi; projetos normalmente executa sequ&ecirc;ncias r&iacute;gidas micro&shy;opera&ccedil;&atilde;o diretamente). O primeiro chip de buffer dispon&iacute;vel implanta&ccedil;&atilde;o dessas din&acirc;micas e t&eacute;cnicas de programa&ccedil;&atilde;o foi o Nx586 NexGen, lan&ccedil;ado em 1994, o AMD K5 foi severamente adiado e lan&ccedil;ado em 1995.</p>&#10;<p><b>3</b>. Mais tarde, os processadores mais poderosos, como Intel P6, AMD K6, AMD K7, Pentium 4, etc. buffering semelhantes, utilizavam din&acirc;micas e princ&iacute;pios de programa&ccedil;&atilde;o e execu&ccedil;&atilde;o superescalar flex&iacute;vel (e especulativa) realiza&ccedil;&atilde;o de opera&ccedil;&atilde;o de micro&shy;sequ&ecirc;ncias geradas a partir de 86 paralelos diversos est&aacute;gios de decodifica&ccedil;&atilde;o. Hoje, essas ideias foram aperfei&ccedil;oadas (cerca de 86 pares em vez disso s&atilde;o fundidas numa mais complexa opera&ccedil;&atilde;o de micro, por exemplo) e ainda s&atilde;o usados pelos processadores x86 modernos, tais como Intel Core 2 e AMD K8.</p>&#10;<p>Enquanto os primeiros projetos RISC foram significativamente diferentes designs contempor&acirc;neos CISC, em 2000 o maior desempenho em CPUs da linha RISC eram quase indistingu&iacute;veis dos CPUs mais eficientes da linha CISC.</p>&#10;<p>Um n&uacute;mero de fornecedores, incluindo a Qualcomm, est&atilde;o tentando entrar no mercado de computadores com dispositivos baseados em ARM apelidado smartbooks, cavalgando a tend&ecirc;ncia de netbooks e crescente aceita&ccedil;&atilde;o das distribui&ccedil;&otilde;es Linux, um n&uacute;mero que j&aacute; constr&oacute;i ARM. Outras empresas est&atilde;o optando por usar o Windows CE.</p>&#10;<a id="RISC_X_CISC" name="RISC_X_CISC"></a><h2> RISC X CISC </h2>&#10;<p>Embora haja manualmente um n&uacute;mero razo&aacute;vel de adeptos das m&aacute;quinas que possuem arquiteturas RISC, tamb&eacute;m h&aacute;, e em grande quantidade, aqueles que relacionam diversas desvantagens desses processadores, advogando em favor da arquitetura CISC.&#10;V&aacute;rios podem ser os temas para discuss&atilde;o sobre RISC e CISC, um dos quais se refere ao desempenho do processador na execu&ccedil;&atilde;o de um programa. De modo geral, os vendedores e outros pesquisadores tendem a medir o desempenho atrav&eacute;s de programas de teste (benchmarks). No entanto, os referidos programas possuem uma s&eacute;rie de complica&ccedil;&otilde;es na interpreta&ccedil;&atilde;o de seus resultados em fun&ccedil;&atilde;o do tipo de ambiente que utilizaram e da natureza dos testes.</p>&#10;<p>Os defensores da arquitetura CISC propugnam que instru&ccedil;&otilde;es mais complexas resultar&atilde;o em um c&oacute;digo&shy;objeto menor, o que reduz um consumo de mem&oacute;ria, com reflexos no custo do sistema.&#10;Isso n&atilde;o &eacute; necessariamente correto se considerarmos que uma menor quantidade de instru&ccedil;&otilde;es nem sempre acarreta menor quantidade de bits (e &eacute; a quantidade efetiva de bits que consome menos mem&oacute;ria e a menor custo). Se cada instru&ccedil;&atilde;o CISC possuir mais operandos que as instru&ccedil;&otilde;es RISC e se cada um de seus operandos ocupar uma boa quantidade de bits na instru&ccedil;&atilde;o, ent&atilde;o poderemos ter um programa CISC maior em bits do que um programa em m&aacute;quina RISC, apesar de o programa para o processador RISC possuir maior quantidade de instru&ccedil;&otilde;es.</p>&#10;<p>Por exemplo, um programa escrito para rodar em um processador CISC pode gastar 150 instru&ccedil;&otilde;es de m&aacute;quina&semi; cada uma das instru&ccedil;&otilde;es possui c&oacute;digo de opera&ccedil;&atilde;o de 8 bits, podendo ser de um, dois, e tr&ecirc;s operandos. Cada campo operando ocupa 18 bits e ainda h&aacute; um campo para outras a&ccedil;&otilde;es, com 4 bits de tamanho. Em m&eacute;dia, as instru&ccedil;&otilde;es t&ecirc;m um total de 50 bits. Um programa para realizar o mesmo problema, escrito para rodar em um processador RISC, pode ter 220 instru&ccedil;&otilde;es, que em m&eacute;dia ocupam 32 bits.&#10;As instru&ccedil;&otilde;es s&atilde;o, em sua esmagadora maioria, de dois operandos, por&eacute;m os operandos s&atilde;o valores em registradores e, por isso, as instru&ccedil;&otilde;es n&atilde;o consomem muitos bits para endere&ccedil;ar os dois registradores.&#10;O programa para a m&aacute;quina CISC gastaria 7.500 bits, enquanto o programa para a m&aacute;quina RISC, mesmo possuindo mais 70 instru&ccedil;&otilde;es que o processador CISC, consumiria 7.040 bits.</p>&#10;<p>Os defensores da arquitetura CISC alegam que estas m&aacute;quinas executam mais rapidamente os programas escritos em linguagem de alto n&iacute;vel devido &agrave; pouca quantidade de c&oacute;digos bin&aacute;rios execut&aacute;veis. No entanto, o tempo que cada instru&ccedil;&atilde;o leva para ser executada nem sempre conduz &agrave; confirma&ccedil;&atilde;o dessa assertiva.&#10;M&aacute;quinas RISC, tendem a executar instru&ccedil;&otilde;es bem mais r&aacute;pido por que:</p>&#10;<p>a)As instru&ccedil;&otilde;es possuem C.Op. com menor quantidade de bits e, portanto, o tempo de decodifica&ccedil;&atilde;o &eacute; menor que o das maquinas CISC&semi;</p>&#10;<p>b)As instru&ccedil;&otilde;es s&atilde;o executadas diretamente pelo hardware e n&atilde;o por um microprograma. M&aacute;quinas RISC n&atilde;o s&atilde;o microprogramadas e, assim, tendem a executar as instru&ccedil;&otilde;es de modo mais r&aacute;pido.</p>&#10;<p>Processadores RISC s&atilde;o tamb&eacute;m otimizados para opera&ccedil;&otilde;es de uma &uacute;nica tarefa devido ao grande n&uacute;mero de registradores que possuem e &agrave; grande quantidade de est&aacute;gios de pipelining. A melhor maneira de obter um bom desempenho dos processadores RISC &eacute; executar um programa de teste (um benchmark), o qual possui exatamente esta caracter&iacute;stica: um grande n&uacute;mero de opera&ccedil;&otilde;es similares, em uma &uacute;nica tarefa.&#10;Neste ponto, e antes de serem apresentados alguns exemplos de arquiteturas cl&aacute;ssicas RISC, deve&shy;se observar que a discuss&atilde;o e o detalhamento de caracter&iacute;sticas de processadores que seguem a filosofia CISC e os que seguem a filosofia RISC s&atilde;o atualmente em menos cr&iacute;tica do que foi em anos anteriores, quando havia realmente uma n&iacute;tida distin&ccedil;&atilde;o entre ambas.&#10;Com o passar do tempo, o avan&ccedil;o da tecnologia em hardware, modificou a vis&atilde;o de alguns projetistas e as adapta&ccedil;&otilde;es foram surgindo de ambas as partes, de modo que atualmente n&atilde;o se pode afirmar com absoluta certeza que um determinada processador segue rigorosamente a linha RISC nem que outro segue rigorosamente a linha CISC.</p>&#10;<p>Os &uacute;ltimos processadores Intel possuem um n&uacute;cleo de execu&ccedil;&atilde;o RISC, assim como os processadores de 64 bits, Itanium, seguem, em grande parte, as caracter&iacute;sticas definidas para um componente RISC. E &eacute; bem verdade, que processadores Power sempre possu&iacute;ram uma quantidade apreci&aacute;vel de instru&ccedil;&otilde;es, embora todas com largura fixa.</p>&#10;<p>Caracter&iacute;sticas CISC</p> &#10;&#10;<ul>&#10;<li>Controle microprogramado&semi;</li>&#10;<li>Instru&ccedil;&otilde;es de dois operandos &#150; ADD CX,mem&semi;</li>&#10;<li>Modos registro&shy;registro, registro&shy;mem&oacute;ria, e mem&oacute;ria&shy;registro&semi;</li>&#10;<li>M&uacute;ltiplos modos de endere&ccedil;amento &agrave; mem&oacute;ria, incluindo indexa&ccedil;&atilde;o (vetores)&semi;</li>&#10;<li>Instru&ccedil;&otilde;es de largura (tamanho) vari&aacute;vel, conforme modo de endere&ccedil;amento utilizado&semi;</li>&#10;<li>Instru&ccedil;&otilde;es requerem m&uacute;ltiplos ciclos de m&aacute;quina para execu&ccedil;&atilde;o, variando tamb&eacute;m com o modo de endere&ccedil;amento&semi;</li>&#10;<li>Poucos registros&semi;</li>&#10;<li>Registros especializados</li></ul>&#10;<p>Caracter&iacute;sticas RISC</p> &#10;&#10;<ul>&#10;<li>Controle por hardware&semi;</li>&#10;<li>Pequeno conjunto de instru&ccedil;&otilde;es&semi;</li>&#10;<li>Todas as instru&ccedil;&otilde;es t&ecirc;m tamanho fixo&semi;</li>&#10;<li>Execu&ccedil;&atilde;o otimizada de chamada de fun&ccedil;&otilde;es (Call / Return)&semi;</li>&#10;<li>Pouqu&iacute;ssimos modos de endere&ccedil;amento&semi;</li>&#10;<li>Uso intenso de pipeline&semi;</li>&#10;<li>Execu&ccedil;&atilde;o r&aacute;pida de cada instru&ccedil;&atilde;o (uma por ciclo do rel&oacute;gio)&semi;</li></ul>&#10;<a id="Benef%C3%ADcios_Decrescentes" name="Benef%C3%ADcios_Decrescentes"></a><h2> Benef&iacute;cios Decrescentes </h2>&#10;<p>Ao longo do tempo, as melhorias nas t&eacute;cnicas de fabrica&ccedil;&atilde;o de chips t&ecirc;m melhorado o desempenho de forma exponencial, de acordo com a lei de Moore, enquanto melhorias na arquitetura foram relativamente pequenas. implementa&ccedil;&otilde;es modernas CISC t&ecirc;m implementado muitas das melhorias introduzidas pelo desempenho RISC, tais como transfer&ecirc;ncia de um &uacute;nico clock de instru&ccedil;&otilde;es simples. Compiladores tamb&eacute;m se tornaram mais sofisticados e s&atilde;o mais capazes de explorar complexos, bem como as instru&ccedil;&otilde;es simples sobre arquiteturas CISC, muitas vezes com cuidado otimizar tanto a sele&ccedil;&atilde;o de instru&ccedil;&atilde;o e da instru&ccedil;&atilde;o e da aquisi&ccedil;&atilde;o de dados em dutos e caches. A distin&ccedil;&atilde;o RISC CISC borrou significativamente na pr&aacute;tica.</p>&#10;<a id="Hist%C3%B3rias_de_Sucesso_RISC" name="Hist%C3%B3rias_de_Sucesso_RISC"></a><h2> Hist&oacute;rias de Sucesso RISC </h2>&#10;<p>Projetos RISC levaram a um certo n&uacute;mero de plataformas e arquiteturas bem sucedidas, algumas das maiores sendo:</p>&#10;&#10;<ul>&#10;<li>ARM &shy; A arquitetura ARM domina o mercado de baixa pot&ecirc;ncia e sistemas de baixo custo embutido (normalmente 100&shy;500&#160&semi;MHz em 2008). ARM Ltd., que licencia  propriedade intelectual, em vez de chips de fabrica&ccedil;&atilde;o, relatou que 10 bilh&otilde;es de chips licenciados tinham sido enviados no in&iacute;cio de 2008. As v&aacute;rias gera&ccedil;&otilde;es, as variantes e as implementa&ccedil;&otilde;es do n&uacute;cleo ARM s&atilde;o utilizados em mais de 90% da eletr&ocirc;nica m&oacute;vel dispositivos, incluindo quase todos os modernos telefones celulares, mp3 players e players de v&iacute;deo port&aacute;teis. Alguns exemplos de destaque s&atilde;o:</li>&#10;<li>O iPod da Apple (costume ARM7TDMI SoC)</li>&#10;<li>O iPhone da Apple e o iPod Touch (Samsung ARM1176JZF, ARM Cortex&shy;A8, a Apple A4)</li>&#10;<li>iPad o SoC (A4 Apple baseados em ARM)</li>&#10;<li>O Palm e Pocket PC PDAs e smartphones (Marvell fam&iacute;lia XScale, Samsung SC32442 &shy; ARM9)</li>&#10;<li>O RIM BlackBerry smartphone dispositivos de E / e&shy;mail.</li>&#10;<li>Microsoft Windows Mobile</li>&#10;<li>O Nintendo Game Boy Advance (ARM7TDMI)</li>&#10;<li>O Nintendo DS (ARM7TDMI, ARM946E&shy;S)</li>&#10;<li>O Sony Network Walkman (Sony in&shy;house chip baseado em ARM)</li>&#10;<li>O T&shy;Mobile G1 (Android HTC Dream, MSM7201A Qualcomm ARM11 @ 528&#160&semi;MHz)</li>&#10;<li>PowerPC Arquitetura &shy; A arquitetura PowerPC &eacute; uma arquitetura RISC popular baseado que domina a restri&ccedil;&atilde;o de desempenho e de alimenta&ccedil;&atilde;o integrada mercados de dispositivos, tais como equipamentos de comunica&ccedil;&atilde;o (Roteadores, Switches), equipamentos de armazenamento, etc</li>&#10;<li>Linha MIPS do MIPS, encontrado na maioria dos computadores da SGI e do PlayStation, PlayStation 2, Nintendo 64 (descontinuado), PlayStation Portable Consolas e gateways residenciais como a Linksys WRT54G s&eacute;rie.</li>&#10;<li>IBM e a Freescale (antiga Motorola SPS) Power Architecture, usado em todos os supercomputadores da IBM, servidores midrange e esta&ccedil;&otilde;es de trabalho, em computadores baseados em PowerPC da Apple Macintosh (descontinuado), no Nintendo Gamecube e Wii, da Microsoft, Xbox 360 e PlayStation 3 consoles de videogame, faixa da EMC DMX da SAN Symmetrix, e em muitos aplicativos embutidos, tais como impressoras e carros.</li>&#10;<li>SPARC, da Oracle (anteriormente Sun Microsystems) e Fujitsu</li>&#10;<li>Hewlett&shy;Packard&shy;RISC, tamb&eacute;m conhecido como HP&shy;PA, interrompido 31 de dezembro de 2008.</li>&#10;<li>Alpha, utilizados em computadores de placa &uacute;nica, workstations, servidores e supercomputadores da Digital Equipment Corporation, Compaq e HP, suspenso em 2007.</li>&#10;<li>XAP processador usado em fios de baixa pot&ecirc;ncia muitos (Bluetooth, wi&shy;fi) chips da RSE.</li>&#10;<li>SuperH Hitachi, originalmente em amplo uso na Super Sega 32X, Saturn e Dreamcast, agora no cora&ccedil;&atilde;o de muitos dispositivos eletr&ocirc;nicos de consumo. O SuperH &eacute; a plataforma base para a Mitsubishi &shy; Hitachi grupo de semicondutores comuns. Os dois grupos se fundiram em 2002, caindo arquitetura RISC pr&oacute;pria Mitsubishi, o M32R.</li>&#10;<li>Atmel AVR usado em uma variedade de produtos, incluindo desde os controladores de Xbox port&aacute;til para carros BMW.</li></ul>&#10;<p> </p>&#10;<a id="Liga%C3%A7%C3%B5es_externas" name="Liga%C3%A7%C3%B5es_externas"></a><h2> Liga&ccedil;&otilde;es externas </h2>&#10;&#10;<ul>&#10;<li> </li>&#10;<li> </li>&#10;<li> </li></ul>&#10;<p> &#10; </p>&#10;<p> </p>&#10;<p> &#10;<a href="http://en.wikipedia.org/wiki/Categoria:Arquitetura_de_computadores" id="w">Categoria:Arquitetura de computadores</a>&#10;<a href="http://en.wikipedia.org/wiki/Categoria:Tipos_de_computadores" id="w">Categoria:Tipos de computadores</a>&#10;<a href="http://en.wikipedia.org/wiki/Categoria:Arquitetura_RISC" id="w">Categoria:Arquitetura RISC</a></p></body></html>