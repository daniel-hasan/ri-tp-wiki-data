<html><title>Rede neural artifical</title><body>&#10;<p> &#10; &#10;<a href="http://en.wikipedia.org/wiki/Imagem:Neuralnetwork.png%7Cthumb%7Cdireita%7C220px" id="w">Diagrama simplificado de uma rede neural.</a></p>&#10;<p>Em <a href="http://en.wikipedia.org/wiki/Ci%C3%AAncia_da_computa%C3%A7%C3%A3o" id="w">ci&ecirc;ncia da computa&ccedil;&atilde;o</a> e campos relacionados, <b>redes neurais artificiais</b> (<b>RNAs</b>) s&atilde;o <a href="http://en.wikipedia.org/wiki/Modelo" id="w">modelos</a> computacionais inspirados pelo <a href="http://en.wikipedia.org/wiki/Sistema_nervoso_central" id="w">sistema nervoso central</a> de um animal (em particular o <a href="http://en.wikipedia.org/wiki/C%C3%A9rebro" id="w">c&eacute;rebro</a>) que &eacute; capaz de realizar o <a href="http://en.wikipedia.org/wiki/Aprendizado_de_m%C3%A1quina" id="w">aprendizado de m&aacute;quina</a> bem como o <a href="http://en.wikipedia.org/wiki/Reconhecimento_de_padr%C3%B5es" id="w">reconhecimento de padr&otilde;es</a>. Redes neurais artificias geralmente s&atilde;o apresentadas como sistemas de &#34&semi;<a href="http://en.wikipedia.org/wiki/Neur%C3%B4nio_artificial" id="w">neur&ocirc;nios</a> interconectados que podem computar valores de entradas.</p>&#10;<p>Por exemplo, uma rede neural para o <a href="http://en.wikipedia.org/wiki/Reconhecimento_de_escrita_manual" id="w">reconhecimento de escrita manual</a> &eacute; definida por um conjunto de neur&ocirc;nios de entrada que podem ser ativados pelos pixels de uma imagem de entrada. As ativa&ccedil;&otilde;es desses neur&ocirc;nios s&atilde;o ent&atilde;o repassadas&#8203;&#8203;, ponderadas e transformadas por uma fun&ccedil;&atilde;o determinada pelo designer da rede, a outros neur&ocirc;nios. Este processo &eacute; repetido at&eacute; que, finalmente, um neur&ocirc;nio de sa&iacute;da &eacute; ativado. Isso determina que caractere foi lido. </p>&#10;<p>Assim como outros m&eacute;todos de aprendizado de m&aacute;quina, sistemas que aprendem a partir dos dados, redes neurais t&ecirc;m sido usadas para resolver uma grande variedade de tarefas que s&atilde;o dif&iacute;ceis de resolver utilizando programa&ccedil;&atilde;o baseada em regras comuns, incluindo <a href="http://en.wikipedia.org/wiki/Vis%C3%A3o_computacional" id="w">vis&atilde;o computacional</a> e <a href="http://en.wikipedia.org/wiki/Reconhecimento_de_voz" id="w">reconhecimento de voz</a>.</p>&#10;<a id="Exemplos" name="Exemplos"></a><h2> Exemplos </h2>&#10;<p>A inspira&ccedil;&atilde;o original para essa t&eacute;cnica adv&eacute;m do exame das estruturas do <a href="http://en.wikipedia.org/wiki/C%C3%A9rebro" id="w">c&eacute;rebro</a>, em particular do exame de <a href="http://en.wikipedia.org/wiki/Neur%C3%B4nio" id="w">neur&ocirc;nios</a>.&#10;A propriedade mais importante das redes neurais &eacute; a habilidade de aprender de seu ambiente e com isso melhorar seu desempenho. &#10;Isso &eacute; feito atrav&eacute;s de um processo iterativo de ajustes aplicado aos seus pesos, o treino. </p> &#10;<p>A aprendizagem ocorre quando a rede neural atinge uma solu&ccedil;&atilde;o generalizada para uma classe de problemas. </p> &#10;<p>Denomina&shy;se algoritmo de aprendizagem a um conjunto de regras bem definidas para a solu&ccedil;&atilde;o de um problema de aprendizagem. &#10;Outro factor importante &eacute; a maneira pela qual uma rede neural se relaciona com o ambiente. Nesse contexto existem os seguintes &#10;paradigmas de aprendizagem: </p> &#10;<p>Aprendizagem Supervisionado, quando &eacute; utilizado um agente externo que indica &agrave; rede a resposta desejada para o padr&atilde;o de entrada. Aprendizado N&atilde;o Supervisionado (auto&shy;organiza&ccedil;&atilde;o), quando n&atilde;o existe uma agente externo indicando a resposta desejada para os padr&otilde;es de entrada&semi; </p> &#10;<p>Refor&ccedil;o, quando um cr&iacute;tico externo avalia a resposta fornecida pela rede. </p>&#10;<p>&bull; Aplica&ccedil;&otilde;es: </p> &#10;<p>Reconhecimento Autom&aacute;tico de Alvos&semi; &#10;Reconhecimento de Caracteres&semi; &#10;Rob&oacute;tica&semi; &#10;Diagn&oacute;stico M&eacute;dico&semi; &#10;Sensoriamento Remoto&semi; &#10;Processamento de Voz&semi; &#10;Biometria. </p>&#10;<a id="Hist%C3%B3rico" name="Hist%C3%B3rico"></a><h2> Hist&oacute;rico </h2>&#10;<p>As primeiras informa&ccedil;&otilde;es sobre <a href="http://en.wikipedia.org/wiki/Neurocomputa%C3%A7%C3%A3o" id="w">neurocomputa&ccedil;&atilde;o</a> surgiram em <a href="http://en.wikipedia.org/wiki/1943" id="w">1943</a>, em artigos do <a href="http://en.wikipedia.org/wiki/Neuroanatomia" id="w">neuroanatomista</a> e <a href="http://en.wikipedia.org/wiki/Psiquiatra" id="w">psiquiatra</a> <a href="http://en.wikipedia.org/wiki/Warren_McCulloch" id="w">Warren McCulloch</a>, do <a href="http://en.wikipedia.org/wiki/Instituto_Tecnol%C3%B3gico_de_Massachusetts" id="w">Instituto Tecnol&oacute;gico de Massachusetts</a>, e do <a href="http://en.wikipedia.org/wiki/Matem%C3%A1tica" id="w">matem&aacute;tico</a> <a href="http://en.wikipedia.org/wiki/Walter_Pitts" id="w">Walter Pitts</a>, da <a href="http://en.wikipedia.org/wiki/Universidade_de_Illinois" id="w">Universidade de Illinois</a>. Os autores fizeram uma <a href="http://en.wikipedia.org/wiki/Analogia" id="w">analogia</a> entre c&eacute;lulas nervosas vivas e o processo <a href="http://en.wikipedia.org/wiki/Eletr%C3%B4nico" id="w">eletr&ocirc;nico</a>, em um trabalho publicado sobre &#34&semi;neur&ocirc;nios formais&#34&semi;&semi; simulando o <a href="http://en.wikipedia.org/wiki/Comportamento" id="w">comportamento</a> do neur&ocirc;nio natural, no qual o neur&ocirc;nio possu&iacute;a apenas uma sa&iacute;da, que era uma fun&ccedil;&atilde;o da soma de valor de suas diversas entradas. O trabalho consistia num modelo de <a href="http://en.wikipedia.org/wiki/Resistor" id="w">resistores</a> vari&aacute;veis e <a href="http://en.wikipedia.org/wiki/Amplificador" id="w">amplificadores</a>, representando <a href="http://en.wikipedia.org/wiki/Sinapse" id="w">conex&otilde;es sin&aacute;pticas</a> de um neur&ocirc;nio biol&oacute;gico.</p>&#10;&#10;<a id="D%C3%A9cada_de_1940" name="D%C3%A9cada_de_1940"></a><h3> D&eacute;cada de 1940 </h3>&#10;<p>Possivelmente uma das publica&ccedil;&otilde;es mais significativas, formulada por von Neumann, foi <i>The General and Logical Theory of Automata</i>, no final da d&eacute;cada de 1940.</p>&#10;<p>Talvez a mais remota  influ&ecirc;ncia (no inicio do <a href="http://en.wikipedia.org/wiki/S%C3%A9culo_XIX" id="w">s&eacute;culo XIX</a>), foi a do &#34&semi;Pato de Vaucanson&#34&semi;, um aut&ocirc;mato em forma de pato com centenas de pe&ccedil;as e que al&eacute;m de grasnar, comia, bebia, digeria e nadava. N&atilde;o esquecendo de mencionar tamb&eacute;m a <a href="http://en.wikipedia.org/wiki/M%C3%A1quina_de_Turing" id="w">m&aacute;quina de Turing</a> (<a href="http://en.wikipedia.org/wiki/1936" id="w">1936</a>). O resultado do aut&ocirc;mato de Turing influenciou von Neumann, e o levou a perceber que os seres vivos estavam de fato entre as m&aacute;quinas que a m&aacute;quina de Turing poderia emular. Na sua obra, (arquitetura de von Neumann), ele fez uma analogia entre os &oacute;rg&atilde;os e as partes de um computador, entre portas l&oacute;gicas, circuitos e neur&ocirc;nios.<sup id="_ref&shy;1" class="reference"><a href="#_note&shy;1" title="">[1]</a></sup></p>&#10;<p>O livro Cybernetics de Wiener publicado em 1948 descreve alguns conceitos sobre controle, comunica&ccedil;&atilde;o e processamento estat&iacute;stico de sinais. Em 1961 foi adicionado na segunda edi&ccedil;&atilde;o do livro material sobre aprendizagem e auto&shy;organiza&ccedil;&atilde;o. Em ambas as edi&ccedil;&otilde;es desse livro o Cap&iacute;tulo 2 traz o compreendimento do significado f&iacute;sico da mec&acirc;nica estat&iacute;stica no contexto desse assunto segundo Wiener, mas quem conseguiu terminar a liga&ccedil;&atilde;o entre a mec&acirc;nica estat&iacute;stica e os sistemas de aprendizagem foi Hopfield mais de 30 anos depois.<sup id="_ref&shy;2" class="reference"><a href="#_note&shy;2" title="">[2]</a></sup></p>&#10;<p>Em <a href="http://en.wikipedia.org/wiki/1949" id="w">1949</a> Hebb introduziu a capacidade de aprender atrav&eacute;s de seu livro &#34&semi;<a href="http://en.wikipedia.org/wiki/The_Organization_of_Behavior" id="w">The Organization of Behavior</a>&#34&semi;. Hebb descreveu um sistema de aprendizado por correla&ccedil;&atilde;o dos neur&ocirc;nios que acabou dando origem a Regra de Aprendizagem de Hebb e essa teoria &eacute; comumente evocada para explicar alguns tipos de aprendizagem associativos no qual a ativa&ccedil;&atilde;o simult&acirc;nea de c&eacute;lulas leva a um crescimento pronunciado na for&ccedil;a sin&aacute;ptica. Tal aprendizado &eacute; conhecido como aprendizagem hebbiana.<sup id="_ref&shy;Hebb_a" class="reference"><a href="#_note&shy;Hebb" title="">[3]</a></sup></p>&#10;<a id="D%C3%A9cada_de_1950" name="D%C3%A9cada_de_1950"></a><h3> D&eacute;cada de 1950 </h3>&#10;<p>Em <a href="http://en.wikipedia.org/wiki/1951" id="w">1951</a>, foi constru&iacute;do o primeiro neuro computador denominado <a href="http://en.wikipedia.org/wiki/Snark" id="w">Snark</a>, por Mavin Minsky. O Snark operava com sucesso a partir de um ponto de partida t&eacute;cnico, ajustando seus pesos automaticamente, entretanto, ele nunca executou qualquer fun&ccedil;&atilde;o de processamento de informa&ccedil;&atilde;o interessante, mas serviu de inspira&ccedil;&atilde;o para as id&eacute;ias de estruturas que o sucederam.</p>&#10;<p>O livro de Ashby (Design for a Brain: The Origin of Adaptive Behavior) que foi publicado em 1952 trata do conhecimento b&aacute;sico de que o comportamento adaptativo n&atilde;o nasce com o indiv&iacute;duo, mas sim &eacute; aprendido, e que atrav&eacute;s da aprendizagem o animal (sistema) normalmente muda seu comportamento para melhor. S&atilde;o enfatizados neste livro os aspectos din&acirc;micos do organismo vivo como uma m&aacute;quina e o conceito correlacionado de estabilidade.</p>&#10;<p>Gabor, um dos pioneiros da teoria da comunica&ccedil;&atilde;o e o inventor da holografia, prop&ocirc;s em 1954 a id&eacute;ia de um filtro adaptativo n&atilde;o linear. Com a ajuda de colaboradores, Gabor construiu uma m&aacute;quina que alimentada com amostras de um processo estoc&aacute;stico, mais a fun&ccedil;&atilde;o&shy;alvo que a m&aacute;quina deveria produzir, realizava a aprendizagem.</p>&#10;<p>Em 1954&shy;1955, Cragg e Tamperley observaram que os &aacute;tomos em uma rede t&ecirc;m seus spins apontando &#34&semi;para cima&#34&semi; ou &#34&semi;para baixo&#34&semi;, assim como os neur&ocirc;nios podem ser &#34&semi;disparados&#34&semi; (ativados) ou &#34&semi;n&atilde;o disparados&#34&semi; (quiescentes).<sup id="_ref&shy;4" class="reference"><a href="#_note&shy;4" title="">[4]</a></sup></p>&#10;<p>Em <a href="http://en.wikipedia.org/wiki/1956" id="w">1956</a> no Darthmouth College nasceram os dois paradigmas da <a href="http://en.wikipedia.org/wiki/Intelig%C3%AAncia_Artificial" id="w">Intelig&ecirc;ncia Artificial</a>, a simb&oacute;lica e o conexionista. A Intelig&ecirc;ncia Artificial Simb&oacute;lica tenta simular o comportamento inteligente humano desconsiderando os mecanismos respons&aacute;veis por tal. J&aacute; a Intelig&ecirc;ncia Artificial Conexionista acredita que constru&iacute;ndo&shy;se um sistema que simule a estrutura do c&eacute;rebro, este sistema apresentar&aacute; <a href="http://en.wikipedia.org/wiki/Intelig%C3%AAncia" id="w">intelig&ecirc;ncia</a>, ou seja, ser&aacute; capaz de aprender, assimilar, errar e aprender com seus erros. O livro de Hebb tem sido uma fonte de inspira&ccedil;&atilde;o para o desenvolvimento de modelos computaconais de sistema adaptativos e de aprendizagem. O artigo de Rochester, Holland, Haibt e Duda (1956) talvez seja a primeira tentativa de usar simula&ccedil;&atilde;o computacional para testar uma teoria neural bem&shy;formulada com base no postulado de aprendizagem de Hebb (que a efici&ecirc;ncia de uma sinapse vari&aacute;vel entre dois neur&ocirc;nios &eacute; aumentada pela ativa&ccedil;&atilde;o repetida de um neur&ocirc;nio causada pelo outro neur&ocirc;nio). Naquele mesmo ano Uttley (1956) demonstrou que uma rede neural com sinapses modific&aacute;veis pode aprender a classificar conjuntos simples de padr&otilde;es bin&aacute;rios em classes correspondentes.</p>&#10;<p>Em 1957 Rosenblatt inicia testes simulados em um computador IBM 704 no Laborat&oacute;rio da Aeron&aacute;utica de Cornell. Pelo estudo de redes neurais, como a Perceptron, Rosenblatt esperava que as leis fundamentais da organiza&ccedil;&atilde;o que s&atilde;o comuns a todos os sistemas de informa&ccedil;&atilde;o de movimenta&ccedil;&atilde;o, m&aacute;quinas e homens inclu&iacute;dos, pudesse eventualmente ser compreendida.</p>&#10;<p>Em 1958, Frank Rosenblatt criou o <a href="http://en.wikipedia.org/wiki/Perceptron" id="w">Perceptron</a>, um modelo cognitivo que consistia de unidades sensoriais conectadas a uma &uacute;nica camada de neur&ocirc;nios de <a href="http://en.wikipedia.org/wiki/Warren_McCulloch" id="w">Warren McCulloch</a> e Pitts, capaz de aprender tudo o que pudesse representar. Rosenblatt demonstrou que, se fossem acrescidas sinapses ajust&aacute;veis, as redes neurais de Warren McCulloch e Pitts poderiam ser treinadas para classificar padr&otilde;es em classes linearmente separ&aacute;veis, convergindo em um n&uacute;mero limitado de passos.<sup id="_ref&shy;M&Aacute;SSON_a" class="reference"><a href="#_note&shy;M&Aacute;SSON" title="">[5]</a></sup></p>&#10;<p>Efici&ecirc;ncia de transmiss&atilde;o (peso) ajust&aacute;vel&semi; esta envia a resposta (sa&iacute;das) para a terceira camada.</p>&#10;<p>O intuito de Rosenblatt era projetar RNAs que fossem capazes de fazer descobertas interessantes sem a necessidade de regras, o que, ali&aacute;s, continua sendo alvo dos pesquisadores.<sup id="_ref&shy;braga_a" class="reference"><a href="#_note&shy;braga" title="">[6]</a></sup></p>&#10;<a id="D%C3%A9cada_de_1960" name="D%C3%A9cada_de_1960"></a><h3> D&eacute;cada de 1960 </h3>&#10;<p>No in&iacute;cio da <a href="http://en.wikipedia.org/wiki/D%C3%A9cada_de_1960" id="w">d&eacute;cada de 1960</a>, Widrow e Hoff publicam um artigo no qual especificam um neur&ocirc;nio artificial baseado no modelo de McCulloch e Pitts, denominado ADALINE. Conforme,<sup id="_ref&shy;M&Aacute;SSON_b" class="reference"><a href="#_note&shy;M&Aacute;SSON" title="">[5]</a></sup> a import&acirc;ncia desse modelo est&aacute; associada &agrave; regra de aprendizagem proposta, a regra Delta. A combina&ccedil;&atilde;o de uma s&eacute;rie de ADELINEs &eacute; chamada de  MADALINE (Multiple Adaline) &eacute; uma de duas camadas de <a href="http://en.wikipedia.org/wiki/Rede_neural" id="w">rede neural</a> com um conjunto de ADALINEs. Widrow tamb&eacute;m fundou a primeira companhia de <a href="http://en.wikipedia.org/wiki/Hardware" id="w">hardware</a> de neurocomputadores e componentes.</p>&#10;<p>Em 1967, Cowan caracterizou o disparo &#34&semi;sigm&oacute;ide&#34&semi; e a condi&ccedil;&atilde;o de disparo suave para um neur&ocirc;nio baseando&shy;se na fun&ccedil;&atilde;o log&iacute;stica.</p>&#10;<p>Em 1967&shy;1968, Grossberg envolvendo equa&ccedil;&otilde;es n&atilde;o&shy;lineares de diferen&ccedil;as/diferenciais introduziu o modelo aditivo de um neur&ocirc;nio e como base para a mem&oacute;ria de curto prazo explorou o uso do modelo.<sup id="_ref&shy;7" class="reference"><a href="#_note&shy;7" title="">[7]</a></sup></p>&#10;<p>A publica&ccedil;&atilde;o de Perceptrons de Minsky e Papert, em 1969, exp&ocirc;s as limita&ccedil;&otilde;es do modelo de Rosenblatt, provando que tais redes n&atilde;o s&atilde;o capazes de resolver uma ampla classe de problemas devido &agrave;s restri&ccedil;&otilde;es de representa&ccedil;&atilde;o.<sup id="_ref&shy;M&Aacute;SSON_c" class="reference"><a href="#_note&shy;M&Aacute;SSON" title="">[5]</a></sup><sup id="_ref&shy;WASSERMAN_a" class="reference"><a href="#_note&shy;WASSERMAN" title="">[8]</a></sup> O impacto desta publica&ccedil;&atilde;o foi devastador, praticamente desaparecendo o interesse em redes neurais artificiais nos anos seguintes, somente poucos pesquisadores como Malsburg, Grossberg, Kohonen e Anderson permaneceram concentrando suas atividades na abordagem conexionista.</p>&#10;<a id="D%C3%A9cada_de_1970" name="D%C3%A9cada_de_1970"></a><h3> D&eacute;cada de 1970 </h3>&#10;<p>Nos anos 70, n&atilde;o ocorreram grandes progressos nos estudos de <a href="http://en.wikipedia.org/wiki/Redes_neurais" id="w">redes neurais</a> devido um entusiasmo exagerado de muitos pesquisadores, que passaram a publicar mais e mais artigos e livros que faziam uma previs&atilde;o pouco confi&aacute;vel para a &eacute;poca, sobre m&aacute;quinas t&atilde;o poderosas quanto o <a href="http://en.wikipedia.org/wiki/C%C3%A9rebro" id="w">c&eacute;rebro</a> humano que surgiriam em um curto espa&ccedil;o de tempo. Isto tirou quase toda a credibilidade dos estudos desta &aacute;rea e causou grandes aborrecimentos aos t&eacute;cnicos de outras &aacute;reas.</p>&#10;<p>Dentre os poucos pesquisadores que continuaram trabalhando na &aacute;rea, destacam&shy;se:&#10;</p>&#10;<ul>&#10;<li>Igor Aleksander, <a href="http://en.wikipedia.org/wiki/Inglaterra" id="w">Inglaterra</a>: redes sem pesos&semi;</li>&#10;<li>Kunihiko Fukushima, <a href="http://en.wikipedia.org/wiki/Jap%C3%A3o" id="w">Jap&atilde;o</a>: cognitron e neocognitron&semi;</li>&#10;<li>Steven Grossberg, <a href="http://en.wikipedia.org/wiki/Estados_Unidos" id="w">Estados Unidos</a>: sistemas auto&shy;adaptativos&semi;</li>&#10;<li>Teuvo Kohonen, <a href="http://en.wikipedia.org/wiki/Finl%C3%A2ndia" id="w">Finl&acirc;ndia</a>: mem&oacute;rias associativas e auto&shy;organizadas.<sup id="_ref&shy;braga_b" class="reference"><a href="#_note&shy;braga" title="">[6]</a></sup></li></ul>&#10;<p>No ano de <a href="http://en.wikipedia.org/wiki/1970" id="w">1970</a> a <a href="http://en.wikipedia.org/wiki/Universidade_de_Michigan" id="w">Universidade de Michigan</a> foi palco para as pesquisas de vida artificial, J. Holland foi o primeiro pesquisador a conseguir o t&iacute;tulo de PhD em <a href="http://en.wikipedia.org/wiki/Ci%C3%AAncia_da_Computa%C3%A7%C3%A3o" id="w">Ci&ecirc;ncia da Computa&ccedil;&atilde;o</a>. Ele e T. Toffoli foram atraidos pela id&eacute;ia de comportamento adaptativo onde envolvia biologia, computadores e informa&ccedil;&atilde;o, se tornaram associados em com algoritmos gen&eacute;ricos e aut&ocirc;matos celulares, respectivamente. Toffoli sempre se preocupou em criar a conex&atilde;o do mundo f&iacute;sico com o aut&ocirc;mato.</p>&#10;<p>Em 1972 foi introduzido de forma independente por Amari o modelo aditivo de um neur&ocirc;nio para estudar o comportamento din&acirc;mico de elementos semelhantes a neur&ocirc;nios conectados aleatoriamente.</p>&#10;<p>Ainda em 1972, Wilson e Cowan derivaram equa&ccedil;&otilde;es diferenciais n&atilde;o&shy;lineares acopladas correspondentes &agrave; din&acirc;mica de popula&ccedil;&otilde;es localizadas no espa&ccedil;o, contendo neur&ocirc;nios tanto excitadores como inibit&oacute;rios.</p>&#10;&shy; <a href="http://en.wikipedia.org/wiki/1974" id="w">1974</a>: WERBOS lan&ccedil;ou bases para o <a href="http://en.wikipedia.org/wiki/Algoritmo" id="w">algoritmo</a> de retropropaga&ccedil;&atilde;o (backpropagation).&#10;&#10;<p>Em 1975, Little e Shaw descreveram e usaram o modelo probabil&iacute;stico de um neur&ocirc;nio, disparando ou n&atilde;o um potencial de a&ccedil;&atilde;o, para desenvolver uma teoria da mem&oacute;ria de curto prazo.</p>&#10;<p>Em 1977, Andereson, Silverstein, Ritz e Jones, sugeriram o modelo do estado cerebral em uma caixa (BSB, brain&shy;state&shy;in&shy;a&shy;box), compondo&shy;se de uma rede associativa simples acoplada a uma din&acirc;mica n&atilde;o&shy;linear.<sup id="_ref&shy;9" class="reference"><a href="#_note&shy;9" title="">[9]</a></sup></p>&#10;<a id="D%C3%A9cada_de_1980" name="D%C3%A9cada_de_1980"></a><h3> D&eacute;cada de 1980 </h3>&#10;<p>A partir dos anos 80, com o avan&ccedil;o da tecnologia e o fracasso da escola simbolista na solu&ccedil;&atilde;o de determinados tipos de problemas, as redes neurais artificiais passaram a atrair substancial aten&ccedil;&atilde;o novamente, as pesquisas na &aacute;rea foram retomadas com for&ccedil;a. A nova explos&atilde;o de interesse pelas redes neurais artificiais na comunidade cient&iacute;fica foi impulsionada, principalmente, pelo avan&ccedil;o da tecnologia (especialmente da microeletr&ocirc;nica) e tamb&eacute;m pelo impacto causado pelo artigo publicado por <a href="http://en.wikipedia.org/wiki/John_Hopfield" id="w">John Hopfield</a> em <a href="http://en.wikipedia.org/wiki/1982" id="w">1982</a>, no qual chamou a aten&ccedil;&atilde;o para as propriedades associativas das RNAs. Hopfield mostrou a rela&ccedil;&atilde;o entre redes recorrentes autoassossiativas e sistemas f&iacute;sicos, abrindo espa&ccedil;o para a utiliza&ccedil;&atilde;o de teorias correntes da F&iacute;sica para estudar tais modelos.<sup id="_ref&shy;braga_c" class="reference"><a href="#_note&shy;braga" title="">[6]</a></sup></p>&#10;<p>Em 1982, a introdu&ccedil;&atilde;o do modelo conexionista conhecido pelo nome de seu idealizador, John Hopfield, permitiu esclarecer, pelas suas caracter&iacute;sticas computacionais e estabilidade, boa parte das d&uacute;vidas at&eacute; ent&atilde;o existentes em rela&ccedil;&atilde;o ao processo din&acirc;mico executado por certas redes neurais. No mesmo ano, Teuvo Kohonen publicou um artigo descrevendo uma rede neural artificial baseada em auto&shy;organiza&ccedil;&atilde;o e nas caracter&iacute;sticas de aprendizado adaptativo do c&eacute;rebro humano.<sup id="_ref&shy;M&Aacute;SSON_d" class="reference"><a href="#_note&shy;M&Aacute;SSON" title="">[5]</a></sup></p>&#10;<p>Hinton e Seynowsky, em <a href="http://en.wikipedia.org/wiki/1983" id="w">1983</a>, estenderam o modelo de Hopfield com a incorpora&ccedil;&atilde;o de din&acirc;mica estoc&aacute;stica. Este modelo de rede neural passou a ser conhecido como M&aacute;quina de Boltzmann.<sup id="_ref&shy;WASSERMAN_b" class="reference"><a href="#_note&shy;WASSERMAN" title="">[8]</a></sup></p>&#10;<p>Por&eacute;m talvez o fato mais importante deste per&iacute;odo tenha ocorrido quando Ira Skurnick, um administrador de programas da <a href="http://en.wikipedia.org/wiki/DARPA" id="w">DARPA</a> (Defense Advanced Research Projects Agency) decidiu ouvir os argumentos da neuro <a href="http://en.wikipedia.org/wiki/Computa%C3%A7%C3%A3o" id="w">computa&ccedil;&atilde;o</a> e seus projetistas, e divergindo dos caminhos tradicionais dos conhecimentos convencionais, fundou em <a href="http://en.wikipedia.org/wiki/1983" id="w">1983</a> pesquisas em neuro computa&ccedil;&atilde;o. Este ato n&atilde;o s&oacute; abriu as portas para a neuro computa&ccedil;&atilde;o, como tamb&eacute;m deu &agrave; DARPA o status de uma das l&iacute;deres mundiais em se tratando de &#34&semi;moda&#34&semi; tecnol&oacute;gica.</p>&#10;<p>Em meados da d&eacute;cada de 1980 surgiu a descri&ccedil;&atilde;o do algoritmo de treinamento backpropagation(Rumelhart, Hinton, &#38&semi; Williams 1986).O termo backpropagation surge do fato que o algoritmo se baseia na retropropaga&ccedil;&atilde;o dos erros para realizar os ajustes de pesos das camadas intermedi&aacute;rias. A maneira de calcular as derivadas parciais do erro de sa&iacute;da em rela&ccedil;&atilde;o a cada um dos pesos da rede &eacute; o que caracteriza o backpropagation.<sup id="_ref&shy;10" class="reference"><a href="#_note&shy;10" title="">[10]</a></sup> Com isso o algoritmo backpropagation foi aplicado em v&aacute;rios problemas, como na identifica&ccedil;&atilde;o da estrutura de prote&iacute;nas, hifeniza&ccedil;&atilde;o de palavras em ingl&ecirc;s, reconhecimento da fala, compress&atilde;o de imagens e previs&atilde;o de s&eacute;ries temporais. O sucesso deste algoritmo estimulou o desenvolvimento de muitas pesquisas em redes neurais artificiais e de uma variedade de modelos cognitivos.</p>&#10;<p>Ap&oacute;s a publica&ccedil;&atilde;o em 1986 do hoje cl&aacute;ssico Parallel Distributed Processing, editado por Rummerlhart e <a href="http://en.wikipedia.org/wiki/McClelland" id="w">McClelland</a> do PDP Research Group da <a href="http://en.wikipedia.org/wiki/Universidade_da_Calif%C3%B3rnia" id="w">Universidade da Calif&oacute;rnia</a> em <a href="http://en.wikipedia.org/wiki/San_Diego" id="w">San Diego</a>, a &aacute;rea de redes neurais teve um desenvolvimento explosivo com a multiplica&ccedil;&atilde;o exponencial de Journal&#39&semi;s, associa&ccedil;&atilde;o locais e internacionais, sem falar da torrente de teses e paper&#39&semi;s cient&iacute;ficos. No come&ccedil;o desta d&eacute;cada surgiram v&aacute;rias empresas para a explora&ccedil;&atilde;o comercial de produtos de redes neurais, invariavelmente produtos de software para o desenvolvimento de aplica&ccedil;&otilde;es ou simula&ccedil;&atilde;o acad&ecirc;micas&#10;<sup id="_ref&shy;KOVACS_a" class="reference"><a href="#_note&shy;KOVACS" title="">[11]</a></sup></p>&#10;<p>Em <a href="http://en.wikipedia.org/wiki/1987" id="w">1987</a> ocorreu em S&atilde;o Francisco a primeira confer&ecirc;ncia de <a href="http://en.wikipedia.org/wiki/Redes_neurais" id="w">redes neurais</a> em tempos modernos, a <a href="http://en.wikipedia.org/wiki/IEEE" id="w">IEEE</a> International Conference on Neural Networks, e tamb&eacute;m foi formada a International Neural Networks Society (INNS). A partir destes acontecimentos decorreram a funda&ccedil;&atilde;o do INNS journal em <a href="http://en.wikipedia.org/wiki/1989" id="w">1989</a>, seguido do Neural Computation e do IEEE Transactions on Neural Networks em <a href="http://en.wikipedia.org/wiki/1990" id="w">1990</a>.</p>&#10;<a id="RNAs_(vantagens_e_caracter%C3%ADsticas)" name="RNAs_(vantagens_e_caracter%C3%ADsticas)"></a><h2> RNAs (vantagens e caracter&iacute;sticas) </h2>&#10;<p>As redes neurais artificiais (RNA) t&ecirc;m muitas vantagens, porque se baseiam na estrutura do sistema nervoso humano, principalmente o <i>c&eacute;rebro</i>.</p>&#10;<p>Sua Aprendizagem: as RNAs t&ecirc;m a capacidade de aprender atrav&eacute;s de uma fase chamada fase de aprendizagem. Trata&shy;se de fornecer dados como entrada RNA, por sua vez, informando qual &eacute; a sa&iacute;da (resposta) que &eacute; o esperado.</p>&#10;<p>Auto&shy;organiza&ccedil;&atilde;o: uma RNA cria sua pr&oacute;pria representa&ccedil;&atilde;o de informa&ccedil;&atilde;o no seu interior,descarregando ao usu&aacute;rio isto.</p>&#10;<p>Toler&acirc;ncia a falhas: Como um RNA armazena informa&ccedil;&otilde;es de forma redundante, pode continuar a responder de uma forma aceit&aacute;vel, mesmo que esteja  parcialmente danificado.</p>&#10;<p>Flexibilidade: Uma rede neural n&atilde;o pode lidar com grandes mudan&ccedil;as na informa&ccedil;&atilde;o de entrada, tais como sinais ruidosos ou outras altera&ccedil;&otilde;es na entrada (por exemplo, se a informa&ccedil;&atilde;o de entrada &eacute; a imagem de um objeto, a correspondente resposta mant&eacute;m&shy;se inalterado, se a imagem muda um pouco de brilho ou o objeto muda um pouco)&#10;Real Time: A estrutura de uma RNA &eacute; paralela, de modo que se for implementado com computadores ou dispositivos eletr&ocirc;nicos especiais, podem obter respostas em tempo real.</p>&#10;<a id="Arquiteturas" name="Arquiteturas"></a><h3> Arquiteturas </h3>&#10;<p>Os neur&ocirc;nios de uma RNAs devem estar conectados entre si, os neur&ocirc;nios s&atilde;o dispostos em camadas, os neur&ocirc;nios de uma mesma camada normalmente se comportam da mesma maneira. A disposi&ccedil;&atilde;o dos neur&ocirc;nios nas camadas e o padr&atilde;o de conex&atilde;o entre estas definem a arquitetura da RNA.</p>&#10;<p>As redes sem realimenta&ccedil;&atilde;o (feedforward) t&ecirc;m neur&ocirc;nios agrupados em camadas o sinal percorre a rede em uma &uacute;nica dire&ccedil;&atilde;o, da entrada para a sa&iacute;da, os neur&ocirc;nios da mesma camada n&atilde;o s&atilde;o conectados.</p>&#10;<p>As redes com realimenta&ccedil;&atilde;o ou recorrentes (recurrent), a sa&iacute;da de alguns neur&ocirc;nios alimentam neur&ocirc;nios da mesma camada (inclusive o pr&oacute;prio) ou de camadas anteriores, o sinal percorre a rede em duas dire&ccedil;&otilde;es, tem mem&oacute;ria din&acirc;mica, capacidade de representar estados em sistemas din&acirc;micos, um exemplo &eacute; a rede de Hopfield.</p>&#10;<a id="Modelos" name="Modelos"></a><h3> Modelos </h3>&#10;<p>Uma t&iacute;pica rede neural feedforward &eacute; um conjunto de n&oacute;s. Alguns desses est&atilde;o na camada de entrada, alguns n&oacute;s na camada de sa&iacute;da, e os outros est&atilde;o nas camadas intermedi&aacute;rias/escondidos. Cada conex&atilde;o entre os neur&ocirc;nios tem um peso num&eacute;rico.<sup id="_ref&shy;12" class="reference"><a href="#_note&shy;12" title="">[12]</a></sup> Quando a rede estiver em opera&ccedil;&atilde;o, o valor ser&aacute; aplicado a cada n&oacute; de entrada &shy; os valores que est&atilde;o sendo alimentados por um operador humano, a partir de sensores ambientais, ou de algum programa externo. Cada n&oacute; passa ent&atilde;o o valor dado &agrave;s conex&otilde;es que levam para fora dela, e em cada conex&atilde;o o valor &eacute; multiplicado pelo peso associado a esse respeito. Cada n&oacute; na camada seguinte ent&atilde;o recebe um valor que &eacute; a soma dos valores produzidos pelas conex&otilde;es que levam at&eacute; ele, e em cada n&oacute; um simples c&aacute;lculo &eacute; realizado sobre o valor &shy; uma fun&ccedil;&atilde;o sigm&oacute;ide &eacute; t&iacute;pica. Este processo &eacute; repetido ent&atilde;o, com os resultados sendo passados atrav&eacute;s de camadas subsequentes de n&oacute;s at&eacute; que os n&oacute;s de sa&iacute;da s&atilde;o alcan&ccedil;adas. Os primeiros modelos, teve um n&uacute;mero fixo de camadas. Mais recentemente, os algoritmos gen&eacute;ticos s&atilde;o usados para desenvolver a estrutura neural.</p>&#10;<a id="C%C3%A1lculos" name="C%C3%A1lculos"></a><h3> C&aacute;lculos </h3>&#10;<p>A curva sigm&oacute;ide &eacute; frequentemente utilizado como uma fun&ccedil;&atilde;o de transfer&ecirc;ncia, porque introduz a n&atilde;o&shy;linearidade em rede c&aacute;lculos da por &#34&semi;esmagamento&#34&semi;<sup id="_ref&shy;13" class="reference"><a href="#_note&shy;13" title="">[13]</a></sup> de ativa&ccedil;&atilde;o do neur&ocirc;nio de n&iacute;vel para o intervalo [0,1]. A fun&ccedil;&atilde;o sigm&oacute;ide tem a vantagem adicional de ter uma fun&ccedil;&atilde;o extremamente simples derivado, tal como exigido para a parte traseira de propaga&ccedil;&atilde;o de erros atrav&eacute;s de uma rede neural feed&shy;forward. Outras fun&ccedil;&otilde;es com caracter&iacute;sticas semelhantes podem ser utilizados, mais comumente tanh que comprime as ativa&ccedil;&otilde;es para o intervalo de [&shy;1,1] em vez disso, ou, ocasionalmente, uma fun&ccedil;&atilde;o linear em pe&ccedil;a que pode ser encaixada a ativa&ccedil;&atilde;o, em vez de o esmagar.</p>&#10;<p>Se nenhuma n&atilde;o&shy;linearidade &eacute; introduzida por esmagamento ou corte, a rede perde muito do seu poder computacional, tornando&shy;se uma opera&ccedil;&atilde;o de multiplica&ccedil;&atilde;o matriz simples de &aacute;lgebra linear .&#10;modelos alternativos de c&aacute;lculo nas redes neurais incluem modelos com al&ccedil;as, onde algum tipo de processo demora tempo deve ser usado, e &#34&semi;o vencedor leva todos os modelos&#34&semi;, onde o neur&ocirc;nio com o maior valor desde o c&aacute;lculo inc&ecirc;ndios e assume um valor 1, e todos os outros neur&ocirc;nios tomam o valor 0.</p>&#10;<p>Normalmente, os pesos em uma rede neural s&atilde;o ajustados inicialmente para pequenos valores aleat&oacute;rios. Isto representa a rede sem saber nada, sua sa&iacute;da &eacute; essencialmente uma fun&ccedil;&atilde;o de reprodu&ccedil;&atilde;o aleat&oacute;ria de sua entrada. Como o produto processo de treinamento, os pesos de conex&atilde;o s&atilde;o gradualmente modificados de acordo com as regras computacionais espec&iacute;ficos para o algoritmo de aprendizagem a ser utilizado. Idealmente, os pesos eventualmente convergir para os valores que lhes permitam executar uma computa&ccedil;&atilde;o &uacute;til. Assim, pode&shy;se dizer que a rede neural come&ccedil;a sabendo nada e move&shy;se para ganhar algum conhecimento real, embora o conhecimento &eacute; sub&shy;simb&oacute;lico.</p>&#10;<a id="Utilidade" name="Utilidade"></a><h3> Utilidade </h3>&#10;<p>As redes neurais s&atilde;o particularmente &uacute;teis para lidar com delimitadas de valor real de dados , onde uma sa&iacute;da de valor real &eacute; desejado&semi; desta maneira as redes neurais ir&atilde;o realizar a classifica&ccedil;&atilde;o por graus, e s&atilde;o capazes de expressar valores equivalentes a &#34&semi;n&atilde;o sabe&#34&semi;. Se a rede neural &eacute; treinada usando a fun&ccedil;&atilde;o de erro de entropia cruzada<sup id="_ref&shy;14" class="reference"><a href="#_note&shy;14" title="">[14]</a></sup> e se a sa&iacute;da da rede neural &eacute; sigmoidal, ent&atilde;o as sa&iacute;das ser&atilde;o estimativas da probabilidade posterior real de uma classe.</p>&#10;<a id="Aprendizado_(ou_treino)" name="Aprendizado_(ou_treino)"></a><h3> Aprendizado (ou treino) </h3>&#10;<p>O aprendizado consiste na modifica&ccedil;&atilde;o dos pesos das conex&otilde;es entre os neur&ocirc;nios, os pesos iniciais (sinapses) s&atilde;o modificados de forma iterativa, por um algoritmo que segue um dos seguintes paradigmas de aprendizado:</p>&#10;&#10;<ul>&#10;<li>Aprendizado Supervisionado: &eacute; apresentado um conjunto de treino, consistindo de entradas e correspondentes sa&iacute;das desejadas.</li>&#10;<li>Aprendizado por Refor&ccedil;o: para cada entrada apresentada, &eacute; produzida uma indica&ccedil;&atilde;o (refor&ccedil;o) sobre a adequa&ccedil;&atilde;o das sa&iacute;das correspondentes produzidas pela rede.</li>&#10;<li>Aprendizado N&atilde;o&shy;supervisionado: A rede atualiza seus pesos sem o uso de pares entrada&shy;sa&iacute;das desejadas e sem indica&ccedil;&otilde;es sobre a adequa&ccedil;&atilde;o das sa&iacute;das produzidas.</li></ul>&#10;<a id="Descri%C3%A7%C3%A3o" name="Descri%C3%A7%C3%A3o"></a><h2> Descri&ccedil;&atilde;o </h2>&#10;<p>As redes neurais artificiais s&atilde;o um m&eacute;todo para solucionar problemas atrav&eacute;s da simula&ccedil;&atilde;o do c&eacute;rebro humano, inclusive em seu comportamento, ou seja, aprendendo, errando e fazendo descobertas. S&atilde;o t&eacute;cnicas computacionais que apresentam um modelo inspirado na estrutura neural de <a href="http://en.wikipedia.org/wiki/Organismo" id="w">organismos</a> inteligentes e que adquirem conhecimento atrav&eacute;s da experi&ecirc;ncia.</p>&#10;<p>As redes neurais possuem n&oacute;s ou unidades de <a href="http://en.wikipedia.org/wiki/Processamento" id="w">processamento</a>. Cada unidade possui liga&ccedil;&otilde;es para outras unidades, nas quais recebem e enviam sinais. Cada unidade pode possuir <a href="http://en.wikipedia.org/wiki/Mem%C3%B3ria" id="w">mem&oacute;ria</a> local. Essas unidades s&atilde;o a simula&ccedil;&atilde;o dos neur&ocirc;nios, recebendo e retransmitindo informa&ccedil;&otilde;es. Somam&shy;se as entradas e se retorna uma sa&iacute;da, caso esta seja maior que o valor da soma.</p>&#10;<p>Uma rede neural pode possuir uma ou m&uacute;ltiplas camadas. Exemplificando com tr&ecirc;s camadas, poder&iacute;amos ter a <i>camada de entrada</i>, em que as unidades recebem os padr&otilde;es&semi; a <i>camada intermedi&aacute;ria</i>, onde &eacute; feito processamento e a extra&ccedil;&atilde;o de caracter&iacute;sticas&semi; e a <i>camada de sa&iacute;da</i>, que conclui e apresenta o resultado final. Quanto maior o n&uacute;mero de camadas, melhor a capacidade de aprendizado.</p>&#10;<p>A <i>camada de entrada</i> deve possuir uma unidade especial conhecida como <i>bias</i>, usada para aumentar os graus de liberdade, permitindo uma melhor adapta&ccedil;&atilde;o, por parte da rede neural, ao conhecimento a ela fornecido.</p>&#10;<p>Em termos mais t&eacute;cnicos, o n&uacute;mero de camadas define a capacidade de representa&ccedil;&atilde;o das rela&ccedil;&otilde;es entre o espa&ccedil;o de entrada e o de sa&iacute;da. A inexist&ecirc;ncia da <i>camada intermedi&aacute;ria</i>, caracter&iacute;stica do modelo <i><a href="http://en.wikipedia.org/wiki/Perceptron" id="w">perceptron</a></i>, condiciona&shy;o a representar bem somente rela&ccedil;&otilde;es linearmente independentes. A exist&ecirc;ncia de camadas intermedi&aacute;rias, caracter&iacute;stica do modelo <i><a href="http://en.wikipedia.org/wiki/Perceptron_de_m%C3%BAltipla_camada" id="w">perceptron de m&uacute;ltipla camada</a></i> (PMC), retira tal limita&ccedil;&atilde;o. Se houver apenas uma <i>camada intermedi&aacute;ria</i>, o PMC pode representar (com qualquer grau de aproxima&ccedil;&atilde;o, por menor que seja) qualquer fun&ccedil;&atilde;o cont&iacute;nua. Duas ou mais camadas ampliam o universo de representa&ccedil;&atilde;o a qualquer fun&ccedil;&atilde;o, cont&iacute;nua ou n&atilde;o.</p>&#10;<p>As redes neurais artificiais, seguindo a tradi&ccedil;&atilde;o <a href="http://en.wikipedia.org/wiki/Estadunidense" id="w">estadunidense</a>, est&atilde;o muito associadas &agrave; adapta&ccedil;&atilde;o de conex&otilde;es (sinapses) entre neur&ocirc;nios, o conexionismo. Cabe registrar, entretanto, a exist&ecirc;ncia de modelos nos quais as conex&otilde;es n&atilde;o s&atilde;o adaptadas, mas apenas transmitem estimula&ccedil;&atilde;o entre neur&ocirc;nios. Tais modelos s&atilde;o chamados redes neurais sem pesos (do <a href="http://en.wikipedia.org/wiki/L%C3%ADngua_inglesa" id="w">ingl&ecirc;s</a>, <i>weightless neural networks</i>). Para completar, h&aacute; modelos em que as sinapses n&atilde;o s&atilde;o adaptadas, mas calculadas previamente, servindo a tarefas de otimiza&ccedil;&atilde;o, geralmente.</p>&#10;<a id="Tipos_de_Entradas" name="Tipos_de_Entradas"></a><h3> Tipos de Entradas </h3>&#10;<p>Podemos classificar as RNAs segundo suas capacidades de processar diferentes tipos de informa&ccedil;&otilde;es como:</p>&#10;&#10;<ul>&#10;<li>Redes anal&oacute;gicas: processam dados de entrada com valores cont&iacute;nuos e, geralmente limitados. Exemplo deste tipo de rede s&atilde;o: Hopfield, Kohonen e as redes de aprendizagem competitivo.</li>&#10;<li>Redes discretas: processam dados de entrada de natureza discreta, geralmente valores l&oacute;gicos booleanos. Exemplo deste segundo tipo de rede s&atilde;o as m&aacute;quinas de Boltzmann e Cauchy, e a rede discreta de Hopfield.</li></ul>&#10;<a id="Diferencia%C3%A7%C3%A3o" name="Diferencia%C3%A7%C3%A3o"></a><h2> Diferencia&ccedil;&atilde;o </h2>&#10;<p>A maior parte dos investigadores concorda em que as redes neurais s&atilde;o muito diferentes do <a href="http://en.wikipedia.org/wiki/C%C3%A9rebro" id="w">c&eacute;rebro</a> em termos de estrutura. No entanto, como o c&eacute;rebro, uma rede neural &eacute; uma cole&ccedil;&atilde;o massivamente paralela de unidades de processamento pequenas e simples, onde as interliga&ccedil;&otilde;es formam a maior parte da <a href="http://en.wikipedia.org/wiki/Intelig%C3%AAncia" id="w">intelig&ecirc;ncia</a> da rede. Entretanto, em termos de escala, o c&eacute;rebro &eacute; muito maior que qualquer rede neural. Al&eacute;m disso, as unidades usadas na rede neural s&atilde;o tipicamente muito mais simples que os <a href="http://en.wikipedia.org/wiki/Neur%C3%B4nio" id="w">neur&ocirc;nios</a> e o processo de aprendizado do c&eacute;rebro (embora ainda desconhecido) &eacute;, certamente, muito diferente do das redes neurais.</p>&#10;<a id="Rede_pr%C3%B3&shy;alimentada" name="Rede_pr%C3%B3&shy;alimentada"></a><h3> Rede pr&oacute;&shy;alimentada </h3>&#10;<p>Uma rede neural pr&oacute;&shy;alimentada (em contraposi&ccedil;&atilde;o &agrave; retroalimentada) t&iacute;pica consiste de um conjunto de n&oacute;s. Alguns desses n&oacute;s s&atilde;o designados n&oacute;s de entrada, outros n&oacute;s de sa&iacute;da e aqueles que est&atilde;o entre esses dois tipos de n&oacute;s s&atilde;o chamados de n&oacute;s escondidos. Existem tamb&eacute;m conex&otilde;es entre os neur&ocirc;nios, com um n&uacute;mero referido como um ponderador associado a cada conex&atilde;o. Quando a rede est&aacute; em opera&ccedil;&atilde;o, um valor de entrada ser&aacute; aplicado a cada <i>n&oacute; de entrada</i> &shy; esses valores s&atilde;o colocados por um operador humano ou por sensores ambientais, ou talvez por outros programas.</p>&#10;<p>Cada n&oacute; ent&atilde;o passa seu dado valor para as conex&otilde;es que saem dele e em cada conex&atilde;o o valor &eacute; multiplicado por um ponderador associado a essa conex&atilde;o. Cada n&oacute; na camada seguinte recebe um valor, que &eacute; a soma dos valores produzidos pelas conex&otilde;es que chegam at&eacute; ele, e em cada n&oacute; &eacute; realizada uma computa&ccedil;&atilde;o simples sobre esse valor &shy; uma <a href="http://en.wikipedia.org/wiki/Fun%C3%A7%C3%A3o_sigm%C3%B3ide" id="w">fun&ccedil;&atilde;o sigm&oacute;ide</a> &eacute; t&iacute;pica nesse caso. O processo ent&atilde;o &eacute; repetido com os resultados sendo passados atrav&eacute;s de camadas subseq&uuml;entes de n&oacute;s, at&eacute; que os n&oacute;s de resultados sejam atingidos. Isso &eacute; baseado em um modelo de neur&ocirc;nio da <a href="http://en.wikipedia.org/wiki/D%C3%A9cada_de_1970" id="w">d&eacute;cada de 1970</a>.</p>&#10;<p>Os modelos alternativos de c&aacute;lculo nas redes neurais incluem aqueles dotados de la&ccedil;os (nos quais algum tipo de processo de retardamento de tempo precisa ser usado) e os modelos o &#34&semi;vencedor leva tudo&#34&semi;, nos quais o neur&ocirc;nio com os valores mais altos dispara e toma o valor 1 e todos os outros neur&ocirc;nios tomam o valor 0.</p>&#10;<p>Tipicamente, os ponderadores em uma rede neural s&atilde;o colocados inicialmente em valores aleat&oacute;rios pequenos&semi; isso significa que a rede n&atilde;o sabe nada. &Agrave; medida que o processo de treinamento acontece, esses ponderadores ir&atilde;o convergir para valores que permitem que eles realizem uma computa&ccedil;&atilde;o &uacute;til. Assim, pode ser dito que uma rede neural come&ccedil;a sabendo nada e move&shy;se no sentido de ganhar algum conhecimento real.</p>&#10;<p>As redes neurais s&atilde;o particularmente &uacute;teis para lidar com dados ligados a valores reais em que se deseja obter uma sa&iacute;da dotada de valor real. Dessa maneira, as redes neurais ir&atilde;o realizar uma classifica&ccedil;&atilde;o por graus e ser&atilde;o capazes de expressar valores equivalentes a &#34&semi;n&atilde;o conhecido com certeza&#34&semi;. Se uma rede neural &eacute; treinada usando a fun&ccedil;&atilde;o de erro de <i><a href="http://en.wikipedia.org/wiki/Entropia_(teoria_da_informa%C3%A7%C3%A3o)" id="w">entropia</a> cruzada</i> e se a sa&iacute;da dessa rede neural tem uma forma sigmoidal n&atilde;o&shy;linear, ent&atilde;o as sa&iacute;das ser&atilde;o estimativas de uma <a href="http://en.wikipedia.org/wiki/Probabilidade" id="w">probabilidade</a> posterior real de uma classe.</p>&#10;<a id="Aplica%C3%A7%C3%B5es_reais" name="Aplica%C3%A7%C3%B5es_reais"></a><h3> Aplica&ccedil;&otilde;es reais </h3>&#10;<p>Em aplica&ccedil;&otilde;es reais, as redes neurais se saem particularmente bem nas seguintes tarefas:&#10;</p>&#10;<ul>&#10;<li>aproxima&ccedil;&atilde;o de fun&ccedil;&otilde;es&semi;</li>&#10;<li>previs&atilde;o de s&eacute;ries temporais&semi;</li>&#10;<li>classifica&ccedil;&otilde;es&semi;</li>&#10;<li>reconhecimento de padr&otilde;es.</li></ul>&#10;<a id="CTRNN" name="CTRNN"></a><h3> CTRNN </h3>&#10;<p>Outros tipos de redes neurais, em particular redes neurais recorrentes de tempo cont&iacute;nuo (CTRNN), s&atilde;o usadas em conjunto com <a href="http://en.wikipedia.org/wiki/Algoritmo_gen%C3%A9tico" id="w">algoritmos gen&eacute;ticos</a> para produzir controladores rob&oacute;ticos. O <a href="http://en.wikipedia.org/wiki/Genoma" id="w">genoma</a> &eacute; ent&atilde;o constitu&iacute;do dos par&acirc;metros de rede e a aptid&atilde;o de uma rede &eacute; a adequa&ccedil;&atilde;o do comportamento exibido pelo <a href="http://en.wikipedia.org/wiki/Rob%C3%B4" id="w">rob&ocirc;</a> controlado (ou freq&uuml;entemente por uma simula&ccedil;&atilde;o desse comportamento).</p>&#10;<a id="Tipos_de_redes_neurais" name="Tipos_de_redes_neurais"></a><h2> Tipos de redes neurais </h2>&#10;<p>O exemplo mais antigo de redes neurais s&atilde;o as redes <i>perceptron</i>, com uma camada de <i>n&oacute;s de sa&iacute;da</i>, conectados &agrave;s entradas por conjuntos de pesos. Essa <a href="http://en.wikipedia.org/wiki/Topologia_de_rede" id="w">topologia</a> pode ser considerada a forma mais simples de rede em avan&ccedil;o. A soma do produtos dos pesos pelas entradas &eacute; calculada por cada <i>n&oacute; de sa&iacute;da</i> e, se o valor calculado ultrapassar um certo limiar (geralmente 0), o neur&ocirc;nio dispara e ajusta a sa&iacute;da para o valor 1&semi; se o valor calculado &eacute; menor que o limiar, a sa&iacute;da &eacute; ajustada para o valor &shy;1. Neur&ocirc;nios com esse comportamento s&atilde;o chamados de neur&ocirc;nios de McCulloch&shy;Pitts ou neur&ocirc;nios com limiar. Ao mesmo tempo, um <a href="http://en.wikipedia.org/wiki/Algoritmo_de_aprendizado" id="w">algoritmo de aprendizado</a> calcula a diferen&ccedil;a entre a sa&iacute;da calculada e os dados de entrada e usa o valor da diferen&ccedil;a para ajustar os pesos da rede.</p>&#10;<a id="Perceptron_com_uma_camada" name="Perceptron_com_uma_camada"></a><h3> Perceptron com uma camada </h3>&#10;<p> &#10;<i>Perceptrons</i> podem ser treinados por um algoritmo de aprendizagem simples, chamado geralmente de regra&shy;delta. Esse algoritmo calcula os erros entre a sa&iacute;da dos dados calculados e a sa&iacute;da desejada e utiliza isso para ajustar os pesos, assim executando um formul&aacute;rio da descida do gradiente.</p>&#10;<p>Os <i>perceptrons</i> de uma camada s&atilde;o capazes de aprender somente sobre problemas linearmente separ&aacute;veis (que podem ser separados por uma reta em um <a href="http://en.wikipedia.org/wiki/Hiperplano" id="w">hiperplano</a>). Em <a href="http://en.wikipedia.org/wiki/1969" id="w">1969</a>, na famosa <a href="http://en.wikipedia.org/wiki/Monografia" id="w">monografia</a> <i>Perceptrons por Marvin Minsky e por Seymour Papert</i>, mostrou&shy;se que era imposs&iacute;vel para uma &uacute;nica rede do <i>perceptron</i> da camada aprender uma fun&ccedil;&atilde;o de <a href="http://en.wikipedia.org/wiki/XOR" id="w">XOR</a>. Conjecturou&shy;se (incorretamente) que um resultado similar penderia para uma rede multicamadas do <i>perceptron</i>. Embora uma &uacute;nica unidade do ponto inicial fosse completamente limitada em seu poder computacional, mostrou&shy;se que as redes de unidades paralelas do ponto inicial podem aproximar toda a fun&ccedil;&atilde;o cont&iacute;nua de um intervalo compacto dos <a href="http://en.wikipedia.org/wiki/N%C3%BAmeros_reais" id="w">n&uacute;meros reais</a> no intervalo [&shy; 1, 1 ].</p>&#10;<a id="Perceptron_multicamadas" name="Perceptron_multicamadas"></a><h3> Perceptron multicamadas </h3>&#10;<p> &#10;Esta classe de rede consiste de m&uacute;ltiplas camadas de unidades computacionais, geralmente interconectadas em uma forma de <a href="http://en.wikipedia.org/wiki/Alimenta%C3%A7%C3%A3o_avante" id="w">alimenta&ccedil;&atilde;o avante</a>. Isso quer dizer que cada neur&ocirc;nio em uma camada tem conex&otilde;es diretas a neur&ocirc;nios da pr&oacute;xima camada. Em muitas aplica&ccedil;&otilde;es, as unidades dessas redes utilizam uma fun&ccedil;&atilde;o sigm&oacute;ide (em forma de S) como a fun&ccedil;&atilde;o de ativa&ccedil;&atilde;o.</p>&#10;<p>O <a href="http://en.wikipedia.org/wiki/Teorema_de_aproxima%C3%A7%C3%A3o_universal" id="w">teorema de aproxima&ccedil;&atilde;o universal</a> dita que toda fun&ccedil;&atilde;o cont&iacute;nua que mapeia intervalos de n&uacute;meros reais de entrada a algum intervalo de n&uacute;meros reais de sa&iacute;da pode ser arbitrariamente aproximada com precis&atilde;o por um <i>perceptron multicamadas</i> com somente uma camada oculta. Esse resultado s&oacute; &eacute; v&aacute;lido para classes restritas de fun&ccedil;&otilde;es de ativa&ccedil;&atilde;o, por exemplo, fun&ccedil;&otilde;es sigm&oacute;ides.</p>&#10;<p>As <i>redes multicamadas</i> podem usar um grande n&uacute;mero de t&eacute;cnicas de aprendizado, sendo que a mais popular &eacute; a propaga&ccedil;&atilde;o reversa. Nesse caso, os valores de sa&iacute;da s&atilde;o comparados com a resposta correta para computar o valor de alguma fun&ccedil;&atilde;o de erro pr&eacute;&shy;definida. Por alguma t&eacute;cnica, o erro &eacute; ent&atilde;o alimentado de volta na rede. Usando essa informa&ccedil;&atilde;o, o algoritmo ajusta os pesos de cada conex&atilde;o para reduzir o valor da fun&ccedil;&atilde;o de erro.</p>&#10;<a id="Redes_ARTs" name="Redes_ARTs"></a><h3> Redes ARTs </h3>&#10;<p>ART s&atilde;o as siglas em ingl&ecirc;s de Teoria da Resson&acirc;ncia Adaptativa (Adaptive Resonance Theory), desenvolvida inicialmente por Stephen Grossberg, em 1976, e em publica&ccedil;&otilde;es posteriores em parceria com Gail Carpenter (1986/87).</p>&#10;<p>As redes neurais artificiais ART s&atilde;o redes que n&atilde;o precisam da exposi&ccedil;&atilde;o pr&eacute;via de qualquer n&uacute;mero de elementos do conjunto de dados para o seu treinamento. A principal caracter&iacute;stica dessa fam&iacute;lia de arquiteturas &eacute; a sua capacidade para formar agrupamentos (clusters), que nos permite identificar padr&otilde;es desconhecidos.<sup id="_ref&shy;15" class="reference"><a href="#_note&shy;15" title="">[15]</a></sup>&#10;Existem tr&ecirc;s modelos de redes ARTs:</p>&#10;<p>ART1: &eacute; capaz de aprender a categorizar padr&otilde;es de entrada bin&aacute;rios apresentados em ordem arbitr&aacute;ria.</p>&#10;<p>ART2: pode aprender a categorizar padr&otilde;es de entrada anal&oacute;gicos ou bin&aacute;rios.</p>&#10;<p>ART3 (ARTMAP): pode realizar uma busca paralela, ou teste de hip&oacute;teses, em c&oacute;digos com reconhecimento distribu&iacute;do.</p>&#10;<a id="Aplica%C3%A7%C3%A3o" name="Aplica%C3%A7%C3%A3o"></a><h4> Aplica&ccedil;&atilde;o </h4>&#10;<p>Reconhecimento Autom&aacute;tico de Alvos&semi;&#10;Reconhecimento de Caracteres&semi;&#10;Rob&oacute;tica&semi;&#10;Diagn&oacute;stico M&eacute;dico&semi;&#10;Sensoriamento Remoto&semi;&#10;Processamento de Voz&semi;</p>&#10;<a id="Aprendizado" name="Aprendizado"></a><h4> Aprendizado </h4>&#10;<p>O algoritmo de aprendizado da rede ART 1 n&atilde;o &eacute; supervisionado e pode ser ativa a qualquer momento, permitindo que a rede aprenda novos padr&otilde;es continuamente.</p>&#10;<p>Existem 2 tipos de  aprendizado na rede ART 1, o aprendizado r&aacute;pido e o lento.</p>&#10;<p>O processo de aprendizado da rede envolve 3 fases como: reconhecimento, compara&ccedil;&atilde;o e busca.</p>&#10;<a id="Rede_Hopfield" name="Rede_Hopfield"></a><h3> Rede Hopfield </h3>&#10;<p>Em 1982 houve uma nova evolu&ccedil;&atilde;o nos trabalhos das redes neurais iniciado por John Hopfield,<sup id="_ref&shy;16" class="reference"><a href="#_note&shy;16" title="">[16]</a></sup> nascido em 15 de julho de 1933 &eacute; um americano Cientista mais conhecido pela inven&ccedil;&atilde;o de uma rede neural associativa, conhecida como a Rede de Hopfield. John Hopfield publicou dois artigos que influenciaram v&aacute;rios pesquisadores, chamando a aten&ccedil;&atilde;o para as propriedades associativas de uma classe de Redes Neurais. A an&aacute;lise &eacute; baseada na defini&ccedil;&atilde;o de &ldquo;energia&rdquo; da rede. &Eacute; uma prova de que a rede opera minimizando esta energia quando evolui para padr&otilde;es est&aacute;veis de opera&ccedil;&atilde;o.</p>&#10;<a id="Defini%C3%A7%C3%B5es_Iniciais" name="Defini%C3%A7%C3%B5es_Iniciais"></a><h3> Defini&ccedil;&otilde;es Iniciais </h3>&#10;<p>&Eacute; uma mem&oacute;ria auto&shy;associativa. Suas entradas s&atilde;o valores bin&aacute;rios.<sup id="_ref&shy;17" class="reference"><a href="#_note&shy;17" title="">[17]</a></sup> Possui uma natureza de opera&ccedil;&atilde;o ass&iacute;ncrona, isto &eacute; a cada instante de tempo, cada neur&ocirc;nio tem seu estado de ativa&ccedil;&atilde;o &ldquo;avaliado&rdquo; de maneira independente dos outros neur&ocirc;nios.</p>&#10;<a id="Mem%C3%B3ria_associativa" name="Mem%C3%B3ria_associativa"></a><h3> Mem&oacute;ria associativa </h3>&#10;<p>&Eacute; um conceito intuitivo,<sup id="_ref&shy;18" class="reference"><a href="#_note&shy;18" title="">[18]</a></sup> onde parece ser uma das fun&ccedil;&otilde;es prim&aacute;rias do c&eacute;rebro, e facilmente associamos objetos, imagens e sensa&ccedil;&otilde;es a eventos com a rede Hopfield, serve para reconstituir padr&otilde;es corrompidos ou incompletos, um exemplo &eacute; uma pessoa que normalmente n&atilde;o usa &oacute;culos escuros, com eles, mesmo assim &eacute; reconhecido, assim recuperando informa&ccedil;&otilde;es pelo conte&uacute;do.</p>&#10;<p>A rede de Hopfield pode ser vista como uma mem&oacute;ria associativa, ou uma mem&oacute;ria endere&ccedil;&aacute;vel por conte&uacute;do, cuja principal fun&ccedil;&atilde;o &eacute; restaurar um padr&atilde;o (item de mem&oacute;ria ) armazenado em resposta &agrave; apresenta&ccedil;&atilde;o de uma vers&atilde;o incompleta ou ruidosa deste padr&atilde;o. </p>&#10;<a id="Aplica%C3%A7%C3%A3o" name="Aplica%C3%A7%C3%A3o"></a><h3> Aplica&ccedil;&atilde;o </h3>&#10;<p>A rede Hopfield foi aplicada em v&aacute;rias &aacute;reas, tendo um campo de utiliza&ccedil;&atilde;o muito grande, umas delas foi a Identifica&ccedil;&atilde;o de alvos militares B&shy;52, Boeing 747 e Space Shuttle, Autenti&ccedil;&atilde;o de usu&aacute;rios, explora&ccedil;&atilde;o de petr&oacute;leo e determina&ccedil;&atilde;o e litologia, Predi&ccedil;&atilde;o no Mercado Financeiro, Reconhecimentos de Faces e Controle de Navega&ccedil;&atilde;o Aut&ocirc;noma de Ve&iacute;culos ALVINN at CMU.<sup id="_ref&shy;19" class="reference"><a href="#_note&shy;19" title="">[19]</a></sup></p>&#10;<a id="Estrutura" name="Estrutura"></a><h3> Estrutura </h3>&#10;<p>As unidades em redes de Hopfield s&atilde;o unidades bin&aacute;rias do ponto inicial, isto &eacute;, as unidades fazem exame somente em dois valores diferentes para seus estados e o valor &eacute; determinado perto se ou n&atilde;o a entrada das unidades excede seu ponto inicial. As redes de Hopfield podem um ou outro ter as unidades que fazem exame em valores de 1 ou de &shy;1, ou as unidades que fazem exame em valores de 1 ou de 0.</p>&#10;<a id="Treinamento" name="Treinamento"></a><h3> Treinamento </h3>&#10;<p>Treinar uma rede de Hopfield envolve abaixar a energia dos estados que a rede se &ldquo;recorde&rdquo;. Isto permite que a rede sirva como um sistema da mem&oacute;ria endere&ccedil;&aacute;vel satisfeita, aquele &eacute; dizer, a rede convergir&aacute; a um estado &ldquo;recordado&rdquo; se for dado somente a parte do estado. A rede pode ser usada recuperar de uma entrada distorcida o estado treinado que &eacute; o mais similar a essa entrada. Isto &eacute; chamado mem&oacute;ria associativa porque recupera mem&oacute;rias na base da similaridade. Por exemplo, se n&oacute;s treinarmos uma rede de Hopfield com cinco unidades de modo que o estado (1, 0, 1, 0, 1)<sup id="_ref&shy;20" class="reference"><a href="#_note&shy;20" title="">[20]</a></sup> seja um m&iacute;nimo da energia, e n&oacute;s damos &agrave; rede o estado (1, 0, 0, 0, 1) que convergir&aacute; (1, 0, 1, 0, 1). Assim, a rede est&aacute; treinada corretamente quando a energia dos estados que a rede deve recordar &eacute; m&iacute;nimos locais.</p>&#10;<a id="Memoria_Associativa" name="Memoria_Associativa"></a><h3> Memoria Associativa </h3>&#10;<p>Mem&oacute;ria associativa &eacute; um meio de armazenamento e recupera&ccedil;&atilde;o da informa&ccedil;&atilde;o por associa&ccedil;&atilde;o com outras informa&ccedil;&otilde;es.</p>&#10;<p>Um dispositivo de armazenamento &eacute; chamado mem&oacute;ria associativa, se voc&ecirc; pode recuperar informa&ccedil;&otilde;es a partir do conhecimento parcial do seu conte&uacute;do, sem saber seu local de armazenamento. &Agrave;s vezes tamb&eacute;m chamado de mem&oacute;ria de conte&uacute;do n&atilde;o endere&ccedil;&aacute;vel.</p>&#10;<p>Os Computadores tradicionais n&atilde;o usam este direcionamento, se baseiam no conhecimento exato da dire&ccedil;&atilde;o (endere&ccedil;o) da mem&oacute;ria em que se encontra a informac&atilde;o.</p>&#10;<p>No entanto, o c&eacute;rebro humano n&atilde;o funciona assim. Se nos lembrarmos do nome de uma pessoa, n&atilde;o seria &uacute;til determinar qual foi o nome de n&uacute;mero 3.274 que aprendemos. Seria mais &uacute;til saber que seu nome come&ccedil;a e termina com &#39&semi;N&#39&semi; e &eacute; um famoso cientista Ingl&ecirc;s. Com essa informa&ccedil;&atilde;o, quase certamente se lembraria com sucesso de &#34&semi;Newton&#34&semi;.</p>&#10;<p>Mem&oacute;rias associativas s&atilde;o uma das mais importantes redes neurais com uma vasta gama de aplica&ccedil;&otilde;es em &aacute;reas como o acesso ao conte&uacute;do de mem&oacute;ria, reconhecimento de padr&otilde;es e controle inteligente.</p>&#10;<p>Uma mem&oacute;ria associativa pode armazenar e recuperar informa&ccedil;&otilde;es quando necess&aacute;rio, ou seja, uma rede realimenta a sa&iacute;da que &eacute; usada repetidamente como uma nova entrada at&eacute; que o processo termine. Voc&ecirc; pode obter essas informa&ccedil;&otilde;es com base no conhecimento da parte dela (chave). O padr&atilde;o de chave pode ser uma vers&atilde;o ruidosa de um padr&atilde;o de memoriza&ccedil;&atilde;o, ou seja, que difere em alguns componentes. A mem&oacute;ria humana &eacute; uma reminisc&ecirc;ncia de uma pessoa, mesmo se voc&ecirc; se veste diferente ou usa &oacute;culos.</p>&#10;<a id="Propriedades_Te%C3%B3ricas" name="Propriedades_Te%C3%B3ricas"></a><h2> Propriedades Te&oacute;ricas </h2>&#10;&#10;<a id="Capacidade_Computacional" name="Capacidade_Computacional"></a><h3> Capacidade Computacional </h3>&#10;&#10;<p>O Perceptron multicamadas &eacute; um aproximador universal de fun&ccedil;&otilde;es, como provado pelo teorema de Cybenko. No entanto, a prova n&atilde;o &eacute; construtiva sobre o n&uacute;mero de neur&ocirc;nios requeridos ou as configura&ccedil;&otilde;es dos valores dos pesos necess&aacute;rias.&#10;O trabalho de Hava Siegelmann e Eduardo D. Sontag forneceu uma prova que uma arquitetura recorrente espec&iacute;fica com valores l&oacute;gicos dos pesos tem o todo o poder de uma <a href="http://en.wikipedia.org/wiki/M%C3%A1quina_de_Turing" id="w">M&aacute;quina de Turing</a><sup id="_ref&shy;21" class="reference"><a href="#_note&shy;21" title="">[21]</a></sup>  usando um n&uacute;mero finito de neur&ocirc;nios e conex&otilde;es lineares padr&otilde;es. Eles mostram tamb&eacute;m que o uso de valores il&oacute;gicos para os pesos resulta em uma m&aacute;quina com capacidade de uma &#34&semi;super&#34&semi; <a href="http://en.wikipedia.org/wiki/M%C3%A1quina_de_Turing" id="w">M&aacute;quina de Turing</a>.</p>&#10;<a id="Capacidade" name="Capacidade"></a><h3> Capacidade </h3>&#10;&#10;<p>Modelos de RNAs tem uma propriedade chamada capacidade, a qual grosseiramente corresponde a sua habilidade de modelar qualquer fun&ccedil;&atilde;o determinada. Isso est&aacute; relacionado com a quantidade de informa&ccedil;&atilde;o que pode ser armazenada na rede e a no&ccedil;&atilde;o de complexidade. </p>&#10;<a id="Converg%C3%AAncia" name="Converg%C3%AAncia"></a><h3> Converg&ecirc;ncia </h3>&#10;&#10;<p>No geral nada pode ser dito sobre converg&ecirc;ncia vendo que ela depende de alguns de fatores. Primeiramente, podem existir m&iacute;nimos locais e isto depende da fun&ccedil;&atilde;o de custo e do modelo. Em segundo lugar, o m&eacute;todo de otimiza&ccedil;&atilde;o usado pode n&atilde;o garantir a converg&ecirc;ncia quando estiver muito longe do m&iacute;nimo local. Em terceiro lugar, para uma quantidade de dados ou par&acirc;metros muito grande, alguns m&eacute;todos se tornam impratic&aacute;veis. No geral, foi descoberto que garantias te&oacute;ricas sobre a converg&ecirc;ncia s&atilde;o guias pouco confi&aacute;veis para aplica&ccedil;&atilde;o pr&aacute;tica.</p>&#10;<a id="Generaliza%C3%A7%C3%A3o_e_Estat%C3%ADsticas" name="Generaliza%C3%A7%C3%A3o_e_Estat%C3%ADsticas"></a><h3> Generaliza&ccedil;&atilde;o e Estat&iacute;sticas </h3>&#10;&#10;<p>Em aplica&ccedil;&otilde;es nas quais o objetivo &eacute; criar um sistema que generalize bem em exemplos cegos, surge o problema de excesso de treinamento. Isso acontece em sistemas complicados ou excessivamente espec&iacute;ficos, quando a capacidade da rede excede significantemente a necessidade dos par&acirc;metros. H&aacute; duas escolas de pensamento para evitar este problema: A primeira &eacute; o uso da valida&ccedil;&atilde;o cruzada e t&eacute;cnicas similares para checar a presen&ccedil;a de excesso de treinamento e selecionar otimamente hiperpar&acirc;metros a fim de minimizar o erro de generaliza&ccedil;&atilde;o. A segunda &eacute; usar alguma forma de regulariza&ccedil;&atilde;o. Este conceito surge naturalmente em um quadro probabil&iacute;stico (Baysiano), no qual a regulariza&ccedil;&atilde;o pode ser feita selecionando uma maior probabilidade anterior em rela&ccedil;&atilde;o a modelos mais simples&semi; mas tamb&eacute;m no aprendizado estat&iacute;stico te&oacute;rico, no qual o objetivo &eacute; minimizar at&eacute; duas quantidades: o &#39&semi;risco emp&iacute;rico&#39&semi; e o &#39&semi;risco estrutural&#39&semi;, o qual corresponde ao erro sobre o conjunto de treinamento e o erro previsto em dados cegos.&#10;Redes neurais supervisionadas que usam uma fun&ccedil;&atilde;o de custo de erro m&eacute;dio quadr&aacute;tico podem usar m&eacute;todos estat&iacute;sticos formais para determinar a confian&ccedil;a do modelo treinado. O erro m&eacute;dio quadr&aacute;tico em um conjunto de valida&ccedil;&atilde;o pode ser usado como uma estimativa para varia&ccedil;&atilde;o. Este valor pode ent&atilde;o ser usado para calcular o intervalo de confian&ccedil;a de uma sa&iacute;da na rede neural, assumindo a distribui&ccedil;&atilde;o normal. A an&aacute;lise da confian&ccedil;a feita desta maneira &eacute; estatisticamente v&aacute;lida enquanto a distribui&ccedil;&atilde;o probabil&iacute;stica da sa&iacute;da se mantiver a mesma e a rede neural n&atilde;o modificada.&#10;Assumindo a fun&ccedil;&atilde;o de ativa&ccedil;&atilde;o softmax na camada de sa&iacute;da da rede neural para vari&aacute;veis categ&oacute;ricas alvos, a sa&iacute;da pode ser interpretada como probabilidades posteriores. Isso &eacute; muito &uacute;til na classifica&ccedil;&atilde;o, pois d&aacute; uma medida de certeza sobre as classifica&ccedil;&otilde;es.</p>&#10;<p>fun&ccedil;&atilde;o de ativa&ccedil;&atilde;o softmax:&#10;</p><dl><dd><span class="math">y_i=\frac{e^{x_i}}{\sum_{j=1}^c e^{x_j}}</span></dd></dl>&#10;<a id="Redes_Neurais_e_Neuroci%C3%AAncia" name="Redes_Neurais_e_Neuroci%C3%AAncia"></a><h2> Redes Neurais e Neuroci&ecirc;ncia </h2>&#10;&#10;<p><a href="http://en.wikipedia.org/wiki/Neuroci%C3%AAncia_computacional" id="w">Neuroci&ecirc;ncia computacional</a> e te&oacute;rica &eacute; o campo preocupado com a an&aacute;lise te&oacute;rica e a modelagem computacional do sistema nervoso biol&oacute;gico. Como sistemas neurais est&atilde;o intimamente relacionados com processos cognitivos e comportamentais, eles tamb&eacute;m est&atilde;o fortemente ligados a modelagem cognitiva e comportamental.</p>&#10;<p>O objetivo do campo &eacute; criar modelos de sistemas neurais biol&oacute;gicos para entender o funcionamento de sistemas biol&oacute;gicos reais. Para chegar a esse entendimento, neurocientistas tentam fazer uma liga&ccedil;&atilde;o entre processos biol&oacute;gicos observados (dados), mecanismos biologicamente plaus&iacute;veis de processamento e aprendizado neural (modelos de <a href="http://en.wikipedia.org/wiki/Redes_neurais_biol%C3%B3gicas" id="w">redes neurais biol&oacute;gicas</a>) e teoria (aprendizado estat&iacute;stico e <a href="http://en.wikipedia.org/wiki/Teoria_da_informa%C3%A7%C3%A3o" id="w">teoria da informa&ccedil;&atilde;o</a>).</p>&#10;<a id="Tipos_de_modelos" name="Tipos_de_modelos"></a><h3> Tipos de modelos </h3>&#10;&#10;<p>Muitos modelos s&atilde;o usados neste campo, cada um definido em um n&iacute;vel diferente de abstra&ccedil;&atilde;o e tentando modelar diferentes aspectos de sistemas neurais. Eles v&atilde;o de modelos de comportamento de curto prazo de neur&ocirc;nios individuais, passando por modelos de como as din&acirc;micas de circuitos neurais surgem de intera&ccedil;&otilde;es entre neur&ocirc;nios individuais, at&eacute; modelos de como comportamentos podem surgir de m&oacute;dulos neurais abstratos que representam subsistemas completos. Estes incluem modelos de plasticidade de curto e longo prazo de sistemas neurais e sua rela&ccedil;&atilde;o com o aprendizado e a mem&oacute;ria, de um neur&ocirc;nio individual at&eacute; o n&iacute;vel de um sistema.</p>&#10;<a id="Galeria" name="Galeria"></a><h2>Galeria</h2>&#10;<p>&#60&semi;gallery widths=&#34&semi;220&#34&semi;&#62&semi;&#10;Image:Two_layer_ann.svg|Rede Neural Artificial FeedForward de duas camadas.&#10;Image:Artificial_neural_network.svg|Exemplo dos componentes de uma Rede Neural Artificial.&#10;&#60&semi;/gallery&#62&semi;</p>&#10;<a id="Ver_tamb%C3%A9m" name="Ver_tamb%C3%A9m"></a><h2> Ver tamb&eacute;m </h2>&#10;&#10;<ul>&#10;<li><a href="http://en.wikipedia.org/wiki/Redes_neurais_biol%C3%B3gicas" id="w">Redes neurais biol&oacute;gicas</a></li>&#10;<li><a href="http://en.wikipedia.org/wiki/Intelig%C3%AAncia_artificial" id="w">Intelig&ecirc;ncia artificial</a></li>&#10;<li><a href="http://en.wikipedia.org/wiki/FAN_(rede_neural)" id="w">FAN (rede neural)</a></li>&#10;<li><a href="http://en.wikipedia.org/wiki/Neuroci%C3%AAncia_computacional" id="w">Neuroci&ecirc;ncia computacional</a></li></ul>&#10;<p> </p>&#10;<a id="Liga%C3%A7%C3%B5es_externas" name="Liga%C3%A7%C3%B5es_externas"></a><h2> Liga&ccedil;&otilde;es externas </h2>&#10;<p> &#10;</p>&#10;<ul>&#10;<li> </li></ul>&#10;<p><a href="http://en.wikipedia.org/wiki/Categoria:Redes_neurais" id="w"> </a></p></body></html>